{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "# from skimage.transform import resize\n",
    "# from matplotlib.pyplot import imread\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('C:\\\\Users\\\\Amit\\\\Documents\\\\Academics\\\\upGrad\\\\Deep Learning\\\\Project_data\\\\train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('C:\\\\Users\\\\Amit\\\\Documents\\\\Academics\\\\upGrad\\\\Deep Learning\\\\Project_data\\\\val.csv').readlines())\n",
    "batch_size = 32 #experiment with the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_path = train_path i.e. path of 663 folders\n",
    "# folder_list = train_doc i.e. csv file\n",
    "# batch_size = 64\n",
    "\n",
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    # It is not possible to work with all the 30 images, as it will take too long processing time.\n",
    "    # So lets choose randomly 18 images\n",
    "    img_idx = [0,1,2,4,6,8,10,12,14,16,18,20,22,24,26,27,28,29] #create a list of image numbers you want to use for a particular video(incase if u want to try with lesser images)\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(t)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,18,84,84,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = resize(image[:,20:140,:],(84,84)).astype(np.float32)\n",
    "                                     \n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (image[:,:,0])/255.0 #normalise and feed in the image # divide by 255.0\n",
    "                    batch_data[folder,idx,:,:,1] = (image[:,:,1])/255.0 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (image[:,:,2])/255.0 #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1 # OHE\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if(len(t)%batch_size)!=0:\n",
    "            batch_data = np.zeros((len(t)%batch_size,18,84,84,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((len(t)%batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(len(t)%batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (num_batches*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imageio.imread(source_path+'/'+ t[folder + (num_batches*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = resize(image[:,20:140,:],(84,84)).astype(np.float32)\n",
    "                                      \n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (image[:,:,0])/255.0 #normalise and feed in the image # divide by 255.0\n",
    "                    batch_data[folder,idx,:,:,1] = (image[:,:,1])/255.0 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (image[:,:,2])/255.0 #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (num_batches*batch_size)].strip().split(';')[2])] = 1 # OHE\n",
    "            yield batch_data, batch_labels# source_path = train_path i.e. path of 663 folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 50\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = 'C:\\\\Users\\\\Amit\\\\Documents\\\\Academics\\\\upGrad\\\\Deep Learning\\\\Project_data\\\\train'\n",
    "val_path = 'C:\\\\Users\\\\Amit\\\\Documents\\\\Academics\\\\upGrad\\\\Deep Learning\\\\Project_data\\\\val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 50 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "#write your model here\n",
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Activation('elu'))\n",
    "model_1.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
    "\n",
    "\n",
    "model_1.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Activation('elu'))\n",
    "model_1.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n",
    "\n",
    "\n",
    "model_1.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Activation('elu'))\n",
    "model_1.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
    "\n",
    "\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(512, activation='elu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 18, 84, 84, 64)    5248      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 18, 84, 84, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 18, 84, 84, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 9, 42, 84, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 9, 42, 84, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9, 42, 84, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9, 42, 84, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 4, 21, 42, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 21, 42, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 21, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               110100992 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 111,216,901\n",
      "Trainable params: 111,216,005\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "optimiser = keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.7, nesterov=True) #write your optimizer\n",
    "model_1.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  C:\\Users\\Amit\\Documents\\Academics\\upGrad\\Deep Learning\\Project_data\\train ; batch size = 32\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - ETA: 0s - loss: 7.8376 - categorical_accuracy: 0.2941Source path =  C:\\Users\\Amit\\Documents\\Academics\\upGrad\\Deep Learning\\Project_data\\val ; batch size = 32\n",
      "21/21 [==============================] - 69s 3s/step - loss: 7.8376 - categorical_accuracy: 0.2941 - val_loss: 3.0298 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-10-2714_06_11.512848\\model-00001-7.83759-0.29412-3.02976-0.18000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.7301 - categorical_accuracy: 0.4012 - val_loss: 2.4565 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00002: saving model to model_init_2021-10-2714_06_11.512848\\model-00002-1.73008-0.40121-2.45645-0.18000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.5317 - categorical_accuracy: 0.4827 - val_loss: 4.5129 - val_categorical_accuracy: 0.1400\n",
      "\n",
      "Epoch 00003: saving model to model_init_2021-10-2714_06_11.512848\\model-00003-1.53171-0.48265-4.51288-0.14000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.2798 - categorical_accuracy: 0.5279 - val_loss: 5.6789 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00004: saving model to model_init_2021-10-2714_06_11.512848\\model-00004-1.27980-0.52790-5.67885-0.29000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.9800 - categorical_accuracy: 0.6456 - val_loss: 7.0595 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00005: saving model to model_init_2021-10-2714_06_11.512848\\model-00005-0.97998-0.64555-7.05948-0.28000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.7966 - categorical_accuracy: 0.7119 - val_loss: 8.2351 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2021-10-2714_06_11.512848\\model-00006-0.79665-0.71192-8.23507-0.32000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.7175 - categorical_accuracy: 0.7270 - val_loss: 9.4122 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00007: saving model to model_init_2021-10-2714_06_11.512848\\model-00007-0.71747-0.72700-9.41223-0.26000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.6606 - categorical_accuracy: 0.7436 - val_loss: 9.8653 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00008: saving model to model_init_2021-10-2714_06_11.512848\\model-00008-0.66065-0.74359-9.86530-0.26000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.6196 - categorical_accuracy: 0.7602 - val_loss: 9.9529 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00009: saving model to model_init_2021-10-2714_06_11.512848\\model-00009-0.61965-0.76018-9.95289-0.28000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5016 - categorical_accuracy: 0.8100 - val_loss: 10.2133 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00010: saving model to model_init_2021-10-2714_06_11.512848\\model-00010-0.50164-0.80995-10.21332-0.29000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5970 - categorical_accuracy: 0.7707 - val_loss: 9.6829 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00011: saving model to model_init_2021-10-2714_06_11.512848\\model-00011-0.59701-0.77074-9.68292-0.27000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.5060 - categorical_accuracy: 0.8175 - val_loss: 9.4903 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00012: saving model to model_init_2021-10-2714_06_11.512848\\model-00012-0.50598-0.81750-9.49035-0.30000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 0.5205 - categorical_accuracy: 0.8175 - val_loss: 9.0648 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00013: saving model to model_init_2021-10-2714_06_11.512848\\model-00013-0.52052-0.81750-9.06482-0.28000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5187 - categorical_accuracy: 0.7964 - val_loss: 8.9241 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00014: saving model to model_init_2021-10-2714_06_11.512848\\model-00014-0.51875-0.79638-8.92409-0.25000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.4781 - categorical_accuracy: 0.8145 - val_loss: 7.9179 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00015: saving model to model_init_2021-10-2714_06_11.512848\\model-00015-0.47811-0.81448-7.91790-0.26000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5325 - categorical_accuracy: 0.7979 - val_loss: 7.5959 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00016: saving model to model_init_2021-10-2714_06_11.512848\\model-00016-0.53252-0.79789-7.59586-0.28000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5133 - categorical_accuracy: 0.7964 - val_loss: 6.7879 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00017: saving model to model_init_2021-10-2714_06_11.512848\\model-00017-0.51333-0.79638-6.78786-0.29000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5226 - categorical_accuracy: 0.7979 - val_loss: 6.1940 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00018: saving model to model_init_2021-10-2714_06_11.512848\\model-00018-0.52259-0.79789-6.19399-0.28000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5226 - categorical_accuracy: 0.8069 - val_loss: 5.6438 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00019: saving model to model_init_2021-10-2714_06_11.512848\\model-00019-0.52264-0.80694-5.64377-0.30000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.4850 - categorical_accuracy: 0.8084 - val_loss: 4.7078 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00020: saving model to model_init_2021-10-2714_06_11.512848\\model-00020-0.48504-0.80845-4.70781-0.29000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.5144 - categorical_accuracy: 0.8039 - val_loss: 4.0379 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00021: saving model to model_init_2021-10-2714_06_11.512848\\model-00021-0.51443-0.80392-4.03788-0.32000.h5\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5194 - categorical_accuracy: 0.7979 - val_loss: 3.2800 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00022: saving model to model_init_2021-10-2714_06_11.512848\\model-00022-0.51944-0.79789-3.28004-0.42000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4906 - categorical_accuracy: 0.8054 - val_loss: 2.8702 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00023: saving model to model_init_2021-10-2714_06_11.512848\\model-00023-0.49056-0.80543-2.87024-0.41000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.4978 - categorical_accuracy: 0.7994 - val_loss: 2.4513 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00024: saving model to model_init_2021-10-2714_06_11.512848\\model-00024-0.49776-0.79940-2.45134-0.49000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.5143 - categorical_accuracy: 0.8265 - val_loss: 2.0902 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00025: saving model to model_init_2021-10-2714_06_11.512848\\model-00025-0.51427-0.82655-2.09020-0.47000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.4790 - categorical_accuracy: 0.8220 - val_loss: 1.9801 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00026: saving model to model_init_2021-10-2714_06_11.512848\\model-00026-0.47903-0.82202-1.98006-0.49000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 0.5005 - categorical_accuracy: 0.8145 - val_loss: 1.5714 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00027: saving model to model_init_2021-10-2714_06_11.512848\\model-00027-0.50055-0.81448-1.57138-0.63000.h5\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.4755 - categorical_accuracy: 0.8145 - val_loss: 1.3607 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00028: saving model to model_init_2021-10-2714_06_11.512848\\model-00028-0.47550-0.81448-1.36069-0.67000.h5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5146 - categorical_accuracy: 0.8039 - val_loss: 1.2807 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00029: saving model to model_init_2021-10-2714_06_11.512848\\model-00029-0.51457-0.80392-1.28068-0.64000.h5\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5058 - categorical_accuracy: 0.8054 - val_loss: 1.1707 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00030: saving model to model_init_2021-10-2714_06_11.512848\\model-00030-0.50577-0.80543-1.17067-0.72000.h5\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4586 - categorical_accuracy: 0.8235 - val_loss: 1.2032 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00031: saving model to model_init_2021-10-2714_06_11.512848\\model-00031-0.45857-0.82353-1.20320-0.68000.h5\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.4102 - categorical_accuracy: 0.8537 - val_loss: 0.9432 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00032: saving model to model_init_2021-10-2714_06_11.512848\\model-00032-0.41019-0.85370-0.94322-0.74000.h5\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5026 - categorical_accuracy: 0.8220 - val_loss: 1.0362 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00033: saving model to model_init_2021-10-2714_06_11.512848\\model-00033-0.50264-0.82202-1.03615-0.72000.h5\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4883 - categorical_accuracy: 0.8024 - val_loss: 1.0686 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00034: saving model to model_init_2021-10-2714_06_11.512848\\model-00034-0.48829-0.80241-1.06861-0.67000.h5\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4457 - categorical_accuracy: 0.8235 - val_loss: 0.9160 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00035: saving model to model_init_2021-10-2714_06_11.512848\\model-00035-0.44570-0.82353-0.91598-0.77000.h5\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.4884 - categorical_accuracy: 0.8130 - val_loss: 1.0091 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00036: saving model to model_init_2021-10-2714_06_11.512848\\model-00036-0.48841-0.81297-1.00908-0.72000.h5\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5043 - categorical_accuracy: 0.7934 - val_loss: 0.9558 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00037: saving model to model_init_2021-10-2714_06_11.512848\\model-00037-0.50432-0.79336-0.95575-0.73000.h5\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4942 - categorical_accuracy: 0.8190 - val_loss: 0.8757 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00038: saving model to model_init_2021-10-2714_06_11.512848\\model-00038-0.49421-0.81900-0.87574-0.75000.h5\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5337 - categorical_accuracy: 0.8024 - val_loss: 1.0651 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00039: saving model to model_init_2021-10-2714_06_11.512848\\model-00039-0.53367-0.80241-1.06512-0.69000.h5\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.5270 - categorical_accuracy: 0.8069 - val_loss: 0.9087 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00040: saving model to model_init_2021-10-2714_06_11.512848\\model-00040-0.52705-0.80694-0.90872-0.73000.h5\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.4329 - categorical_accuracy: 0.8265 - val_loss: 0.9332 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00041: saving model to model_init_2021-10-2714_06_11.512848\\model-00041-0.43295-0.82655-0.93318-0.71000.h5\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4765 - categorical_accuracy: 0.8130 - val_loss: 1.0133 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00042: saving model to model_init_2021-10-2714_06_11.512848\\model-00042-0.47646-0.81297-1.01333-0.65000.h5\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.5150 - categorical_accuracy: 0.7994 - val_loss: 0.8680 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00043: saving model to model_init_2021-10-2714_06_11.512848\\model-00043-0.51501-0.79940-0.86797-0.73000.h5\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.4642 - categorical_accuracy: 0.7964 - val_loss: 0.9211 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00044: saving model to model_init_2021-10-2714_06_11.512848\\model-00044-0.46417-0.79638-0.92106-0.71000.h5\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.5059 - categorical_accuracy: 0.7979 - val_loss: 0.9204 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00045: saving model to model_init_2021-10-2714_06_11.512848\\model-00045-0.50590-0.79789-0.92040-0.71000.h5\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4278 - categorical_accuracy: 0.8341 - val_loss: 0.9324 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00046: saving model to model_init_2021-10-2714_06_11.512848\\model-00046-0.42781-0.83409-0.93238-0.73000.h5\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.4803 - categorical_accuracy: 0.8084 - val_loss: 0.7807 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00047: saving model to model_init_2021-10-2714_06_11.512848\\model-00047-0.48027-0.80845-0.78075-0.72000.h5\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.4005 - categorical_accuracy: 0.8477 - val_loss: 0.9370 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00048: saving model to model_init_2021-10-2714_06_11.512848\\model-00048-0.40046-0.84766-0.93702-0.73000.h5\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4495 - categorical_accuracy: 0.8446 - val_loss: 0.9224 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00049: saving model to model_init_2021-10-2714_06_11.512848\\model-00049-0.44945-0.84465-0.92236-0.71000.h5\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.5020 - categorical_accuracy: 0.8039 - val_loss: 0.9546 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00050: saving model to model_init_2021-10-2714_06_11.512848\\model-00050-0.50196-0.80392-0.95462-0.70000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bcb47e45e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using model_1.fit instead of fit_generator (as the latter has been deprecated):\n",
    "\n",
    "model_1.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 appears to be slightly overfitting. But the overall performance appears to be good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv3D(32, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_2.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_2.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(1024, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(512, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_3 (Conv3D)            (None, 18, 84, 84, 32)    2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 18, 84, 84, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 18, 84, 84, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 18, 84, 84, 64)    55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 18, 84, 84, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 18, 84, 84, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 9, 42, 42, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 9, 42, 42, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 9, 42, 42, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 9, 42, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 4, 21, 21, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 4, 21, 21, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 21, 21, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 21, 21, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 2, 10, 10, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              52429824  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 54,123,397\n",
      "Trainable params: 54,122,437\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 61s 3s/step - loss: 4.1823 - categorical_accuracy: 0.2142 - val_loss: 1.6172 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61719, saving model to model_init_2021-10-2714_06_11.512848\\model-00001-4.18232-0.21418-1.61719-0.15000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 4.1129 - categorical_accuracy: 0.2051 - val_loss: 1.6210 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.61719\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.8472 - categorical_accuracy: 0.2217 - val_loss: 1.6334 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.61719\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.9244 - categorical_accuracy: 0.2353 - val_loss: 1.6662 - val_categorical_accuracy: 0.1100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.61719\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.6290 - categorical_accuracy: 0.2127 - val_loss: 1.6994 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.61719\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.4558 - categorical_accuracy: 0.2262 - val_loss: 1.7271 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.61719\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.3943 - categorical_accuracy: 0.2428 - val_loss: 1.7489 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.61719\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.3701 - categorical_accuracy: 0.2247 - val_loss: 1.7814 - val_categorical_accuracy: 0.1400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.61719\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.2167 - categorical_accuracy: 0.2459 - val_loss: 1.7945 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.61719\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.9722 - categorical_accuracy: 0.2489 - val_loss: 1.8365 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.61719\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.0069 - categorical_accuracy: 0.2474 - val_loss: 1.8649 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.61719\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.0762 - categorical_accuracy: 0.2413 - val_loss: 1.9658 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.61719\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.8953 - categorical_accuracy: 0.2383 - val_loss: 1.7576 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.61719\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.7632 - categorical_accuracy: 0.2836 - val_loss: 1.9083 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.61719\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.5959 - categorical_accuracy: 0.3017 - val_loss: 1.9001 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.61719\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.6098 - categorical_accuracy: 0.2715 - val_loss: 1.8759 - val_categorical_accuracy: 0.1400\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.61719\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.6278 - categorical_accuracy: 0.2851 - val_loss: 1.8569 - val_categorical_accuracy: 0.1400\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.61719\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.4699 - categorical_accuracy: 0.2851 - val_loss: 1.7789 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.61719\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.4698 - categorical_accuracy: 0.2866 - val_loss: 1.7067 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.61719\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.3022 - categorical_accuracy: 0.3228 - val_loss: 1.6596 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.61719\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.5420 - categorical_accuracy: 0.2775 - val_loss: 1.6325 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.61719\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.2965 - categorical_accuracy: 0.3002 - val_loss: 1.5032 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.61719 to 1.50323, saving model to model_init_2021-10-2714_06_11.512848\\model-00022-2.29652-0.30015-1.50323-0.26000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.2654 - categorical_accuracy: 0.3228 - val_loss: 1.4776 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.50323 to 1.47760, saving model to model_init_2021-10-2714_06_11.512848\\model-00023-2.26538-0.32278-1.47760-0.27000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 2.2480 - categorical_accuracy: 0.3122 - val_loss: 1.3822 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.47760 to 1.38220, saving model to model_init_2021-10-2714_06_11.512848\\model-00024-2.24797-0.31222-1.38220-0.36000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.2033 - categorical_accuracy: 0.3469 - val_loss: 1.3802 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.38220 to 1.38023, saving model to model_init_2021-10-2714_06_11.512848\\model-00025-2.20331-0.34691-1.38023-0.32000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.2208 - categorical_accuracy: 0.2986 - val_loss: 1.3487 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.38023 to 1.34869, saving model to model_init_2021-10-2714_06_11.512848\\model-00026-2.22076-0.29864-1.34869-0.38000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.3304 - categorical_accuracy: 0.2941 - val_loss: 1.3171 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.34869 to 1.31712, saving model to model_init_2021-10-2714_06_11.512848\\model-00027-2.33036-0.29412-1.31712-0.36000.h5\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.2821 - categorical_accuracy: 0.2911 - val_loss: 1.3088 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.31712 to 1.30883, saving model to model_init_2021-10-2714_06_11.512848\\model-00028-2.28206-0.29110-1.30883-0.38000.h5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.1138 - categorical_accuracy: 0.3243 - val_loss: 1.2575 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.30883 to 1.25751, saving model to model_init_2021-10-2714_06_11.512848\\model-00029-2.11383-0.32428-1.25751-0.37000.h5\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.2434 - categorical_accuracy: 0.3002 - val_loss: 1.2373 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.25751 to 1.23726, saving model to model_init_2021-10-2714_06_11.512848\\model-00030-2.24343-0.30015-1.23726-0.38000.h5\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.1846 - categorical_accuracy: 0.3394 - val_loss: 1.2541 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.23726\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.1350 - categorical_accuracy: 0.3077 - val_loss: 1.2319 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.23726 to 1.23188, saving model to model_init_2021-10-2714_06_11.512848\\model-00032-2.13499-0.30769-1.23188-0.44000.h5\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.0812 - categorical_accuracy: 0.3183 - val_loss: 1.1806 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.23188 to 1.18064, saving model to model_init_2021-10-2714_06_11.512848\\model-00033-2.08115-0.31825-1.18064-0.46000.h5\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.0073 - categorical_accuracy: 0.3318 - val_loss: 1.2426 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.18064\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.0097 - categorical_accuracy: 0.3258 - val_loss: 1.2384 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.18064\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.1089 - categorical_accuracy: 0.3424 - val_loss: 1.2250 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.18064\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.9971 - categorical_accuracy: 0.3379 - val_loss: 1.2321 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.18064\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.8892 - categorical_accuracy: 0.3514 - val_loss: 1.2262 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.18064\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.9568 - categorical_accuracy: 0.3620 - val_loss: 1.2304 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.18064\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.0802 - categorical_accuracy: 0.3258 - val_loss: 1.2305 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.18064\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.8870 - categorical_accuracy: 0.3620 - val_loss: 1.1958 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.18064\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.9658 - categorical_accuracy: 0.3273 - val_loss: 1.2119 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.18064\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.8885 - categorical_accuracy: 0.3544 - val_loss: 1.2165 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.18064\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 2.0047 - categorical_accuracy: 0.3092 - val_loss: 1.1740 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.18064 to 1.17396, saving model to model_init_2021-10-2714_06_11.512848\\model-00044-2.00472-0.30920-1.17396-0.50000.h5\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.9422 - categorical_accuracy: 0.3348 - val_loss: 1.1987 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.17396\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.8442 - categorical_accuracy: 0.3710 - val_loss: 1.2091 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.17396\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.8173 - categorical_accuracy: 0.3665 - val_loss: 1.2107 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.17396\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.8187 - categorical_accuracy: 0.3590 - val_loss: 1.2756 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.17396\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.7001 - categorical_accuracy: 0.3876 - val_loss: 1.1694 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.17396 to 1.16941, saving model to model_init_2021-10-2714_06_11.512848\\model-00049-1.70010-0.38763-1.16941-0.56000.h5\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.8404 - categorical_accuracy: 0.3635 - val_loss: 1.2045 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.16941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bcb7710b80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 is underfitting & overall performance is poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(Conv3D(32, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_3.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_3.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Dense(1024, activation='relu'))\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Dense(512, activation='relu'))\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_7 (Conv3D)            (None, 18, 84, 84, 32)    2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 18, 84, 84, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 18, 84, 84, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 18, 84, 84, 64)    55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 18, 84, 84, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 18, 84, 84, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 9, 42, 42, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 9, 42, 42, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 9, 42, 42, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 9, 42, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 4, 21, 21, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 4, 21, 21, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4, 21, 21, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 21, 21, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 2, 10, 10, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              52429824  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 54,123,397\n",
      "Trainable params: 54,122,437\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_3.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 4.3237 - categorical_accuracy: 0.2142 - val_loss: 1.6140 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61401, saving model to model_init_2021-10-2714_06_11.512848\\model-00001-4.32365-0.21418-1.61401-0.18000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.0262 - categorical_accuracy: 0.1946 - val_loss: 1.6250 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.61401\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 3.9014 - categorical_accuracy: 0.2323 - val_loss: 1.6117 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.61401 to 1.61174, saving model to model_init_2021-10-2714_06_11.512848\\model-00003-3.90136-0.23228-1.61174-0.20000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 3.7846 - categorical_accuracy: 0.2142 - val_loss: 1.6247 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.61174\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.5540 - categorical_accuracy: 0.2549 - val_loss: 1.6314 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.61174\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.6179 - categorical_accuracy: 0.2308 - val_loss: 1.6250 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.61174\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.2826 - categorical_accuracy: 0.2443 - val_loss: 1.6506 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.61174\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 3.3243 - categorical_accuracy: 0.2278 - val_loss: 1.6496 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.61174\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.2721 - categorical_accuracy: 0.2323 - val_loss: 1.6627 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.61174\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.2070 - categorical_accuracy: 0.2443 - val_loss: 1.7013 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.61174\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.9775 - categorical_accuracy: 0.2655 - val_loss: 1.6914 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.61174\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.7761 - categorical_accuracy: 0.2655 - val_loss: 1.7023 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.61174\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.8514 - categorical_accuracy: 0.2775 - val_loss: 1.7012 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.61174\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.6969 - categorical_accuracy: 0.2745 - val_loss: 1.7148 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.61174\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.8319 - categorical_accuracy: 0.2624 - val_loss: 1.7323 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.61174\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.6560 - categorical_accuracy: 0.2790 - val_loss: 1.7009 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.61174\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.6976 - categorical_accuracy: 0.2745 - val_loss: 1.6597 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.61174\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.6356 - categorical_accuracy: 0.2881 - val_loss: 1.6090 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.61174 to 1.60901, saving model to model_init_2021-10-2714_06_11.512848\\model-00018-2.63564-0.28808-1.60901-0.27000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.6030 - categorical_accuracy: 0.3047 - val_loss: 1.6048 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.60901 to 1.60484, saving model to model_init_2021-10-2714_06_11.512848\\model-00019-2.60297-0.30468-1.60484-0.26000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.5463 - categorical_accuracy: 0.2866 - val_loss: 1.5800 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.60484 to 1.57997, saving model to model_init_2021-10-2714_06_11.512848\\model-00020-2.54628-0.28658-1.57997-0.33000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.3684 - categorical_accuracy: 0.2971 - val_loss: 1.5367 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.57997 to 1.53671, saving model to model_init_2021-10-2714_06_11.512848\\model-00021-2.36843-0.29713-1.53671-0.34000.h5\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.5153 - categorical_accuracy: 0.2685 - val_loss: 1.4470 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.53671 to 1.44705, saving model to model_init_2021-10-2714_06_11.512848\\model-00022-2.51527-0.26848-1.44705-0.41000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.3909 - categorical_accuracy: 0.3152 - val_loss: 1.4160 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.44705 to 1.41603, saving model to model_init_2021-10-2714_06_11.512848\\model-00023-2.39092-0.31523-1.41603-0.48000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.3757 - categorical_accuracy: 0.3017 - val_loss: 1.4524 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.41603\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 2.2938 - categorical_accuracy: 0.3032 - val_loss: 1.3887 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.41603 to 1.38868, saving model to model_init_2021-10-2714_06_11.512848\\model-00025-2.29378-0.30317-1.38868-0.46000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.3003 - categorical_accuracy: 0.2866 - val_loss: 1.3836 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.38868 to 1.38365, saving model to model_init_2021-10-2714_06_11.512848\\model-00026-2.30028-0.28658-1.38365-0.43000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.3151 - categorical_accuracy: 0.3032 - val_loss: 1.3888 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.38365\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.1898 - categorical_accuracy: 0.3258 - val_loss: 1.3067 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.38365 to 1.30672, saving model to model_init_2021-10-2714_06_11.512848\\model-00028-2.18983-0.32579-1.30672-0.49000.h5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 2.1605 - categorical_accuracy: 0.3258 - val_loss: 1.3105 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.30672\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.1828 - categorical_accuracy: 0.3243 - val_loss: 1.2604 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.30672 to 1.26036, saving model to model_init_2021-10-2714_06_11.512848\\model-00030-2.18283-0.32428-1.26036-0.52000.h5\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.1405 - categorical_accuracy: 0.3107 - val_loss: 1.3048 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.26036\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.2088 - categorical_accuracy: 0.3137 - val_loss: 1.2907 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.26036\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 52s 3s/step - loss: 2.2028 - categorical_accuracy: 0.3077 - val_loss: 1.2727 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.26036\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.0663 - categorical_accuracy: 0.3017 - val_loss: 1.2627 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.26036\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.1987 - categorical_accuracy: 0.2911 - val_loss: 1.2368 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.26036 to 1.23677, saving model to model_init_2021-10-2714_06_11.512848\\model-00035-2.19868-0.29110-1.23677-0.49000.h5\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.0829 - categorical_accuracy: 0.3363 - val_loss: 1.2787 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.23677\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.1142 - categorical_accuracy: 0.3484 - val_loss: 1.2508 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.23677\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.1668 - categorical_accuracy: 0.3017 - val_loss: 1.2668 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.23677\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.0900 - categorical_accuracy: 0.3258 - val_loss: 1.2325 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.23677 to 1.23253, saving model to model_init_2021-10-2714_06_11.512848\\model-00039-2.09003-0.32579-1.23253-0.58000.h5\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.0238 - categorical_accuracy: 0.3107 - val_loss: 1.2758 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.23253\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.0206 - categorical_accuracy: 0.3318 - val_loss: 1.2533 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.23253\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.0159 - categorical_accuracy: 0.3273 - val_loss: 1.2677 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.23253\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.0006 - categorical_accuracy: 0.3198 - val_loss: 1.2561 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.23253\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.8686 - categorical_accuracy: 0.3469 - val_loss: 1.2452 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.23253\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.9204 - categorical_accuracy: 0.3077 - val_loss: 1.2456 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.23253\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.9615 - categorical_accuracy: 0.3394 - val_loss: 1.2036 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.23253 to 1.20358, saving model to model_init_2021-10-2714_06_11.512848\\model-00046-1.96149-0.33937-1.20358-0.58000.h5\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.8505 - categorical_accuracy: 0.3529 - val_loss: 1.2721 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.20358\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.8649 - categorical_accuracy: 0.3499 - val_loss: 1.2296 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.20358\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.8994 - categorical_accuracy: 0.3650 - val_loss: 1.2397 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.20358\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.8296 - categorical_accuracy: 0.3801 - val_loss: 1.2840 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.20358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bcb77101f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 is underfitting and overall performance is poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying model 1 with 50% dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(Conv3D(32, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Activation('elu'))\n",
    "model_4.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Activation('elu'))\n",
    "model_4.add(MaxPooling3D(pool_size=(2,2,1)))\n",
    "model_4.add(Dropout(0.25))\n",
    "\n",
    "model_4.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Activation('elu'))\n",
    "model_4.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model_4.add(Dropout(0.25))\n",
    "\n",
    "model_4.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Activation('elu'))\n",
    "model_4.add(MaxPooling3D(pool_size=(2,2,1)))\n",
    "model_4.add(Dropout(0.25))\n",
    "\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Dense(1024, activation='elu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Dense(512, activation='elu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_11 (Conv3D)           (None, 18, 84, 84, 32)    2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 18, 84, 84, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 18, 84, 84, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 18, 84, 84, 64)    55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 18, 84, 84, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 18, 84, 84, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 9, 42, 84, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 9, 42, 84, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 9, 42, 84, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 9, 42, 84, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 9, 42, 84, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 4, 21, 42, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4, 21, 42, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 4, 21, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              220201984 \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 221,895,557\n",
      "Trainable params: 221,894,597\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_4.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 5.2266 - categorical_accuracy: 0.1900 - val_loss: 1.6434 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.64344, saving model to model_init_2021-10-2714_06_11.512848\\model-00001-5.22657-0.19005-1.64344-0.23000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 4.9184 - categorical_accuracy: 0.2278 - val_loss: 1.8477 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.64344\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 4.4334 - categorical_accuracy: 0.2112 - val_loss: 2.2449 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.64344\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.9639 - categorical_accuracy: 0.2474 - val_loss: 2.6584 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.64344\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.8033 - categorical_accuracy: 0.2519 - val_loss: 3.1909 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.64344\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 3.3865 - categorical_accuracy: 0.2941 - val_loss: 3.8172 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.64344\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.2943 - categorical_accuracy: 0.2836 - val_loss: 4.1777 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.64344\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 3.4681 - categorical_accuracy: 0.2790 - val_loss: 4.2943 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.64344\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.3124 - categorical_accuracy: 0.2911 - val_loss: 4.8655 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.64344\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.8792 - categorical_accuracy: 0.3183 - val_loss: 4.9316 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.64344\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.9127 - categorical_accuracy: 0.2896 - val_loss: 5.1552 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.64344\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.7658 - categorical_accuracy: 0.3333 - val_loss: 5.4681 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.64344\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.8621 - categorical_accuracy: 0.3032 - val_loss: 5.1840 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.64344\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.8333 - categorical_accuracy: 0.3379 - val_loss: 5.2721 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.64344\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.7263 - categorical_accuracy: 0.3167 - val_loss: 5.3967 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.64344\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.7040 - categorical_accuracy: 0.3409 - val_loss: 5.0666 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.64344\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.5983 - categorical_accuracy: 0.3439 - val_loss: 4.9248 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.64344\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.4042 - categorical_accuracy: 0.3454 - val_loss: 4.8854 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.64344\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.4897 - categorical_accuracy: 0.3590 - val_loss: 4.8511 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.64344\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.4163 - categorical_accuracy: 0.3620 - val_loss: 4.6151 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.64344\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.5173 - categorical_accuracy: 0.3861 - val_loss: 4.1279 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.64344\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.3801 - categorical_accuracy: 0.3756 - val_loss: 4.4335 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.64344\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.3576 - categorical_accuracy: 0.3997 - val_loss: 3.9690 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.64344\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.2936 - categorical_accuracy: 0.3891 - val_loss: 3.6240 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.64344\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.3805 - categorical_accuracy: 0.3605 - val_loss: 3.6146 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.64344\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.2317 - categorical_accuracy: 0.3846 - val_loss: 3.4524 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.64344\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.2403 - categorical_accuracy: 0.3952 - val_loss: 3.1273 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.64344\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.2203 - categorical_accuracy: 0.4118 - val_loss: 3.2832 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.64344\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.1345 - categorical_accuracy: 0.3982 - val_loss: 2.8952 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.64344\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.0784 - categorical_accuracy: 0.4253 - val_loss: 2.8368 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.64344\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.0787 - categorical_accuracy: 0.4012 - val_loss: 2.7391 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.64344\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.1099 - categorical_accuracy: 0.4253 - val_loss: 2.6474 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.64344\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.0009 - categorical_accuracy: 0.4268 - val_loss: 2.3697 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.64344\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.0977 - categorical_accuracy: 0.4193 - val_loss: 2.5490 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.64344\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.0232 - categorical_accuracy: 0.4314 - val_loss: 2.5931 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.64344\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.0279 - categorical_accuracy: 0.4178 - val_loss: 2.0826 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.64344\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.9702 - categorical_accuracy: 0.4404 - val_loss: 2.1855 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.64344\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.0096 - categorical_accuracy: 0.4284 - val_loss: 2.2171 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.64344\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.0520 - categorical_accuracy: 0.4253 - val_loss: 2.1179 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.64344\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.0151 - categorical_accuracy: 0.4495 - val_loss: 2.5359 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.64344\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.9440 - categorical_accuracy: 0.4344 - val_loss: 2.2159 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.64344\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.9613 - categorical_accuracy: 0.4404 - val_loss: 2.1830 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.64344\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7923 - categorical_accuracy: 0.4766 - val_loss: 2.1481 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.64344\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.9117 - categorical_accuracy: 0.4329 - val_loss: 2.3886 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.64344\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7003 - categorical_accuracy: 0.5068 - val_loss: 2.2299 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.64344\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.9308 - categorical_accuracy: 0.4344 - val_loss: 2.2538 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.64344\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.8769 - categorical_accuracy: 0.4555 - val_loss: 2.2344 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.64344\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.8071 - categorical_accuracy: 0.4751 - val_loss: 2.1201 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.64344\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.8552 - categorical_accuracy: 0.4661 - val_loss: 2.4133 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.64344\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.7940 - categorical_accuracy: 0.4510 - val_loss: 2.2916 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.64344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bcbb6d1220>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although, the difference between categorical accuracy and validation accuracy is not much, overall performance of\n",
    "# model 4 is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running model 4 with 'relu' as activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model_5 = Sequential()\n",
    "\n",
    "model_5.add(Conv3D(32, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(MaxPooling3D(pool_size=(2,2,1)))\n",
    "model_5.add(Dropout(0.25))\n",
    "\n",
    "model_5.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model_5.add(Dropout(0.25))\n",
    "\n",
    "model_5.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(MaxPooling3D(pool_size=(2,2,1)))\n",
    "model_5.add(Dropout(0.25))\n",
    "\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(1024, activation='relu'))\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(512, activation='relu'))\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_15 (Conv3D)           (None, 18, 84, 84, 32)    2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 18, 84, 84, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 18, 84, 84, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 18, 84, 84, 64)    55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 18, 84, 84, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 18, 84, 84, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 9, 42, 84, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 9, 42, 84, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 9, 42, 84, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 9, 42, 84, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 9, 42, 84, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 4, 21, 42, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 4, 21, 42, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 4, 21, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              220201984 \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 221,895,557\n",
      "Trainable params: 221,894,597\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_5.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 5.0641 - categorical_accuracy: 0.1946 - val_loss: 1.6071 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60713, saving model to model_init_2021-10-2714_06_11.512848\\model-00001-5.06414-0.19457-1.60713-0.26000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 4.3366 - categorical_accuracy: 0.1946 - val_loss: 1.6149 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.60713\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.1028 - categorical_accuracy: 0.1991 - val_loss: 1.6387 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.60713\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 3.6478 - categorical_accuracy: 0.2066 - val_loss: 1.6696 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.60713\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 3.4044 - categorical_accuracy: 0.2398 - val_loss: 1.6843 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.60713\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 3.3728 - categorical_accuracy: 0.2187 - val_loss: 1.8097 - val_categorical_accuracy: 0.1200\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.60713\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.2328 - categorical_accuracy: 0.2247 - val_loss: 1.7169 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.60713\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 3.0046 - categorical_accuracy: 0.2459 - val_loss: 1.7545 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.60713\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.9445 - categorical_accuracy: 0.2413 - val_loss: 1.7674 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.60713\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.7652 - categorical_accuracy: 0.2368 - val_loss: 1.7991 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.60713\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.6839 - categorical_accuracy: 0.2655 - val_loss: 1.7879 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.60713\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.5593 - categorical_accuracy: 0.2730 - val_loss: 1.7802 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.60713\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.7218 - categorical_accuracy: 0.2247 - val_loss: 1.7908 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.60713\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.3989 - categorical_accuracy: 0.2821 - val_loss: 1.8399 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.60713\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 2.4562 - categorical_accuracy: 0.2670 - val_loss: 1.7770 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.60713\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 2.3057 - categorical_accuracy: 0.2489 - val_loss: 1.8003 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.60713\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.2108 - categorical_accuracy: 0.2866 - val_loss: 1.8065 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.60713\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.3221 - categorical_accuracy: 0.2715 - val_loss: 1.7988 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.60713\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 2.1029 - categorical_accuracy: 0.2760 - val_loss: 1.8291 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.60713\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.1657 - categorical_accuracy: 0.2549 - val_loss: 1.7854 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.60713\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.9900 - categorical_accuracy: 0.3092 - val_loss: 1.7825 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.60713\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.1006 - categorical_accuracy: 0.2881 - val_loss: 1.7639 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.60713\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.0243 - categorical_accuracy: 0.2971 - val_loss: 1.7102 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.60713\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.0681 - categorical_accuracy: 0.2624 - val_loss: 1.7362 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.60713\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.9911 - categorical_accuracy: 0.2941 - val_loss: 1.7230 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.60713\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 2.0413 - categorical_accuracy: 0.2896 - val_loss: 1.6645 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.60713\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.9651 - categorical_accuracy: 0.2881 - val_loss: 1.6716 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.60713\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.0259 - categorical_accuracy: 0.2790 - val_loss: 1.6485 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.60713\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.9779 - categorical_accuracy: 0.2851 - val_loss: 1.6293 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.60713\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.9442 - categorical_accuracy: 0.3122 - val_loss: 1.6659 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.60713\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.8671 - categorical_accuracy: 0.3167 - val_loss: 1.5998 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.60713 to 1.59976, saving model to model_init_2021-10-2714_06_11.512848\\model-00031-1.86712-0.31674-1.59976-0.22000.h5\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.8711 - categorical_accuracy: 0.3122 - val_loss: 1.5996 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.59976 to 1.59964, saving model to model_init_2021-10-2714_06_11.512848\\model-00032-1.87112-0.31222-1.59964-0.18000.h5\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.8447 - categorical_accuracy: 0.2971 - val_loss: 1.5781 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.59964 to 1.57814, saving model to model_init_2021-10-2714_06_11.512848\\model-00033-1.84472-0.29713-1.57814-0.21000.h5\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.8417 - categorical_accuracy: 0.3137 - val_loss: 1.5846 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.57814\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.8175 - categorical_accuracy: 0.3062 - val_loss: 1.5733 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.57814 to 1.57327, saving model to model_init_2021-10-2714_06_11.512848\\model-00035-1.81748-0.30618-1.57327-0.23000.h5\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.8790 - categorical_accuracy: 0.2821 - val_loss: 1.5474 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.57327 to 1.54745, saving model to model_init_2021-10-2714_06_11.512848\\model-00036-1.87898-0.28205-1.54745-0.23000.h5\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.8115 - categorical_accuracy: 0.3047 - val_loss: 1.5465 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.54745 to 1.54649, saving model to model_init_2021-10-2714_06_11.512848\\model-00037-1.81147-0.30468-1.54649-0.26000.h5\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.7577 - categorical_accuracy: 0.3032 - val_loss: 1.5177 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.54649 to 1.51772, saving model to model_init_2021-10-2714_06_11.512848\\model-00038-1.75773-0.30317-1.51772-0.23000.h5\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.8042 - categorical_accuracy: 0.3092 - val_loss: 1.5258 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.51772\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.7604 - categorical_accuracy: 0.2836 - val_loss: 1.5387 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.51772\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.7249 - categorical_accuracy: 0.3243 - val_loss: 1.5384 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.51772\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6627 - categorical_accuracy: 0.3333 - val_loss: 1.5248 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.51772\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.7498 - categorical_accuracy: 0.3077 - val_loss: 1.5715 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.51772\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.7269 - categorical_accuracy: 0.3077 - val_loss: 1.5310 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.51772\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.7322 - categorical_accuracy: 0.3107 - val_loss: 1.5348 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.51772\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.7563 - categorical_accuracy: 0.3137 - val_loss: 1.5144 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.51772 to 1.51437, saving model to model_init_2021-10-2714_06_11.512848\\model-00046-1.75628-0.31373-1.51437-0.23000.h5\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.7351 - categorical_accuracy: 0.3122 - val_loss: 1.5604 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.51437\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6304 - categorical_accuracy: 0.3394 - val_loss: 1.5382 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.51437\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.6873 - categorical_accuracy: 0.3107 - val_loss: 1.5324 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.51437\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.6184 - categorical_accuracy: 0.3695 - val_loss: 1.5264 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.51437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bcbb925820>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that the performance of 'elu' activation on the same model is much better than the 'relu' activation --> on the\n",
    "# given data (After 50 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 25% dropout after the 3rd MaxPool layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "#write your model here\n",
    "model_6 = Sequential()\n",
    "\n",
    "model_6.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Activation('elu'))\n",
    "model_6.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
    "\n",
    "model_6.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Activation('elu'))\n",
    "model_6.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n",
    "\n",
    "model_6.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Activation('elu'))\n",
    "model_6.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
    "model_6.add(Dropout(0.25))\n",
    "\n",
    "model_6.add(Flatten())\n",
    "model_6.add(Dropout(0.5))\n",
    "model_6.add(Dense(512, activation='elu'))\n",
    "model_6.add(Dropout(0.5))\n",
    "model_6.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 18, 84, 84, 64)    5248      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 18, 84, 84, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 18, 84, 84, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 9, 42, 84, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 9, 42, 84, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9, 42, 84, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9, 42, 84, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 4, 21, 42, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 21, 42, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 21, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               110100992 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 111,216,901\n",
      "Trainable params: 111,216,005\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "optimiser = keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.7, nesterov=True) #write your optimizer\n",
    "\n",
    "model_6.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_6.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  C:\\Users\\Amit\\Documents\\Academics\\upGrad\\Deep Learning\\Project_data\\train ; batch size = 32\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - ETA: 0s - loss: 9.4492 - categorical_accuracy: 0.2821Source path =  C:\\Users\\Amit\\Documents\\Academics\\upGrad\\Deep Learning\\Project_data\\val ; batch size = 32\n",
      "21/21 [==============================] - 65s 3s/step - loss: 9.4492 - categorical_accuracy: 0.2821 - val_loss: 2.0736 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.07357, saving model to model_init_2021-10-2718_08_28.064000\\model-00001-9.44915-0.28205-2.07357-0.21000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7034 - categorical_accuracy: 0.4087 - val_loss: 2.2690 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.07357\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.3762 - categorical_accuracy: 0.5143 - val_loss: 3.6814 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.07357\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.2067 - categorical_accuracy: 0.5716 - val_loss: 5.0904 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.07357\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0996 - categorical_accuracy: 0.5913 - val_loss: 5.9798 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.07357\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.9581 - categorical_accuracy: 0.6471 - val_loss: 6.8207 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.07357\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.8133 - categorical_accuracy: 0.6968 - val_loss: 7.8240 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.07357\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.8287 - categorical_accuracy: 0.6727 - val_loss: 8.1053 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.07357\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.7558 - categorical_accuracy: 0.7225 - val_loss: 8.2354 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.07357\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.7326 - categorical_accuracy: 0.7285 - val_loss: 8.5089 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.07357\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.7185 - categorical_accuracy: 0.7270 - val_loss: 8.1617 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.07357\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 0.6795 - categorical_accuracy: 0.7330 - val_loss: 7.9609 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.07357\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.6834 - categorical_accuracy: 0.7511 - val_loss: 7.6473 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.07357\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.7519 - categorical_accuracy: 0.7179 - val_loss: 7.5414 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.07357\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.7159 - categorical_accuracy: 0.7436 - val_loss: 6.7077 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.07357\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.7020 - categorical_accuracy: 0.7572 - val_loss: 6.4284 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.07357\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 0.6949 - categorical_accuracy: 0.7285 - val_loss: 5.7858 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.07357\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 0.7053 - categorical_accuracy: 0.7285 - val_loss: 5.3590 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.07357\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.6724 - categorical_accuracy: 0.7466 - val_loss: 4.8031 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.07357\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.6752 - categorical_accuracy: 0.7360 - val_loss: 4.1298 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.07357\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.6877 - categorical_accuracy: 0.7360 - val_loss: 3.5678 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.07357\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 0.7092 - categorical_accuracy: 0.7406 - val_loss: 2.8609 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.07357\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.6640 - categorical_accuracy: 0.7557 - val_loss: 2.5539 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.07357\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.6763 - categorical_accuracy: 0.7541 - val_loss: 2.1807 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.07357\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.7042 - categorical_accuracy: 0.7315 - val_loss: 1.8565 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.07357 to 1.85654, saving model to model_init_2021-10-2718_08_28.064000\\model-00025-0.70424-0.73152-1.85654-0.50000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.6848 - categorical_accuracy: 0.7421 - val_loss: 1.7036 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.85654 to 1.70363, saving model to model_init_2021-10-2718_08_28.064000\\model-00026-0.68479-0.74208-1.70363-0.50000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 0.6674 - categorical_accuracy: 0.7391 - val_loss: 1.4433 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.70363 to 1.44334, saving model to model_init_2021-10-2718_08_28.064000\\model-00027-0.66745-0.73906-1.44334-0.59000.h5\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.6498 - categorical_accuracy: 0.7587 - val_loss: 1.2350 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.44334 to 1.23501, saving model to model_init_2021-10-2718_08_28.064000\\model-00028-0.64981-0.75867-1.23501-0.61000.h5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.6502 - categorical_accuracy: 0.7587 - val_loss: 1.1688 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.23501 to 1.16882, saving model to model_init_2021-10-2718_08_28.064000\\model-00029-0.65018-0.75867-1.16882-0.65000.h5\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.6359 - categorical_accuracy: 0.7647 - val_loss: 1.0753 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.16882 to 1.07526, saving model to model_init_2021-10-2718_08_28.064000\\model-00030-0.63594-0.76471-1.07526-0.64000.h5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't decrement id ref count (unable to extend file properly)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    125\u001b[0m         not isinstance(model.optimizer, optimizer_v1.TFOptimizer)):\n\u001b[1;32m--> 126\u001b[1;33m       \u001b[0msave_optimizer_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_optimizer_weights_to_hdf5_group\u001b[1;34m(hdf5_group, optimizer)\u001b[0m\n\u001b[0;32m    599\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[0mparam_dset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, args, val)\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.write\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.dset_rw\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Can't write data (file write failed: time = Wed Oct 27 18:36:07 2021\n, filename = 'model_init_2021-10-2718_08_28.064000\\model-00030-0.63594-0.76471-1.07526-0.64000.h5', file descriptor = 4, errno = 28, error message = 'No space left on device', buf = 0000017B9E67C040, total write size = 440401920, bytes this sub-write = 440401920, bytes actually written = 18446744073709551615, offset = 449395408)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ce5f873b37a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model_6.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1228\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1230\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1231\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[0;32m   1420\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[0;32m   1421\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1422\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1423\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1424\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   2143\u001b[0m     \"\"\"\n\u001b[0;32m   2144\u001b[0m     \u001b[1;31m# pylint: enable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2145\u001b[1;33m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[0;32m   2146\u001b[0m                     signatures, options, save_traces)\n\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    143\u001b[0m           \u001b[1;34m'to the Tensorflow SavedModel format (by setting save_format=\"tf\") '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m--> 145\u001b[1;33m     hdf5_format.save_model_to_hdf5(\n\u001b[0m\u001b[0;32m    146\u001b[0m         model, filepath, overwrite, include_optimizer)\n\u001b[0;32m    147\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    129\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m       \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    455\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mid_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m                     \u001b[1;32mwhile\u001b[0m \u001b[0mid_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m                         \u001b[0mh5i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdec_ref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5i.pyx\u001b[0m in \u001b[0;36mh5py.h5i.dec_ref\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't decrement id ref count (unable to extend file properly)"
     ]
    }
   ],
   "source": [
    "model_6.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got runtime error after the 30th epoch of model 6 as the .h5 files reached 109 GB and filled up the hard disk\n",
    "# We would not be re-running model 6 again as it was not giving good results (difference between the train and val\n",
    "# accuracies was consistently high from epoch 1 to epoch 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using model 6 and adding 25% dropouts after the 2nd MaxPool layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model_7 = Sequential()\n",
    "\n",
    "model_7.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(Activation('elu'))\n",
    "model_7.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
    "\n",
    "\n",
    "model_7.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(Activation('elu'))\n",
    "model_7.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n",
    "model_7.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model_7.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(Activation('elu'))\n",
    "model_7.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
    "model_7.add(Dropout(0.25))\n",
    "\n",
    "model_7.add(Flatten())\n",
    "model_7.add(Dropout(0.5))\n",
    "model_7.add(Dense(512, activation='elu'))\n",
    "model_7.add(Dropout(0.5))\n",
    "model_7.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_3 (Conv3D)            (None, 18, 84, 84, 64)    5248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 18, 84, 84, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 18, 84, 84, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 9, 42, 84, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 9, 42, 84, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 9, 42, 84, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 9, 42, 84, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 4, 21, 42, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 21, 42, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 21, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               110100992 \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 111,216,901\n",
      "Trainable params: 111,216,005\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_7.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_7.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 3.6757 - categorical_accuracy: 0.2443 - val_loss: 1.7234 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.62567\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 3.1555 - categorical_accuracy: 0.2881 - val_loss: 1.9417 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.62567\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.7861 - categorical_accuracy: 0.3228 - val_loss: 2.1360 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.62567\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.5230 - categorical_accuracy: 0.3756 - val_loss: 2.8042 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.62567\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.5025 - categorical_accuracy: 0.3484 - val_loss: 3.0570 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.62567\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 2.5133 - categorical_accuracy: 0.3650 - val_loss: 3.2493 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.62567\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.4152 - categorical_accuracy: 0.3786 - val_loss: 3.3276 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.62567\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.2436 - categorical_accuracy: 0.3801 - val_loss: 4.1745 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.62567\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 2.0116 - categorical_accuracy: 0.4253 - val_loss: 3.9788 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.62567\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.9875 - categorical_accuracy: 0.4223 - val_loss: 4.1895 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.62567\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.9379 - categorical_accuracy: 0.4133 - val_loss: 4.1808 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.62567\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.8616 - categorical_accuracy: 0.4404 - val_loss: 4.2688 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.62567\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.8512 - categorical_accuracy: 0.4691 - val_loss: 4.0960 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.62567\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7535 - categorical_accuracy: 0.4465 - val_loss: 4.1354 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.62567\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7613 - categorical_accuracy: 0.4842 - val_loss: 3.8228 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.62567\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6625 - categorical_accuracy: 0.4887 - val_loss: 3.9311 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.62567\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6634 - categorical_accuracy: 0.4842 - val_loss: 3.3894 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.62567\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6337 - categorical_accuracy: 0.4932 - val_loss: 3.2569 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.62567\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.5406 - categorical_accuracy: 0.4962 - val_loss: 3.0048 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.62567\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.3987 - categorical_accuracy: 0.5490 - val_loss: 2.7280 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.62567\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.6648 - categorical_accuracy: 0.4811 - val_loss: 2.5939 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.62567\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.4883 - categorical_accuracy: 0.5264 - val_loss: 2.2126 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.62567\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.4623 - categorical_accuracy: 0.5219 - val_loss: 2.0638 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.62567\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.5373 - categorical_accuracy: 0.5053 - val_loss: 1.8522 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.62567\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.3563 - categorical_accuracy: 0.5445 - val_loss: 1.6668 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.62567\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.3676 - categorical_accuracy: 0.5490 - val_loss: 1.4648 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.62567 to 1.46484, saving model to model_init_2021-10-2718_08_28.064000\\model-00026-1.36763-0.54902-1.46484-0.51000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.4379 - categorical_accuracy: 0.5490 - val_loss: 1.4811 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.46484\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.2965 - categorical_accuracy: 0.5626 - val_loss: 1.3422 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.46484 to 1.34224, saving model to model_init_2021-10-2718_08_28.064000\\model-00028-1.29649-0.56259-1.34224-0.54000.h5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.3562 - categorical_accuracy: 0.5656 - val_loss: 1.3130 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.34224 to 1.31305, saving model to model_init_2021-10-2718_08_28.064000\\model-00029-1.35616-0.56561-1.31305-0.55000.h5\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.4500 - categorical_accuracy: 0.5400 - val_loss: 1.2170 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.31305 to 1.21700, saving model to model_init_2021-10-2718_08_28.064000\\model-00030-1.44997-0.53997-1.21700-0.56000.h5\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.2109 - categorical_accuracy: 0.5792 - val_loss: 0.9741 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.21700 to 0.97409, saving model to model_init_2021-10-2718_08_28.064000\\model-00031-1.21087-0.57919-0.97409-0.63000.h5\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.2896 - categorical_accuracy: 0.5732 - val_loss: 1.1153 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.97409\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.2481 - categorical_accuracy: 0.5475 - val_loss: 1.0205 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.97409\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.3065 - categorical_accuracy: 0.5747 - val_loss: 1.0750 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.97409\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.3125 - categorical_accuracy: 0.5505 - val_loss: 1.1721 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.97409\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.2700 - categorical_accuracy: 0.5581 - val_loss: 0.9271 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.97409 to 0.92713, saving model to model_init_2021-10-2718_08_28.064000\\model-00036-1.27003-0.55807-0.92713-0.60000.h5\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.2999 - categorical_accuracy: 0.5837 - val_loss: 0.9297 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.92713\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.2406 - categorical_accuracy: 0.5762 - val_loss: 0.9904 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.92713\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.1912 - categorical_accuracy: 0.5913 - val_loss: 0.8794 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.92713 to 0.87943, saving model to model_init_2021-10-2718_08_28.064000\\model-00039-1.19123-0.59125-0.87943-0.60000.h5\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.1689 - categorical_accuracy: 0.5973 - val_loss: 1.1192 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.87943\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.0213 - categorical_accuracy: 0.6380 - val_loss: 0.9213 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.87943\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.1407 - categorical_accuracy: 0.6078 - val_loss: 0.9477 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.87943\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.1857 - categorical_accuracy: 0.5867 - val_loss: 0.8671 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.87943 to 0.86712, saving model to model_init_2021-10-2718_08_28.064000\\model-00043-1.18569-0.58673-0.86712-0.59000.h5\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.1277 - categorical_accuracy: 0.6169 - val_loss: 0.9471 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.86712\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.1501 - categorical_accuracy: 0.6078 - val_loss: 0.8750 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.86712\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0801 - categorical_accuracy: 0.6305 - val_loss: 0.9182 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.86712\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.1787 - categorical_accuracy: 0.6048 - val_loss: 0.9763 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.86712\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0923 - categorical_accuracy: 0.6154 - val_loss: 0.7408 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.86712 to 0.74084, saving model to model_init_2021-10-2718_08_28.064000\\model-00048-1.09226-0.61538-0.74084-0.68000.h5\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.0854 - categorical_accuracy: 0.6305 - val_loss: 0.8210 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.74084\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0497 - categorical_accuracy: 0.6290 - val_loss: 0.8450 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.74084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ac02f9430>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 7 is slightly underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model_8 = Sequential()\n",
    "\n",
    "model_8.add(Conv3D(32, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "# model_8.add(BatchNormalization())\n",
    "model_8.add(Activation('relu'))\n",
    "model_8.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "# model_8.add(BatchNormalization())\n",
    "model_8.add(Activation('relu'))\n",
    "model_8.add(MaxPooling3D(pool_size=(2,2,1)))\n",
    "model_8.add(Dropout(0.25))\n",
    "\n",
    "model_8.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "# model_8.add(BatchNormalization())\n",
    "model_8.add(Activation('relu'))\n",
    "model_8.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model_8.add(Dropout(0.25))\n",
    "\n",
    "model_8.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "# model_8.add(BatchNormalization())\n",
    "model_8.add(Activation('relu'))\n",
    "model_8.add(MaxPooling3D(pool_size=(2,2,1)))\n",
    "model_8.add(Dropout(0.25))\n",
    "\n",
    "model_8.add(Flatten())\n",
    "model_8.add(Dropout(0.5))\n",
    "model_8.add(Dense(1024, activation='relu'))\n",
    "model_8.add(Dropout(0.5))\n",
    "model_8.add(Dense(512, activation='relu'))\n",
    "model_8.add(Dropout(0.5))\n",
    "model_8.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_6 (Conv3D)            (None, 18, 84, 84, 32)    2624      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 18, 84, 84, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 18, 84, 84, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 18, 84, 84, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 9, 42, 84, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 9, 42, 84, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 9, 42, 84, 128)    221312    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 9, 42, 84, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 4, 21, 42, 256)    884992    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4, 21, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              220201984 \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 221,893,637\n",
      "Trainable params: 221,893,637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_8.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_8.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.6353 - categorical_accuracy: 0.2142 - val_loss: 1.6145 - val_categorical_accuracy: 0.1200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61447, saving model to model_init_2021-10-2718_08_28.064000\\model-00001-1.63531-0.21418-1.61447-0.12000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6436 - categorical_accuracy: 0.1991 - val_loss: 1.6083 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.61447 to 1.60834, saving model to model_init_2021-10-2718_08_28.064000\\model-00002-1.64358-0.19910-1.60834-0.15000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.6569 - categorical_accuracy: 0.1840 - val_loss: 1.6112 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.60834\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6490 - categorical_accuracy: 0.1644 - val_loss: 1.6106 - val_categorical_accuracy: 0.1400\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.60834\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6379 - categorical_accuracy: 0.2021 - val_loss: 1.6110 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.60834\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.6262 - categorical_accuracy: 0.2187 - val_loss: 1.6090 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.60834\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6342 - categorical_accuracy: 0.1780 - val_loss: 1.6098 - val_categorical_accuracy: 0.1300\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.60834\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6229 - categorical_accuracy: 0.1870 - val_loss: 1.6094 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.60834\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6364 - categorical_accuracy: 0.2142 - val_loss: 1.6100 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.60834\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6084 - categorical_accuracy: 0.2428 - val_loss: 1.6086 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.60834\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.6366 - categorical_accuracy: 0.1900 - val_loss: 1.6083 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.60834 to 1.60829, saving model to model_init_2021-10-2718_08_28.064000\\model-00011-1.63661-0.19005-1.60829-0.19000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.6240 - categorical_accuracy: 0.1976 - val_loss: 1.6085 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.60829\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.6201 - categorical_accuracy: 0.2247 - val_loss: 1.6085 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.60829\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.6223 - categorical_accuracy: 0.1931 - val_loss: 1.6061 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.60829 to 1.60614, saving model to model_init_2021-10-2718_08_28.064000\\model-00014-1.62226-0.19306-1.60614-0.23000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6336 - categorical_accuracy: 0.2097 - val_loss: 1.6076 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.60614\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.6307 - categorical_accuracy: 0.2081 - val_loss: 1.6076 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.60614\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.6257 - categorical_accuracy: 0.1976 - val_loss: 1.6057 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.60614 to 1.60565, saving model to model_init_2021-10-2718_08_28.064000\\model-00017-1.62573-0.19759-1.60565-0.25000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6332 - categorical_accuracy: 0.1825 - val_loss: 1.6079 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.60565\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.6335 - categorical_accuracy: 0.1810 - val_loss: 1.6067 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.60565\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6152 - categorical_accuracy: 0.2006 - val_loss: 1.6069 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.60565\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6246 - categorical_accuracy: 0.1885 - val_loss: 1.6071 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.60565\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6287 - categorical_accuracy: 0.1900 - val_loss: 1.6064 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.60565\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.6288 - categorical_accuracy: 0.1916 - val_loss: 1.6068 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.60565\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6238 - categorical_accuracy: 0.2066 - val_loss: 1.6063 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.60565\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.6304 - categorical_accuracy: 0.1931 - val_loss: 1.6039 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.60565 to 1.60395, saving model to model_init_2021-10-2718_08_28.064000\\model-00025-1.63043-0.19306-1.60395-0.22000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6180 - categorical_accuracy: 0.2066 - val_loss: 1.6028 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.60395 to 1.60276, saving model to model_init_2021-10-2718_08_28.064000\\model-00026-1.61803-0.20664-1.60276-0.26000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6236 - categorical_accuracy: 0.2081 - val_loss: 1.6062 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.60276\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6229 - categorical_accuracy: 0.2262 - val_loss: 1.6059 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.60276\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.6350 - categorical_accuracy: 0.1991 - val_loss: 1.6052 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.60276\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.6179 - categorical_accuracy: 0.1961 - val_loss: 1.6079 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.60276\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.6162 - categorical_accuracy: 0.2232 - val_loss: 1.6053 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.60276\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.6137 - categorical_accuracy: 0.2247 - val_loss: 1.6056 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.60276\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.6185 - categorical_accuracy: 0.1976 - val_loss: 1.6061 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.60276\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.6102 - categorical_accuracy: 0.2202 - val_loss: 1.6040 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.60276\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6188 - categorical_accuracy: 0.2097 - val_loss: 1.6061 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.60276\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6165 - categorical_accuracy: 0.2217 - val_loss: 1.6053 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.60276\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6184 - categorical_accuracy: 0.1900 - val_loss: 1.6073 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.60276\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.6226 - categorical_accuracy: 0.1946 - val_loss: 1.6049 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.60276\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.6345 - categorical_accuracy: 0.1870 - val_loss: 1.6051 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.60276\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6199 - categorical_accuracy: 0.1795 - val_loss: 1.6048 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.60276\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6148 - categorical_accuracy: 0.2051 - val_loss: 1.6067 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.60276\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.6351 - categorical_accuracy: 0.1765 - val_loss: 1.6083 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.60276\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.6210 - categorical_accuracy: 0.2202 - val_loss: 1.6042 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.60276\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6275 - categorical_accuracy: 0.1855 - val_loss: 1.6046 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.60276\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6071 - categorical_accuracy: 0.2202 - val_loss: 1.6018 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.60276 to 1.60183, saving model to model_init_2021-10-2718_08_28.064000\\model-00045-1.60714-0.22021-1.60183-0.20000.h5\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.6241 - categorical_accuracy: 0.2142 - val_loss: 1.6071 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.60183\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.6201 - categorical_accuracy: 0.1870 - val_loss: 1.6045 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.60183\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.6140 - categorical_accuracy: 0.2202 - val_loss: 1.6042 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.60183\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6278 - categorical_accuracy: 0.2006 - val_loss: 1.6032 - val_categorical_accuracy: 0.1400\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.60183\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6278 - categorical_accuracy: 0.1931 - val_loss: 1.6015 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.60183 to 1.60153, saving model to model_init_2021-10-2718_08_28.064000\\model-00050-1.62775-0.19306-1.60153-0.23000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ac0312f10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the results of models 5 and 8 after 50 epochs:\n",
    "\n",
    "# Model 5:\n",
    "# loss: 1.6184 - categorical_accuracy: 0.3695 - val_loss: 1.5264 - val_categorical_accuracy: 0.2300\n",
    "\n",
    "# Model 8:\n",
    "#  loss: 1.6278 - categorical_accuracy: 0.1931 - val_loss: 1.6015 - val_categorical_accuracy: 0.2300\n",
    "\n",
    "# We can see that removing batch normalization has adversely affected the categorical accuracy and validation loss.\n",
    "# Moreover, both of these models (model 5 and model 8) are pretty much useless for the data that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model_9 = Sequential()\n",
    "\n",
    "model_9.add(Conv3D(32, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_9.add(BatchNormalization())\n",
    "model_9.add(Activation('relu'))\n",
    "model_9.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "# model_9.add(Dropout(0.25))\n",
    "\n",
    "model_9.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_9.add(BatchNormalization())\n",
    "model_9.add(Activation('relu'))\n",
    "model_9.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "# model_9.add(Dropout(0.25))\n",
    "\n",
    "model_9.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_9.add(BatchNormalization())\n",
    "model_9.add(Activation('relu'))\n",
    "model_9.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "# model_9.add(Dropout(0.25))\n",
    "\n",
    "model_9.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_9.add(BatchNormalization())\n",
    "model_9.add(Activation('relu'))\n",
    "model_9.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "# model_9.add(Dropout(0.25))\n",
    "\n",
    "model_9.add(Flatten())\n",
    "model_9.add(Dropout(0.5))\n",
    "model_9.add(Dense(1024, activation='relu'))\n",
    "model_9.add(Dropout(0.5))\n",
    "model_9.add(Dense(512, activation='relu'))\n",
    "model_9.add(Dropout(0.5))\n",
    "model_9.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_10 (Conv3D)           (None, 18, 84, 84, 32)    2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 18, 84, 84, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 18, 84, 84, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 9, 42, 42, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 9, 42, 42, 64)     55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 9, 42, 42, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 9, 42, 42, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 4, 21, 21, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 4, 21, 21, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 21, 21, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4, 21, 21, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 2, 10, 10, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 2, 10, 10, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2, 10, 10, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 2, 10, 10, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 1, 5, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              6554624   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 8,248,197\n",
      "Trainable params: 8,247,237\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_9.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_9.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 4.9019 - categorical_accuracy: 0.2262 - val_loss: 1.6140 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61395, saving model to model_init_2021-10-2718_08_28.064000\\model-00001-4.90189-0.22624-1.61395-0.23000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.8916 - categorical_accuracy: 0.1825 - val_loss: 1.6170 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.61395\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.9116 - categorical_accuracy: 0.1765 - val_loss: 1.6295 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.61395\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 4.3051 - categorical_accuracy: 0.2142 - val_loss: 1.6235 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.61395\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 4.3882 - categorical_accuracy: 0.1961 - val_loss: 1.6268 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.61395\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.1793 - categorical_accuracy: 0.2383 - val_loss: 1.6304 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.61395\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.4123 - categorical_accuracy: 0.2097 - val_loss: 1.6266 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.61395\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 4.0489 - categorical_accuracy: 0.2278 - val_loss: 1.6537 - val_categorical_accuracy: 0.1400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.61395\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 3.7806 - categorical_accuracy: 0.2293 - val_loss: 1.6424 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.61395\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.9900 - categorical_accuracy: 0.1931 - val_loss: 1.6447 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.61395\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 4.2088 - categorical_accuracy: 0.2036 - val_loss: 1.6475 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.61395\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.7373 - categorical_accuracy: 0.2278 - val_loss: 1.6586 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.61395\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 3.6141 - categorical_accuracy: 0.2640 - val_loss: 1.6430 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.61395\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 3.8175 - categorical_accuracy: 0.2353 - val_loss: 1.6619 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.61395\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 3.8912 - categorical_accuracy: 0.2006 - val_loss: 1.6540 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.61395\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.6478 - categorical_accuracy: 0.2368 - val_loss: 1.6437 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.61395\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 3.5296 - categorical_accuracy: 0.2428 - val_loss: 1.6848 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.61395\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.5814 - categorical_accuracy: 0.2534 - val_loss: 1.6610 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.61395\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.6855 - categorical_accuracy: 0.2564 - val_loss: 1.6241 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.61395\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.5489 - categorical_accuracy: 0.2232 - val_loss: 1.5618 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.61395 to 1.56182, saving model to model_init_2021-10-2718_08_28.064000\\model-00020-3.54893-0.22323-1.56182-0.26000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 3.5825 - categorical_accuracy: 0.2293 - val_loss: 1.6284 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.56182\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.4575 - categorical_accuracy: 0.2353 - val_loss: 1.6012 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.56182\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.4898 - categorical_accuracy: 0.2187 - val_loss: 1.5606 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.56182 to 1.56056, saving model to model_init_2021-10-2718_08_28.064000\\model-00023-3.48977-0.21870-1.56056-0.29000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 3.2960 - categorical_accuracy: 0.2519 - val_loss: 1.5596 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.56056 to 1.55956, saving model to model_init_2021-10-2718_08_28.064000\\model-00024-3.29599-0.25189-1.55956-0.26000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.4079 - categorical_accuracy: 0.2594 - val_loss: 1.5377 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.55956 to 1.53767, saving model to model_init_2021-10-2718_08_28.064000\\model-00025-3.40793-0.25943-1.53767-0.28000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 3.3772 - categorical_accuracy: 0.2594 - val_loss: 1.5269 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.53767 to 1.52693, saving model to model_init_2021-10-2718_08_28.064000\\model-00026-3.37716-0.25943-1.52693-0.27000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.4067 - categorical_accuracy: 0.2081 - val_loss: 1.5883 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.52693\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 3.2963 - categorical_accuracy: 0.2866 - val_loss: 1.4406 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.52693 to 1.44058, saving model to model_init_2021-10-2718_08_28.064000\\model-00028-3.29627-0.28658-1.44058-0.32000.h5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.3208 - categorical_accuracy: 0.2519 - val_loss: 1.4764 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.44058\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.2246 - categorical_accuracy: 0.2443 - val_loss: 1.4629 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.44058\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.2415 - categorical_accuracy: 0.2640 - val_loss: 1.4361 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.44058 to 1.43610, saving model to model_init_2021-10-2718_08_28.064000\\model-00031-3.24147-0.26395-1.43610-0.34000.h5\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 3.2104 - categorical_accuracy: 0.2715 - val_loss: 1.4210 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.43610 to 1.42101, saving model to model_init_2021-10-2718_08_28.064000\\model-00032-3.21039-0.27149-1.42101-0.32000.h5\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 3.1835 - categorical_accuracy: 0.2821 - val_loss: 1.4408 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.42101\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.0937 - categorical_accuracy: 0.2413 - val_loss: 1.4358 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.42101\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 3.0334 - categorical_accuracy: 0.2821 - val_loss: 1.3681 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.42101 to 1.36810, saving model to model_init_2021-10-2718_08_28.064000\\model-00035-3.03336-0.28205-1.36810-0.36000.h5\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.0132 - categorical_accuracy: 0.2624 - val_loss: 1.4329 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.36810\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 3.0607 - categorical_accuracy: 0.2624 - val_loss: 1.4252 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.36810\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.9263 - categorical_accuracy: 0.2896 - val_loss: 1.3934 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.36810\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.0653 - categorical_accuracy: 0.2760 - val_loss: 1.4304 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.36810\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.2203 - categorical_accuracy: 0.2564 - val_loss: 1.3748 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.36810\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 3.0528 - categorical_accuracy: 0.2594 - val_loss: 1.4100 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.36810\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.8038 - categorical_accuracy: 0.3047 - val_loss: 1.3932 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.36810\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 3.0532 - categorical_accuracy: 0.2775 - val_loss: 1.3986 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.36810\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 2.8891 - categorical_accuracy: 0.2594 - val_loss: 1.3690 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.36810\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 2.9394 - categorical_accuracy: 0.2700 - val_loss: 1.3918 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.36810\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.8994 - categorical_accuracy: 0.2866 - val_loss: 1.3802 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.36810\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.9138 - categorical_accuracy: 0.2474 - val_loss: 1.3500 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.36810 to 1.35002, saving model to model_init_2021-10-2718_08_28.064000\\model-00047-2.91377-0.24736-1.35002-0.44000.h5\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.8136 - categorical_accuracy: 0.3002 - val_loss: 1.3222 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.35002 to 1.32217, saving model to model_init_2021-10-2718_08_28.064000\\model-00048-2.81358-0.30015-1.32217-0.47000.h5\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 2.8709 - categorical_accuracy: 0.2851 - val_loss: 1.3134 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.32217 to 1.31338, saving model to model_init_2021-10-2718_08_28.064000\\model-00049-2.87088-0.28507-1.31338-0.49000.h5\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 2.6726 - categorical_accuracy: 0.3017 - val_loss: 1.3518 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.31338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ac189d5b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 9 is underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model_10 = Sequential()\n",
    "\n",
    "model_10.add(Conv3D(32, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "# model_10.add(BatchNormalization())\n",
    "model_10.add(Activation('relu'))\n",
    "model_10.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model_10.add(Dropout(0.25))\n",
    "\n",
    "model_10.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "# model_10.add(BatchNormalization())\n",
    "model_10.add(Activation('relu'))\n",
    "model_10.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model_10.add(Dropout(0.25))\n",
    "\n",
    "model_10.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "# model_10.add(BatchNormalization())\n",
    "model_10.add(Activation('relu'))\n",
    "model_10.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model_10.add(Dropout(0.25))\n",
    "\n",
    "model_10.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "# model_10.add(BatchNormalization())\n",
    "model_10.add(Activation('relu'))\n",
    "model_10.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model_10.add(Dropout(0.25))\n",
    "\n",
    "model_10.add(Flatten())\n",
    "model_10.add(Dropout(0.5))\n",
    "model_10.add(Dense(1024, activation='relu'))\n",
    "model_10.add(Dropout(0.5))\n",
    "model_10.add(Dense(512, activation='relu'))\n",
    "model_10.add(Dropout(0.5))\n",
    "model_10.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_14 (Conv3D)           (None, 18, 84, 84, 32)    2624      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 18, 84, 84, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 9, 42, 42, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 9, 42, 42, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 9, 42, 42, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 9, 42, 42, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 4, 21, 21, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 4, 21, 21, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 4, 21, 21, 128)    221312    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 4, 21, 21, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 2, 10, 10, 128)    0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2, 10, 10, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 2, 10, 10, 256)    884992    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 2, 10, 10, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 1, 5, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1, 5, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              6554624   \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 8,246,277\n",
      "Trainable params: 8,246,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_10.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_10.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.8074 - categorical_accuracy: 0.1765 - val_loss: 1.6108 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61079, saving model to model_init_2021-10-2718_08_28.064000\\model-00001-1.80741-0.17647-1.61079-0.26000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.7774 - categorical_accuracy: 0.2066 - val_loss: 1.6141 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.61079\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.7637 - categorical_accuracy: 0.2066 - val_loss: 1.6107 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.61079 to 1.61074, saving model to model_init_2021-10-2718_08_28.064000\\model-00003-1.76366-0.20664-1.61074-0.26000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7330 - categorical_accuracy: 0.2006 - val_loss: 1.6115 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.61074\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.7552 - categorical_accuracy: 0.1931 - val_loss: 1.6102 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.61074 to 1.61022, saving model to model_init_2021-10-2718_08_28.064000\\model-00005-1.75518-0.19306-1.61022-0.27000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7532 - categorical_accuracy: 0.1931 - val_loss: 1.6082 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.61022 to 1.60824, saving model to model_init_2021-10-2718_08_28.064000\\model-00006-1.75320-0.19306-1.60824-0.28000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.7083 - categorical_accuracy: 0.2172 - val_loss: 1.6110 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.60824\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7459 - categorical_accuracy: 0.1855 - val_loss: 1.6106 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.60824\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7059 - categorical_accuracy: 0.2157 - val_loss: 1.6092 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.60824\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6999 - categorical_accuracy: 0.2142 - val_loss: 1.6090 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.60824\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.7398 - categorical_accuracy: 0.2127 - val_loss: 1.6103 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.60824\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7265 - categorical_accuracy: 0.1961 - val_loss: 1.6100 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.60824\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7463 - categorical_accuracy: 0.1825 - val_loss: 1.6122 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.60824\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7182 - categorical_accuracy: 0.1840 - val_loss: 1.6089 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.60824\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.7415 - categorical_accuracy: 0.1825 - val_loss: 1.6103 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.60824\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7325 - categorical_accuracy: 0.1810 - val_loss: 1.6095 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.60824\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.7256 - categorical_accuracy: 0.1825 - val_loss: 1.6053 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.60824 to 1.60529, saving model to model_init_2021-10-2718_08_28.064000\\model-00017-1.72560-0.18250-1.60529-0.26000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.6977 - categorical_accuracy: 0.1946 - val_loss: 1.6083 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.60529\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.7256 - categorical_accuracy: 0.1554 - val_loss: 1.6100 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.60529\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7003 - categorical_accuracy: 0.1900 - val_loss: 1.6091 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.60529\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.7230 - categorical_accuracy: 0.1931 - val_loss: 1.6064 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.60529\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.7015 - categorical_accuracy: 0.2036 - val_loss: 1.6119 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.60529\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.7028 - categorical_accuracy: 0.2006 - val_loss: 1.6081 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.60529\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7189 - categorical_accuracy: 0.1900 - val_loss: 1.6088 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.60529\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.6968 - categorical_accuracy: 0.2157 - val_loss: 1.6075 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.60529\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.7166 - categorical_accuracy: 0.2021 - val_loss: 1.6103 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.60529\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.6909 - categorical_accuracy: 0.1991 - val_loss: 1.6091 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.60529\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.7091 - categorical_accuracy: 0.1840 - val_loss: 1.6085 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.60529\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6811 - categorical_accuracy: 0.1885 - val_loss: 1.6071 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.60529\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6522 - categorical_accuracy: 0.2172 - val_loss: 1.6089 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.60529\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.6896 - categorical_accuracy: 0.1780 - val_loss: 1.6087 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.60529\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.7033 - categorical_accuracy: 0.1976 - val_loss: 1.6083 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.60529\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.7238 - categorical_accuracy: 0.1719 - val_loss: 1.6073 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.60529\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6876 - categorical_accuracy: 0.1900 - val_loss: 1.6079 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.60529\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 47s 2s/step - loss: 1.6942 - categorical_accuracy: 0.1780 - val_loss: 1.6088 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.60529\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.6894 - categorical_accuracy: 0.1946 - val_loss: 1.6081 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.60529\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6833 - categorical_accuracy: 0.2127 - val_loss: 1.6062 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.60529\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.6832 - categorical_accuracy: 0.1976 - val_loss: 1.6092 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.60529\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.6774 - categorical_accuracy: 0.2308 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.60529\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6809 - categorical_accuracy: 0.1870 - val_loss: 1.6079 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.60529\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6856 - categorical_accuracy: 0.1885 - val_loss: 1.6070 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.60529\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6678 - categorical_accuracy: 0.1976 - val_loss: 1.6090 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.60529\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.6543 - categorical_accuracy: 0.2157 - val_loss: 1.6072 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.60529\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.6921 - categorical_accuracy: 0.1855 - val_loss: 1.6077 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.60529\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.6571 - categorical_accuracy: 0.2112 - val_loss: 1.6083 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.60529\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6887 - categorical_accuracy: 0.1825 - val_loss: 1.6065 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.60529\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 1.6915 - categorical_accuracy: 0.1855 - val_loss: 1.6076 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.60529\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.6908 - categorical_accuracy: 0.1855 - val_loss: 1.6076 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.60529\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6536 - categorical_accuracy: 0.2051 - val_loss: 1.6063 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.60529\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.6988 - categorical_accuracy: 0.1780 - val_loss: 1.6081 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.60529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17abe166760>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 10 also appears to be a bad model for the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model_11 = Sequential()\n",
    "\n",
    "model_11.add(Conv3D(32, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_11.add(BatchNormalization())\n",
    "model_11.add(Activation('relu'))\n",
    "model_11.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model_11.add(Dropout(0.25))\n",
    "\n",
    "model_11.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_11.add(BatchNormalization())\n",
    "model_11.add(Activation('relu'))\n",
    "model_11.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model_11.add(Dropout(0.25))\n",
    "\n",
    "model_11.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_11.add(BatchNormalization())\n",
    "model_11.add(Activation('relu'))\n",
    "model_11.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model_11.add(Dropout(0.25))\n",
    "\n",
    "model_11.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_11.add(BatchNormalization())\n",
    "model_11.add(Activation('relu'))\n",
    "model_11.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model_11.add(Dropout(0.25))\n",
    "\n",
    "model_11.add(Flatten())\n",
    "model_11.add(Dropout(0.5))\n",
    "model_11.add(Dense(1024, activation='relu'))\n",
    "model_11.add(Dropout(0.5))\n",
    "model_11.add(Dense(512, activation='relu'))\n",
    "model_11.add(Dropout(0.5))\n",
    "model_11.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_18 (Conv3D)           (None, 18, 84, 84, 32)    2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 18, 84, 84, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 18, 84, 84, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 9, 42, 42, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 9, 42, 42, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_19 (Conv3D)           (None, 9, 42, 42, 64)     55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 9, 42, 42, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 9, 42, 42, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 4, 21, 21, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 4, 21, 21, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_20 (Conv3D)           (None, 4, 21, 21, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 21, 21, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 4, 21, 21, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 2, 10, 10, 128)    0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 2, 10, 10, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_21 (Conv3D)           (None, 2, 10, 10, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 2, 10, 10, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 2, 10, 10, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_20 (MaxPooling (None, 1, 5, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1, 5, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              6554624   \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 8,248,197\n",
      "Trainable params: 8,247,237\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_11.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_11.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 5.6400 - categorical_accuracy: 0.1900 - val_loss: 1.6126 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61260, saving model to model_init_2021-10-2718_08_28.064000\\model-00001-5.64003-0.19005-1.61260-0.16000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 5.1649 - categorical_accuracy: 0.2006 - val_loss: 1.6143 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.61260\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 5.5630 - categorical_accuracy: 0.1780 - val_loss: 1.6178 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.61260\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 5.9188 - categorical_accuracy: 0.1735 - val_loss: 1.6259 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.61260\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 5.0604 - categorical_accuracy: 0.1991 - val_loss: 1.6229 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.61260\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 5.1745 - categorical_accuracy: 0.1976 - val_loss: 1.6253 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.61260\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 5.1619 - categorical_accuracy: 0.1991 - val_loss: 1.6246 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.61260\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 5.1886 - categorical_accuracy: 0.1961 - val_loss: 1.6219 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.61260\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 4.8536 - categorical_accuracy: 0.2006 - val_loss: 1.6318 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.61260\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 5.2514 - categorical_accuracy: 0.1765 - val_loss: 1.6316 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.61260\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 4.9271 - categorical_accuracy: 0.1916 - val_loss: 1.6364 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.61260\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 5.1378 - categorical_accuracy: 0.1855 - val_loss: 1.6227 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.61260\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 4.6735 - categorical_accuracy: 0.2006 - val_loss: 1.6294 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.61260\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.7073 - categorical_accuracy: 0.2036 - val_loss: 1.6403 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.61260\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 4.5812 - categorical_accuracy: 0.2262 - val_loss: 1.6409 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.61260\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 4.8062 - categorical_accuracy: 0.1810 - val_loss: 1.6547 - val_categorical_accuracy: 0.1200\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.61260\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 4.7695 - categorical_accuracy: 0.1991 - val_loss: 1.6509 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.61260\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 4.7489 - categorical_accuracy: 0.2021 - val_loss: 1.6477 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.61260\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.7972 - categorical_accuracy: 0.2066 - val_loss: 1.6576 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.61260\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.4345 - categorical_accuracy: 0.2293 - val_loss: 1.6296 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.61260\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 4.6230 - categorical_accuracy: 0.2127 - val_loss: 1.6680 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.61260\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.4984 - categorical_accuracy: 0.2036 - val_loss: 1.6503 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.61260\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 4.4472 - categorical_accuracy: 0.2157 - val_loss: 1.6453 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.61260\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 4.7669 - categorical_accuracy: 0.1855 - val_loss: 1.6469 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.61260\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 4.6427 - categorical_accuracy: 0.2066 - val_loss: 1.6693 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.61260\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.7558 - categorical_accuracy: 0.1825 - val_loss: 1.6600 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.61260\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.6921 - categorical_accuracy: 0.2036 - val_loss: 1.6585 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.61260\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.2324 - categorical_accuracy: 0.2262 - val_loss: 1.6552 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.61260\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 4.5576 - categorical_accuracy: 0.1855 - val_loss: 1.6435 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.61260\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 4.5090 - categorical_accuracy: 0.2172 - val_loss: 1.6535 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.61260\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 4.2390 - categorical_accuracy: 0.2232 - val_loss: 1.6329 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.61260\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.2675 - categorical_accuracy: 0.2006 - val_loss: 1.6395 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.61260\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 4.0966 - categorical_accuracy: 0.2217 - val_loss: 1.6500 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.61260\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 4.2964 - categorical_accuracy: 0.2278 - val_loss: 1.6394 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.61260\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 4.2843 - categorical_accuracy: 0.2142 - val_loss: 1.6251 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.61260\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.2358 - categorical_accuracy: 0.2187 - val_loss: 1.6493 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.61260\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 4.2283 - categorical_accuracy: 0.2187 - val_loss: 1.6417 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.61260\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.9708 - categorical_accuracy: 0.2262 - val_loss: 1.6481 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.61260\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 3.9240 - categorical_accuracy: 0.2232 - val_loss: 1.6171 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.61260\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.2130 - categorical_accuracy: 0.2036 - val_loss: 1.6121 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.61260 to 1.61211, saving model to model_init_2021-10-2718_08_28.064000\\model-00040-4.21304-0.20362-1.61211-0.22000.h5\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 4.1454 - categorical_accuracy: 0.2142 - val_loss: 1.6666 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.61211\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 3.7511 - categorical_accuracy: 0.2474 - val_loss: 1.6541 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.61211\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.1110 - categorical_accuracy: 0.2112 - val_loss: 1.6729 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.61211\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 3.9372 - categorical_accuracy: 0.2368 - val_loss: 1.6713 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.61211\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 3.9043 - categorical_accuracy: 0.2398 - val_loss: 1.6538 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.61211\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 4.0983 - categorical_accuracy: 0.2066 - val_loss: 1.6599 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.61211\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.0330 - categorical_accuracy: 0.2081 - val_loss: 1.7006 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.61211\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 3.8575 - categorical_accuracy: 0.2534 - val_loss: 1.6848 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.61211\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 3.9380 - categorical_accuracy: 0.2308 - val_loss: 1.6803 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.61211\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 3.5367 - categorical_accuracy: 0.2519 - val_loss: 1.6640 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.61211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17abe1efd60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_11.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of model 11 is too poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of all the models (1 to 11) we have seen till now, model 1 appeared to perform the best. We would be tweaking model_1, a\n",
    "# little and trying to run that model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model_12 = Sequential()\n",
    "\n",
    "model_12.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_12.add(BatchNormalization())\n",
    "model_12.add(Activation('elu'))\n",
    "model_12.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
    "\n",
    "\n",
    "model_12.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_12.add(BatchNormalization())\n",
    "model_12.add(Activation('elu'))\n",
    "model_12.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n",
    "\n",
    "\n",
    "model_12.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "model_12.add(BatchNormalization())\n",
    "model_12.add(Activation('elu'))\n",
    "model_12.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
    "\n",
    "\n",
    "model_12.add(Flatten())\n",
    "model_12.add(Dropout(0.5))\n",
    "model_12.add(Dense(1024, activation='elu'))\n",
    "model_12.add(Dropout(0.5))\n",
    "model_12.add(Dense(512, activation='elu'))\n",
    "model_12.add(Dropout(0.5))\n",
    "model_12.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_22 (Conv3D)           (None, 18, 84, 84, 64)    5248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 18, 84, 84, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 18, 84, 84, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_21 (MaxPooling (None, 9, 42, 84, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_23 (Conv3D)           (None, 9, 42, 84, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 9, 42, 84, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 9, 42, 84, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_22 (MaxPooling (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 4, 21, 42, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 4, 21, 42, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4, 21, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_23 (MaxPooling (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1024)              220201984 \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 221,842,693\n",
      "Trainable params: 221,841,797\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_12.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_12.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 4.4650 - categorical_accuracy: 0.2081 - val_loss: 1.5935 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59351, saving model to model_init_2021-10-2718_08_28.064000\\model-00001-4.46497-0.20814-1.59351-0.28000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.6054 - categorical_accuracy: 0.2745 - val_loss: 1.5833 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.59351 to 1.58334, saving model to model_init_2021-10-2718_08_28.064000\\model-00002-3.60539-0.27451-1.58334-0.23000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 48s 2s/step - loss: 3.4056 - categorical_accuracy: 0.2745 - val_loss: 1.6386 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.58334\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.9027 - categorical_accuracy: 0.3318 - val_loss: 1.8999 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.58334\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.7628 - categorical_accuracy: 0.3514 - val_loss: 2.2106 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.58334\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.6742 - categorical_accuracy: 0.3469 - val_loss: 2.5852 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.58334\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.5106 - categorical_accuracy: 0.3635 - val_loss: 2.8827 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.58334\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.5889 - categorical_accuracy: 0.3575 - val_loss: 3.1261 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.58334\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.1773 - categorical_accuracy: 0.4223 - val_loss: 3.3985 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.58334\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.2396 - categorical_accuracy: 0.3952 - val_loss: 3.3114 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.58334\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.1539 - categorical_accuracy: 0.4042 - val_loss: 3.8873 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.58334\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.9721 - categorical_accuracy: 0.4314 - val_loss: 3.6989 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.58334\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.9105 - categorical_accuracy: 0.4646 - val_loss: 3.6653 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.58334\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.9335 - categorical_accuracy: 0.4676 - val_loss: 4.4143 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.58334\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.8808 - categorical_accuracy: 0.4389 - val_loss: 3.5538 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.58334\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.8052 - categorical_accuracy: 0.4691 - val_loss: 3.2583 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.58334\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7133 - categorical_accuracy: 0.5113 - val_loss: 3.1374 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.58334\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7547 - categorical_accuracy: 0.4887 - val_loss: 3.0434 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.58334\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.6858 - categorical_accuracy: 0.4842 - val_loss: 2.5304 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.58334\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.5327 - categorical_accuracy: 0.5249 - val_loss: 2.2738 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.58334\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.6060 - categorical_accuracy: 0.5339 - val_loss: 1.8781 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.58334\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.5583 - categorical_accuracy: 0.5204 - val_loss: 1.9233 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.58334\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.4420 - categorical_accuracy: 0.5385 - val_loss: 1.4555 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.58334 to 1.45553, saving model to model_init_2021-10-2718_08_28.064000\\model-00023-1.44198-0.53846-1.45553-0.55000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.5280 - categorical_accuracy: 0.5204 - val_loss: 1.3495 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.45553 to 1.34951, saving model to model_init_2021-10-2718_08_28.064000\\model-00024-1.52803-0.52036-1.34951-0.57000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.4799 - categorical_accuracy: 0.5400 - val_loss: 1.2483 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.34951 to 1.24829, saving model to model_init_2021-10-2718_08_28.064000\\model-00025-1.47990-0.53997-1.24829-0.59000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.4307 - categorical_accuracy: 0.5535 - val_loss: 1.1587 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.24829 to 1.15873, saving model to model_init_2021-10-2718_08_28.064000\\model-00026-1.43068-0.55354-1.15873-0.57000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.4595 - categorical_accuracy: 0.5460 - val_loss: 1.0374 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.15873 to 1.03744, saving model to model_init_2021-10-2718_08_28.064000\\model-00027-1.45949-0.54600-1.03744-0.65000.h5\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.3860 - categorical_accuracy: 0.5445 - val_loss: 1.0116 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.03744 to 1.01158, saving model to model_init_2021-10-2718_08_28.064000\\model-00028-1.38603-0.54449-1.01158-0.66000.h5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.4210 - categorical_accuracy: 0.5505 - val_loss: 1.0490 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.01158\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.3806 - categorical_accuracy: 0.5747 - val_loss: 1.0077 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.01158 to 1.00765, saving model to model_init_2021-10-2718_08_28.064000\\model-00030-1.38062-0.57466-1.00765-0.63000.h5\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.2897 - categorical_accuracy: 0.5762 - val_loss: 0.9153 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.00765 to 0.91534, saving model to model_init_2021-10-2718_08_28.064000\\model-00031-1.28971-0.57617-0.91534-0.67000.h5\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.2207 - categorical_accuracy: 0.5988 - val_loss: 0.9273 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.91534\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.2927 - categorical_accuracy: 0.5822 - val_loss: 0.9122 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.91534 to 0.91220, saving model to model_init_2021-10-2718_08_28.064000\\model-00033-1.29269-0.58220-0.91220-0.66000.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.2144 - categorical_accuracy: 0.6139 - val_loss: 0.8550 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.91220 to 0.85504, saving model to model_init_2021-10-2718_08_28.064000\\model-00034-1.21436-0.61388-0.85504-0.67000.h5\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.2707 - categorical_accuracy: 0.5867 - val_loss: 0.8530 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.85504 to 0.85296, saving model to model_init_2021-10-2718_08_28.064000\\model-00035-1.27074-0.58673-0.85296-0.70000.h5\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.1870 - categorical_accuracy: 0.6109 - val_loss: 0.8550 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.85296\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.1631 - categorical_accuracy: 0.6033 - val_loss: 0.8673 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.85296\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0419 - categorical_accuracy: 0.6184 - val_loss: 0.8624 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.85296\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.1265 - categorical_accuracy: 0.6229 - val_loss: 0.8101 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.85296 to 0.81007, saving model to model_init_2021-10-2718_08_28.064000\\model-00039-1.12647-0.62293-0.81007-0.71000.h5\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0748 - categorical_accuracy: 0.6275 - val_loss: 0.8337 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.81007\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.1000 - categorical_accuracy: 0.6365 - val_loss: 0.8642 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.81007\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.1187 - categorical_accuracy: 0.6410 - val_loss: 0.7928 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.81007 to 0.79280, saving model to model_init_2021-10-2718_08_28.064000\\model-00042-1.11868-0.64103-0.79280-0.73000.h5\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0289 - categorical_accuracy: 0.6486 - val_loss: 0.8678 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.79280\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.0955 - categorical_accuracy: 0.6335 - val_loss: 0.8526 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.79280\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.1150 - categorical_accuracy: 0.6275 - val_loss: 0.7534 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.79280 to 0.75336, saving model to model_init_2021-10-2718_08_28.064000\\model-00045-1.11498-0.62745-0.75336-0.70000.h5\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0249 - categorical_accuracy: 0.6576 - val_loss: 0.9891 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.75336\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.0988 - categorical_accuracy: 0.6199 - val_loss: 0.8374 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.75336\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.8848 - categorical_accuracy: 0.6833 - val_loss: 0.8529 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.75336\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.0712 - categorical_accuracy: 0.6621 - val_loss: 0.8193 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.75336\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 0.9528 - categorical_accuracy: 0.6591 - val_loss: 0.9398 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.75336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17abe01e220>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_12.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly, models 1 stands out. Thus, we would be re-running models 1 and 12 as conv3d_model_1 with the parameter\n",
    "# save_best = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "#write your model here\n",
    "conv3d_model_1 = Sequential()\n",
    "\n",
    "conv3d_model_1.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "conv3d_model_1.add(BatchNormalization())\n",
    "conv3d_model_1.add(Activation('elu'))\n",
    "conv3d_model_1.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
    "\n",
    "\n",
    "conv3d_model_1.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "conv3d_model_1.add(BatchNormalization())\n",
    "conv3d_model_1.add(Activation('elu'))\n",
    "conv3d_model_1.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n",
    "\n",
    "\n",
    "conv3d_model_1.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "conv3d_model_1.add(BatchNormalization())\n",
    "conv3d_model_1.add(Activation('elu'))\n",
    "conv3d_model_1.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
    "\n",
    "\n",
    "conv3d_model_1.add(Flatten())\n",
    "conv3d_model_1.add(Dropout(0.5))\n",
    "conv3d_model_1.add(Dense(512, activation='elu'))\n",
    "conv3d_model_1.add(Dropout(0.5))\n",
    "conv3d_model_1.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 18, 84, 84, 64)    5248      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 18, 84, 84, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 18, 84, 84, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 9, 42, 84, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 9, 42, 84, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9, 42, 84, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9, 42, 84, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 4, 21, 42, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 21, 42, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 21, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               110100992 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 111,216,901\n",
      "Trainable params: 111,216,005\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "optimiser = keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.7, nesterov=True) #write your optimizer\n",
    "\n",
    "conv3d_model_1.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(conv3d_model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  C:\\Users\\Amit\\Documents\\Academics\\upGrad\\Deep Learning\\Project_data\\train ; batch size = 32\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - ETA: 0s - loss: 7.8384 - categorical_accuracy: 0.2926Source path =  C:\\Users\\Amit\\Documents\\Academics\\upGrad\\Deep Learning\\Project_data\\val ; batch size = 32\n",
      "21/21 [==============================] - 63s 3s/step - loss: 7.8384 - categorical_accuracy: 0.2926 - val_loss: 3.0341 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-10-2723_54_21.814102\\model-00001-7.83838-0.29261-3.03408-0.18000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.7314 - categorical_accuracy: 0.4042 - val_loss: 2.4487 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00002: saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.73141-0.40422-2.44870-0.18000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.5232 - categorical_accuracy: 0.4842 - val_loss: 4.4316 - val_categorical_accuracy: 0.1400\n",
      "\n",
      "Epoch 00003: saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.52325-0.48416-4.43162-0.14000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.2836 - categorical_accuracy: 0.5370 - val_loss: 5.6684 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00004: saving model to model_init_2021-10-2723_54_21.814102\\model-00004-1.28360-0.53695-5.66842-0.29000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.9678 - categorical_accuracy: 0.6531 - val_loss: 7.0705 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00005: saving model to model_init_2021-10-2723_54_21.814102\\model-00005-0.96779-0.65309-7.07052-0.29000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.7948 - categorical_accuracy: 0.7059 - val_loss: 8.3016 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2021-10-2723_54_21.814102\\model-00006-0.79477-0.70588-8.30157-0.32000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.7160 - categorical_accuracy: 0.7345 - val_loss: 9.4745 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00007: saving model to model_init_2021-10-2723_54_21.814102\\model-00007-0.71599-0.73454-9.47452-0.26000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 0.6572 - categorical_accuracy: 0.7451 - val_loss: 9.9918 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00008: saving model to model_init_2021-10-2723_54_21.814102\\model-00008-0.65716-0.74510-9.99184-0.26000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.6123 - categorical_accuracy: 0.7587 - val_loss: 10.0732 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00009: saving model to model_init_2021-10-2723_54_21.814102\\model-00009-0.61227-0.75867-10.07319-0.28000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.4913 - categorical_accuracy: 0.8084 - val_loss: 10.3181 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00010: saving model to model_init_2021-10-2723_54_21.814102\\model-00010-0.49134-0.80845-10.31807-0.28000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 0.5907 - categorical_accuracy: 0.7798 - val_loss: 9.7758 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00011: saving model to model_init_2021-10-2723_54_21.814102\\model-00011-0.59070-0.77979-9.77575-0.27000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.5073 - categorical_accuracy: 0.8190 - val_loss: 9.5816 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00012: saving model to model_init_2021-10-2723_54_21.814102\\model-00012-0.50726-0.81900-9.58155-0.29000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.5188 - categorical_accuracy: 0.8175 - val_loss: 9.1536 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00013: saving model to model_init_2021-10-2723_54_21.814102\\model-00013-0.51884-0.81750-9.15355-0.28000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5210 - categorical_accuracy: 0.7934 - val_loss: 9.0227 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00014: saving model to model_init_2021-10-2723_54_21.814102\\model-00014-0.52104-0.79336-9.02267-0.24000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.4764 - categorical_accuracy: 0.8160 - val_loss: 7.9844 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00015: saving model to model_init_2021-10-2723_54_21.814102\\model-00015-0.47642-0.81599-7.98442-0.26000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.5261 - categorical_accuracy: 0.7934 - val_loss: 7.6749 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00016: saving model to model_init_2021-10-2723_54_21.814102\\model-00016-0.52612-0.79336-7.67489-0.27000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.5056 - categorical_accuracy: 0.7964 - val_loss: 6.8556 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00017: saving model to model_init_2021-10-2723_54_21.814102\\model-00017-0.50558-0.79638-6.85557-0.29000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5238 - categorical_accuracy: 0.7934 - val_loss: 6.2617 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00018: saving model to model_init_2021-10-2723_54_21.814102\\model-00018-0.52376-0.79336-6.26172-0.27000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5166 - categorical_accuracy: 0.8084 - val_loss: 5.6783 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00019: saving model to model_init_2021-10-2723_54_21.814102\\model-00019-0.51660-0.80845-5.67827-0.29000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.4793 - categorical_accuracy: 0.8130 - val_loss: 4.7524 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00020: saving model to model_init_2021-10-2723_54_21.814102\\model-00020-0.47931-0.81297-4.75239-0.29000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5151 - categorical_accuracy: 0.8069 - val_loss: 4.0728 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00021: saving model to model_init_2021-10-2723_54_21.814102\\model-00021-0.51510-0.80694-4.07280-0.33000.h5\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5086 - categorical_accuracy: 0.8084 - val_loss: 3.3097 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00022: saving model to model_init_2021-10-2723_54_21.814102\\model-00022-0.50859-0.80845-3.30966-0.42000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4933 - categorical_accuracy: 0.8084 - val_loss: 2.8950 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00023: saving model to model_init_2021-10-2723_54_21.814102\\model-00023-0.49330-0.80845-2.89500-0.41000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.4950 - categorical_accuracy: 0.8130 - val_loss: 2.4797 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00024: saving model to model_init_2021-10-2723_54_21.814102\\model-00024-0.49503-0.81297-2.47972-0.49000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 0.5078 - categorical_accuracy: 0.8250 - val_loss: 2.1091 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00025: saving model to model_init_2021-10-2723_54_21.814102\\model-00025-0.50783-0.82504-2.10914-0.47000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4683 - categorical_accuracy: 0.8265 - val_loss: 1.9876 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00026: saving model to model_init_2021-10-2723_54_21.814102\\model-00026-0.46828-0.82655-1.98758-0.49000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5011 - categorical_accuracy: 0.8039 - val_loss: 1.5775 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00027: saving model to model_init_2021-10-2723_54_21.814102\\model-00027-0.50105-0.80392-1.57755-0.62000.h5\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.4791 - categorical_accuracy: 0.8039 - val_loss: 1.3636 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00028: saving model to model_init_2021-10-2723_54_21.814102\\model-00028-0.47914-0.80392-1.36355-0.66000.h5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5157 - categorical_accuracy: 0.7994 - val_loss: 1.2830 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00029: saving model to model_init_2021-10-2723_54_21.814102\\model-00029-0.51574-0.79940-1.28303-0.66000.h5\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5041 - categorical_accuracy: 0.8145 - val_loss: 1.1682 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00030: saving model to model_init_2021-10-2723_54_21.814102\\model-00030-0.50410-0.81448-1.16818-0.72000.h5\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4583 - categorical_accuracy: 0.8311 - val_loss: 1.2110 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00031: saving model to model_init_2021-10-2723_54_21.814102\\model-00031-0.45834-0.83107-1.21098-0.68000.h5\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.4014 - categorical_accuracy: 0.8507 - val_loss: 0.9435 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00032: saving model to model_init_2021-10-2723_54_21.814102\\model-00032-0.40142-0.85068-0.94354-0.73000.h5\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 0.4987 - categorical_accuracy: 0.8250 - val_loss: 1.0359 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00033: saving model to model_init_2021-10-2723_54_21.814102\\model-00033-0.49867-0.82504-1.03592-0.72000.h5\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4905 - categorical_accuracy: 0.7994 - val_loss: 1.0604 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00034: saving model to model_init_2021-10-2723_54_21.814102\\model-00034-0.49055-0.79940-1.06040-0.67000.h5\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4459 - categorical_accuracy: 0.8145 - val_loss: 0.9167 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00035: saving model to model_init_2021-10-2723_54_21.814102\\model-00035-0.44587-0.81448-0.91666-0.79000.h5\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.4824 - categorical_accuracy: 0.8145 - val_loss: 1.0120 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00036: saving model to model_init_2021-10-2723_54_21.814102\\model-00036-0.48242-0.81448-1.01197-0.72000.h5\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5033 - categorical_accuracy: 0.7919 - val_loss: 0.9560 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00037: saving model to model_init_2021-10-2723_54_21.814102\\model-00037-0.50331-0.79186-0.95600-0.73000.h5\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4902 - categorical_accuracy: 0.8220 - val_loss: 0.8743 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00038: saving model to model_init_2021-10-2723_54_21.814102\\model-00038-0.49017-0.82202-0.87427-0.74000.h5\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5324 - categorical_accuracy: 0.8039 - val_loss: 1.0680 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00039: saving model to model_init_2021-10-2723_54_21.814102\\model-00039-0.53237-0.80392-1.06802-0.71000.h5\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.5147 - categorical_accuracy: 0.8100 - val_loss: 0.9092 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00040: saving model to model_init_2021-10-2723_54_21.814102\\model-00040-0.51469-0.80995-0.90922-0.74000.h5\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4330 - categorical_accuracy: 0.8281 - val_loss: 0.9345 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00041: saving model to model_init_2021-10-2723_54_21.814102\\model-00041-0.43298-0.82805-0.93453-0.72000.h5\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 0.4721 - categorical_accuracy: 0.8190 - val_loss: 1.0233 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00042: saving model to model_init_2021-10-2723_54_21.814102\\model-00042-0.47209-0.81900-1.02329-0.65000.h5\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5039 - categorical_accuracy: 0.8039 - val_loss: 0.8667 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00043: saving model to model_init_2021-10-2723_54_21.814102\\model-00043-0.50390-0.80392-0.86665-0.73000.h5\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.4585 - categorical_accuracy: 0.7888 - val_loss: 0.9244 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00044: saving model to model_init_2021-10-2723_54_21.814102\\model-00044-0.45848-0.78884-0.92441-0.71000.h5\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.5074 - categorical_accuracy: 0.7979 - val_loss: 0.9239 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00045: saving model to model_init_2021-10-2723_54_21.814102\\model-00045-0.50736-0.79789-0.92389-0.71000.h5\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4278 - categorical_accuracy: 0.8356 - val_loss: 0.9350 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00046: saving model to model_init_2021-10-2723_54_21.814102\\model-00046-0.42776-0.83560-0.93501-0.73000.h5\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4745 - categorical_accuracy: 0.8190 - val_loss: 0.7870 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00047: saving model to model_init_2021-10-2723_54_21.814102\\model-00047-0.47447-0.81900-0.78699-0.72000.h5\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.3980 - categorical_accuracy: 0.8446 - val_loss: 0.9421 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00048: saving model to model_init_2021-10-2723_54_21.814102\\model-00048-0.39802-0.84465-0.94212-0.73000.h5\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4541 - categorical_accuracy: 0.8326 - val_loss: 0.9261 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00049: saving model to model_init_2021-10-2723_54_21.814102\\model-00049-0.45415-0.83258-0.92610-0.71000.h5\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.4976 - categorical_accuracy: 0.8130 - val_loss: 0.9646 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00050: saving model to model_init_2021-10-2723_54_21.814102\\model-00050-0.49762-0.81297-0.96463-0.70000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25745665fa0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3d_model_1.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 35: loss: 0.4459 - categorical_accuracy: 0.8145 - val_loss: 0.9167 - val_categorical_accuracy: 0.7900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "conv3d_model_2 = Sequential()\n",
    "\n",
    "conv3d_model_2.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "conv3d_model_2.add(BatchNormalization())\n",
    "conv3d_model_2.add(Activation('elu'))\n",
    "conv3d_model_2.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
    "\n",
    "\n",
    "conv3d_model_2.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "conv3d_model_2.add(BatchNormalization())\n",
    "conv3d_model_2.add(Activation('elu'))\n",
    "conv3d_model_2.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n",
    "\n",
    "\n",
    "conv3d_model_2.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,84,84,3)))\n",
    "conv3d_model_2.add(BatchNormalization())\n",
    "conv3d_model_2.add(Activation('elu'))\n",
    "conv3d_model_2.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
    "\n",
    "\n",
    "conv3d_model_2.add(Flatten())\n",
    "conv3d_model_2.add(Dropout(0.5))\n",
    "conv3d_model_2.add(Dense(1024, activation='elu'))\n",
    "conv3d_model_2.add(Dropout(0.5))\n",
    "conv3d_model_2.add(Dense(512, activation='elu'))\n",
    "conv3d_model_2.add(Dropout(0.5))\n",
    "conv3d_model_2.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_3 (Conv3D)            (None, 18, 84, 84, 64)    5248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 18, 84, 84, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 18, 84, 84, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 9, 42, 84, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 9, 42, 84, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 9, 42, 84, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 9, 42, 84, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 4, 21, 42, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 4, 21, 42, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 21, 42, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 21, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 2, 10, 42, 256)    0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              220201984 \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 221,842,693\n",
      "Trainable params: 221,841,797\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv3d_model_2.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(conv3d_model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 4.3874 - categorical_accuracy: 0.1825 - val_loss: 1.6406 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-10-2723_54_21.814102\\model-00001-4.38737-0.18250-1.64055-0.20000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 3.6685 - categorical_accuracy: 0.2308 - val_loss: 1.6548 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00002: saving model to model_init_2021-10-2723_54_21.814102\\model-00002-3.66855-0.23077-1.65484-0.29000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 3.5081 - categorical_accuracy: 0.2534 - val_loss: 1.7666 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00003: saving model to model_init_2021-10-2723_54_21.814102\\model-00003-3.50814-0.25339-1.76657-0.21000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.9204 - categorical_accuracy: 0.3107 - val_loss: 2.0143 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: saving model to model_init_2021-10-2723_54_21.814102\\model-00004-2.92040-0.31071-2.01428-0.21000.h5\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.7364 - categorical_accuracy: 0.3484 - val_loss: 2.3403 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00005: saving model to model_init_2021-10-2723_54_21.814102\\model-00005-2.73645-0.34842-2.34032-0.23000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.7042 - categorical_accuracy: 0.3409 - val_loss: 2.7051 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00006: saving model to model_init_2021-10-2723_54_21.814102\\model-00006-2.70415-0.34087-2.70515-0.22000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 2.4888 - categorical_accuracy: 0.3514 - val_loss: 2.9875 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: saving model to model_init_2021-10-2723_54_21.814102\\model-00007-2.48877-0.35143-2.98746-0.21000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.3425 - categorical_accuracy: 0.3861 - val_loss: 3.4104 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00008: saving model to model_init_2021-10-2723_54_21.814102\\model-00008-2.34255-0.38612-3.41044-0.19000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.2173 - categorical_accuracy: 0.4118 - val_loss: 3.4754 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00009: saving model to model_init_2021-10-2723_54_21.814102\\model-00009-2.21730-0.41176-3.47537-0.18000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.9513 - categorical_accuracy: 0.4691 - val_loss: 3.7247 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2021-10-2723_54_21.814102\\model-00010-1.95131-0.46908-3.72469-0.21000.h5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 2.0657 - categorical_accuracy: 0.4163 - val_loss: 3.8802 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00011: saving model to model_init_2021-10-2723_54_21.814102\\model-00011-2.06565-0.41629-3.88022-0.21000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.9935 - categorical_accuracy: 0.4419 - val_loss: 4.2226 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00012: saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.99351-0.44193-4.22262-0.20000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.9358 - categorical_accuracy: 0.4570 - val_loss: 3.6014 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00013: saving model to model_init_2021-10-2723_54_21.814102\\model-00013-1.93582-0.45701-3.60137-0.24000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.9283 - categorical_accuracy: 0.4691 - val_loss: 3.9685 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00014: saving model to model_init_2021-10-2723_54_21.814102\\model-00014-1.92827-0.46908-3.96847-0.21000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.7964 - categorical_accuracy: 0.4630 - val_loss: 3.7160 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00015: saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.79642-0.46305-3.71601-0.24000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.7093 - categorical_accuracy: 0.4842 - val_loss: 3.6851 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00016: saving model to model_init_2021-10-2723_54_21.814102\\model-00016-1.70932-0.48416-3.68509-0.25000.h5\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.5891 - categorical_accuracy: 0.5189 - val_loss: 3.3099 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00017: saving model to model_init_2021-10-2723_54_21.814102\\model-00017-1.58909-0.51885-3.30986-0.27000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.5920 - categorical_accuracy: 0.5143 - val_loss: 3.0181 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00018: saving model to model_init_2021-10-2723_54_21.814102\\model-00018-1.59205-0.51433-3.01811-0.27000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.6831 - categorical_accuracy: 0.4796 - val_loss: 2.9625 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00019: saving model to model_init_2021-10-2723_54_21.814102\\model-00019-1.68313-0.47964-2.96253-0.27000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.5848 - categorical_accuracy: 0.5370 - val_loss: 2.8319 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00020: saving model to model_init_2021-10-2723_54_21.814102\\model-00020-1.58476-0.53695-2.83194-0.28000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.5500 - categorical_accuracy: 0.5339 - val_loss: 2.6117 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00021: saving model to model_init_2021-10-2723_54_21.814102\\model-00021-1.55004-0.53394-2.61165-0.29000.h5\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 50s 3s/step - loss: 1.4970 - categorical_accuracy: 0.5430 - val_loss: 2.1024 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00022: saving model to model_init_2021-10-2723_54_21.814102\\model-00022-1.49699-0.54299-2.10237-0.39000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.4319 - categorical_accuracy: 0.5656 - val_loss: 1.8810 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00023: saving model to model_init_2021-10-2723_54_21.814102\\model-00023-1.43189-0.56561-1.88103-0.42000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.4910 - categorical_accuracy: 0.5415 - val_loss: 1.6888 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00024: saving model to model_init_2021-10-2723_54_21.814102\\model-00024-1.49101-0.54148-1.68882-0.47000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.4189 - categorical_accuracy: 0.5641 - val_loss: 1.6620 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00025: saving model to model_init_2021-10-2723_54_21.814102\\model-00025-1.41893-0.56410-1.66203-0.46000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.3822 - categorical_accuracy: 0.5611 - val_loss: 1.4124 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00026: saving model to model_init_2021-10-2723_54_21.814102\\model-00026-1.38223-0.56109-1.41238-0.52000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.3940 - categorical_accuracy: 0.5475 - val_loss: 1.3028 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00027: saving model to model_init_2021-10-2723_54_21.814102\\model-00027-1.39395-0.54751-1.30284-0.55000.h5\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.3505 - categorical_accuracy: 0.5852 - val_loss: 1.2659 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00028: saving model to model_init_2021-10-2723_54_21.814102\\model-00028-1.35047-0.58522-1.26586-0.53000.h5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.2175 - categorical_accuracy: 0.5882 - val_loss: 1.0283 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00029: saving model to model_init_2021-10-2723_54_21.814102\\model-00029-1.21747-0.58824-1.02828-0.62000.h5\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.2344 - categorical_accuracy: 0.6018 - val_loss: 0.9877 - val_categorical_accuracy: 0.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00030: saving model to model_init_2021-10-2723_54_21.814102\\model-00030-1.23438-0.60181-0.98766-0.58000.h5\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.1964 - categorical_accuracy: 0.5958 - val_loss: 1.0329 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00031: saving model to model_init_2021-10-2723_54_21.814102\\model-00031-1.19642-0.59578-1.03293-0.61000.h5\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.3109 - categorical_accuracy: 0.5928 - val_loss: 0.8835 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00032: saving model to model_init_2021-10-2723_54_21.814102\\model-00032-1.31094-0.59276-0.88346-0.69000.h5\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.3628 - categorical_accuracy: 0.5596 - val_loss: 0.8261 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00033: saving model to model_init_2021-10-2723_54_21.814102\\model-00033-1.36282-0.55958-0.82606-0.67000.h5\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.1673 - categorical_accuracy: 0.6244 - val_loss: 0.9592 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00034: saving model to model_init_2021-10-2723_54_21.814102\\model-00034-1.16735-0.62443-0.95915-0.65000.h5\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.2841 - categorical_accuracy: 0.5852 - val_loss: 0.9505 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00035: saving model to model_init_2021-10-2723_54_21.814102\\model-00035-1.28412-0.58522-0.95050-0.63000.h5\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.1471 - categorical_accuracy: 0.6139 - val_loss: 0.9955 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00036: saving model to model_init_2021-10-2723_54_21.814102\\model-00036-1.14712-0.61388-0.99546-0.65000.h5\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0861 - categorical_accuracy: 0.6305 - val_loss: 0.9129 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00037: saving model to model_init_2021-10-2723_54_21.814102\\model-00037-1.08612-0.63047-0.91289-0.64000.h5\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 50s 2s/step - loss: 1.1900 - categorical_accuracy: 0.6124 - val_loss: 0.8379 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00038: saving model to model_init_2021-10-2723_54_21.814102\\model-00038-1.19000-0.61237-0.83790-0.66000.h5\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 1.1726 - categorical_accuracy: 0.6229 - val_loss: 0.9137 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00039: saving model to model_init_2021-10-2723_54_21.814102\\model-00039-1.17264-0.62293-0.91367-0.65000.h5\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.1234 - categorical_accuracy: 0.6305 - val_loss: 1.0391 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00040: saving model to model_init_2021-10-2723_54_21.814102\\model-00040-1.12339-0.63047-1.03906-0.65000.h5\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.2115 - categorical_accuracy: 0.6335 - val_loss: 0.8365 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00041: saving model to model_init_2021-10-2723_54_21.814102\\model-00041-1.21149-0.63348-0.83653-0.73000.h5\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 49s 2s/step - loss: 1.1172 - categorical_accuracy: 0.6184 - val_loss: 0.8591 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00042: saving model to model_init_2021-10-2723_54_21.814102\\model-00042-1.11719-0.61840-0.85907-0.66000.h5\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0783 - categorical_accuracy: 0.6591 - val_loss: 0.8583 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00043: saving model to model_init_2021-10-2723_54_21.814102\\model-00043-1.07833-0.65913-0.85827-0.67000.h5\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0246 - categorical_accuracy: 0.6576 - val_loss: 0.8455 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00044: saving model to model_init_2021-10-2723_54_21.814102\\model-00044-1.02464-0.65762-0.84547-0.67000.h5\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0856 - categorical_accuracy: 0.6290 - val_loss: 0.7283 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00045: saving model to model_init_2021-10-2723_54_21.814102\\model-00045-1.08565-0.62896-0.72829-0.73000.h5\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9934 - categorical_accuracy: 0.6576 - val_loss: 0.9108 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00046: saving model to model_init_2021-10-2723_54_21.814102\\model-00046-0.99342-0.65762-0.91085-0.69000.h5\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 1.0028 - categorical_accuracy: 0.6531 - val_loss: 0.8164 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00047: saving model to model_init_2021-10-2723_54_21.814102\\model-00047-1.00278-0.65309-0.81637-0.72000.h5\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0431 - categorical_accuracy: 0.6561 - val_loss: 0.9456 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00048: saving model to model_init_2021-10-2723_54_21.814102\\model-00048-1.04307-0.65611-0.94557-0.68000.h5\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.9408 - categorical_accuracy: 0.6712 - val_loss: 0.8277 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00049: saving model to model_init_2021-10-2723_54_21.814102\\model-00049-0.94079-0.67119-0.82767-0.69000.h5\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 51s 3s/step - loss: 0.9672 - categorical_accuracy: 0.6908 - val_loss: 0.8005 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00050: saving model to model_init_2021-10-2723_54_21.814102\\model-00050-0.96723-0.69080-0.80052-0.73000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25ab7fa1a30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3d_model_2.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After observing the results of the two models, we conclude that the result obtained in the 35th epoch of model conv3d_model_1\n",
    "# is the best result so far. Thus, we would be uploading its .h5 file for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - RNN Models (Without Transfer Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_path = train_path i.e. path of 663 folders\n",
    "# folder_list = train_doc i.e. csv file\n",
    "# batch_size = 64\n",
    "\n",
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    # It is not possible to work with all the 30 images, as it will take too long processing time.\n",
    "    # So lets choose randomly 20 images, as this is more computationally expensive\n",
    "    img_idx = [1,2,4,6,10,11,12,14,15,16,17,18,19,20,22,23,24,27,28,29] #create a list of image numbers you want to use for a particular video(incase if u want to try with lesser images)\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(t)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,20,84,84,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = resize(image[:,20:140,:],(84,84)).astype(np.float32)\n",
    "                    normalizedImg = image/255.0                    \n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (normalizedImg[:,:,0]) #normalise and feed in the image # divide by 255.0\n",
    "                    batch_data[folder,idx,:,:,1] = (normalizedImg[:,:,1]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (normalizedImg[:,:,2]) #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1 # OHE\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if(len(t)%batch_size)!=0:\n",
    "            batch_data = np.zeros((len(t)%batch_size,20,84,84,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((len(t)%batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(len(t)%batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (num_batches*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imageio.imread(source_path+'/'+ t[folder + (num_batches*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = resize(image[:,20:140,:],(84,84)).astype(np.float32)\n",
    "                    normalizedImg = image/255.0                    \n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (normalizedImg[:,:,0]) #normalise and feed in the image # divide by 255.0\n",
    "                    batch_data[folder,idx,:,:,1] = (normalizedImg[:,:,1]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (normalizedImg[:,:,2]) #normalise and feed in the imagee\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (num_batches*batch_size)].strip().split(';')[2])] = 1 # OHE\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "#write your model here\n",
    "\n",
    "model_13 = Sequential()\n",
    "\n",
    "model_13.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "\n",
    "\n",
    "model_13.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_13.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_13.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_13.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_13.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_13.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_13.add(TimeDistributed(BatchNormalization()))\n",
    "model_13.add(Dropout(0.25))\n",
    "\n",
    "model_13.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_13.add(Dense(128, activation='relu'))\n",
    "model_13.add(Dropout(0.25))\n",
    "model_13.add(Dense(64, activation='relu'))\n",
    "model_13.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_13.add(GRU(128, return_sequences=False))\n",
    "model_13.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20, 128)           204928    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 302,869\n",
      "Trainable params: 302,741\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimiser_2 = Adam(0.001) #write your optimizer\n",
    "\n",
    "model_13.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_13.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  C:\\Users\\Amit\\Documents\\Academics\\upGrad\\Deep Learning\\Project_data\\train ; batch size = 32\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4560 - categorical_accuracy: 0.3590Source path =  C:\\Users\\Amit\\Documents\\Academics\\upGrad\\Deep Learning\\Project_data\\val ; batch size = 32\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.4560 - categorical_accuracy: 0.3590 - val_loss: 1.7117 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.71168, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.45598-0.35897-1.71168-0.23000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2007 - categorical_accuracy: 0.4827 - val_loss: 1.6111 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.71168 to 1.61108, saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.20070-0.48265-1.61108-0.28000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0113 - categorical_accuracy: 0.5807 - val_loss: 1.5984 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.61108 to 1.59839, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.01126-0.58069-1.59839-0.21000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 0.7749 - categorical_accuracy: 0.6848 - val_loss: 1.5852 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.59839 to 1.58516, saving model to model_init_2021-10-2723_54_21.814102\\model-00004-0.77487-0.68477-1.58516-0.28000.h5\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.6465 - categorical_accuracy: 0.7677 - val_loss: 1.4254 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.58516 to 1.42538, saving model to model_init_2021-10-2723_54_21.814102\\model-00005-0.64650-0.76772-1.42538-0.39000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.4606 - categorical_accuracy: 0.8265 - val_loss: 1.1283 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.42538 to 1.12830, saving model to model_init_2021-10-2723_54_21.814102\\model-00006-0.46063-0.82655-1.12830-0.65000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.3429 - categorical_accuracy: 0.8778 - val_loss: 1.5076 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.12830\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 0.2715 - categorical_accuracy: 0.8929 - val_loss: 1.0017 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.12830 to 1.00171, saving model to model_init_2021-10-2723_54_21.814102\\model-00008-0.27151-0.89291-1.00171-0.59000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.1615 - categorical_accuracy: 0.9336 - val_loss: 1.0750 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.00171\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.1053 - categorical_accuracy: 0.9668 - val_loss: 1.5305 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.00171\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0600 - categorical_accuracy: 0.9849 - val_loss: 0.8624 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.00171 to 0.86238, saving model to model_init_2021-10-2723_54_21.814102\\model-00011-0.06003-0.98492-0.86238-0.65000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.0317 - categorical_accuracy: 0.9910 - val_loss: 1.1005 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.86238\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0360 - categorical_accuracy: 0.9925 - val_loss: 1.0865 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.86238\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0184 - categorical_accuracy: 0.9970 - val_loss: 0.9714 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.86238\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0128 - categorical_accuracy: 0.9985 - val_loss: 1.3359 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.86238\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 0.0109 - categorical_accuracy: 0.9985 - val_loss: 1.1767 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.86238\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0073 - categorical_accuracy: 1.0000 - val_loss: 1.2299 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.86238\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0066 - categorical_accuracy: 1.0000 - val_loss: 1.3301 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.86238\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0071 - categorical_accuracy: 1.0000 - val_loss: 1.3336 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.86238\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.0066 - categorical_accuracy: 1.0000 - val_loss: 1.2405 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.86238\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0083 - categorical_accuracy: 0.9985 - val_loss: 1.3127 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.86238\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0084 - categorical_accuracy: 1.0000 - val_loss: 1.1303 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.86238\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0104 - categorical_accuracy: 1.0000 - val_loss: 1.5038 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.86238\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.0077 - categorical_accuracy: 1.0000 - val_loss: 1.2832 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.86238\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0055 - categorical_accuracy: 1.0000 - val_loss: 1.3561 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.86238\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0067 - categorical_accuracy: 1.0000 - val_loss: 1.0946 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.86238\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0073 - categorical_accuracy: 1.0000 - val_loss: 1.3244 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.86238\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.0064 - categorical_accuracy: 1.0000 - val_loss: 1.3823 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.86238\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0081 - categorical_accuracy: 0.9985 - val_loss: 1.3697 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.86238\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0084 - categorical_accuracy: 0.9985 - val_loss: 1.3225 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.86238\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 56s 3s/step - loss: 0.0059 - categorical_accuracy: 1.0000 - val_loss: 1.2474 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.86238\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.0059 - categorical_accuracy: 1.0000 - val_loss: 1.3343 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.86238\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0081 - categorical_accuracy: 1.0000 - val_loss: 1.3839 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.86238\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0079 - categorical_accuracy: 1.0000 - val_loss: 1.3323 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.86238\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0063 - categorical_accuracy: 1.0000 - val_loss: 1.5141 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.86238\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.0057 - categorical_accuracy: 1.0000 - val_loss: 1.3159 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.86238\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0063 - categorical_accuracy: 1.0000 - val_loss: 1.3858 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.86238\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0065 - categorical_accuracy: 1.0000 - val_loss: 1.3528 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.86238\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0080 - categorical_accuracy: 1.0000 - val_loss: 1.4633 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.86238\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.0055 - categorical_accuracy: 1.0000 - val_loss: 1.4101 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.86238\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0050 - categorical_accuracy: 1.0000 - val_loss: 1.3907 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.86238\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0073 - categorical_accuracy: 1.0000 - val_loss: 1.1592 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.86238\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0066 - categorical_accuracy: 1.0000 - val_loss: 1.5226 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.86238\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.0076 - categorical_accuracy: 1.0000 - val_loss: 1.3906 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.86238\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0063 - categorical_accuracy: 1.0000 - val_loss: 1.3897 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.86238\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.0070 - categorical_accuracy: 0.9985 - val_loss: 1.3828 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.86238\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0107 - categorical_accuracy: 0.9955 - val_loss: 1.2592 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.86238\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.0050 - categorical_accuracy: 1.0000 - val_loss: 1.4444 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.86238\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0053 - categorical_accuracy: 1.0000 - val_loss: 1.3729 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.86238\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0051 - categorical_accuracy: 1.0000 - val_loss: 1.2522 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.86238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25ab6ceb430>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_13.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that this model is massively overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying with 16, 32, 64 and 128 in Conv2D. Also, increasing the dropout percentage from 25% to 50% in dense layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_14 = Sequential()\n",
    "\n",
    "model_14.add(TimeDistributed(Conv2D(16, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "\n",
    "\n",
    "model_14.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_14.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_14.add(TimeDistributed(Conv2D(64, (3,3),padding='same', activation='relu')))\n",
    "model_14.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_14.add(TimeDistributed(Conv2D(128, (2,2),padding='same', activation='relu')))\n",
    "model_14.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_14.add(TimeDistributed(BatchNormalization()))\n",
    "model_14.add(Dropout(0.25))\n",
    "\n",
    "model_14.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_14.add(Dense(128, activation='relu'))\n",
    "model_14.add(Dropout(0.5))\n",
    "model_14.add(Dense(64, activation='relu'))\n",
    "model_14.add(Dropout(0.5))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_14.add(GRU(128, return_sequences=False))\n",
    "model_14.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_9 (TimeDist (None, 20, 42, 42, 16)    448       \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 20, 42, 42, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 20, 21, 21, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 20, 21, 21, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 20, 10, 10, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 20, 10, 10, 128)   32896     \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 20, 5, 5, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 20, 5, 5, 128)     512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 20, 5, 5, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 20, 3200)          0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20, 128)           409728    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 550,117\n",
      "Trainable params: 549,861\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_14.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_14.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.6020 - categorical_accuracy: 0.2413 - val_loss: 1.6074 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60743, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.60198-0.24133-1.60743-0.18000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.5496 - categorical_accuracy: 0.3047 - val_loss: 1.6034 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60743 to 1.60343, saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.54962-0.30468-1.60343-0.30000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.5190 - categorical_accuracy: 0.3258 - val_loss: 1.6007 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.60343 to 1.60067, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.51904-0.32579-1.60067-0.28000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.4716 - categorical_accuracy: 0.3725 - val_loss: 1.5963 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.60067 to 1.59629, saving model to model_init_2021-10-2723_54_21.814102\\model-00004-1.47159-0.37255-1.59629-0.29000.h5\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4436 - categorical_accuracy: 0.3876 - val_loss: 1.5929 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.59629 to 1.59288, saving model to model_init_2021-10-2723_54_21.814102\\model-00005-1.44363-0.38763-1.59288-0.31000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.4207 - categorical_accuracy: 0.4133 - val_loss: 1.5907 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.59288 to 1.59071, saving model to model_init_2021-10-2723_54_21.814102\\model-00006-1.42072-0.41327-1.59071-0.26000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3891 - categorical_accuracy: 0.4284 - val_loss: 1.5831 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.59071 to 1.58314, saving model to model_init_2021-10-2723_54_21.814102\\model-00007-1.38912-0.42836-1.58314-0.26000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3419 - categorical_accuracy: 0.4646 - val_loss: 1.5772 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.58314 to 1.57717, saving model to model_init_2021-10-2723_54_21.814102\\model-00008-1.34191-0.46456-1.57717-0.24000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3163 - categorical_accuracy: 0.4555 - val_loss: 1.5675 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.57717 to 1.56746, saving model to model_init_2021-10-2723_54_21.814102\\model-00009-1.31626-0.45551-1.56746-0.36000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3197 - categorical_accuracy: 0.4796 - val_loss: 1.5629 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.56746 to 1.56288, saving model to model_init_2021-10-2723_54_21.814102\\model-00010-1.31973-0.47964-1.56288-0.35000.h5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2874 - categorical_accuracy: 0.4781 - val_loss: 1.5467 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.56288 to 1.54666, saving model to model_init_2021-10-2723_54_21.814102\\model-00011-1.28736-0.47813-1.54666-0.39000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2711 - categorical_accuracy: 0.4887 - val_loss: 1.5370 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.54666 to 1.53698, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.27110-0.48869-1.53698-0.44000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2510 - categorical_accuracy: 0.4902 - val_loss: 1.5072 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.53698 to 1.50716, saving model to model_init_2021-10-2723_54_21.814102\\model-00013-1.25103-0.49020-1.50716-0.44000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2382 - categorical_accuracy: 0.4992 - val_loss: 1.4990 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.50716 to 1.49902, saving model to model_init_2021-10-2723_54_21.814102\\model-00014-1.23823-0.49925-1.49902-0.42000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2121 - categorical_accuracy: 0.5128 - val_loss: 1.4834 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.49902 to 1.48339, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.21205-0.51282-1.48339-0.46000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2179 - categorical_accuracy: 0.5204 - val_loss: 1.4603 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.48339 to 1.46032, saving model to model_init_2021-10-2723_54_21.814102\\model-00016-1.21785-0.52036-1.46032-0.47000.h5\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2031 - categorical_accuracy: 0.5249 - val_loss: 1.4584 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.46032 to 1.45838, saving model to model_init_2021-10-2723_54_21.814102\\model-00017-1.20314-0.52489-1.45838-0.44000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1815 - categorical_accuracy: 0.5415 - val_loss: 1.4308 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.45838 to 1.43078, saving model to model_init_2021-10-2723_54_21.814102\\model-00018-1.18154-0.54148-1.43078-0.46000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1499 - categorical_accuracy: 0.5566 - val_loss: 1.4032 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.43078 to 1.40318, saving model to model_init_2021-10-2723_54_21.814102\\model-00019-1.14988-0.55656-1.40318-0.46000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1331 - categorical_accuracy: 0.5943 - val_loss: 1.3857 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.40318 to 1.38573, saving model to model_init_2021-10-2723_54_21.814102\\model-00020-1.13311-0.59427-1.38573-0.44000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1170 - categorical_accuracy: 0.5837 - val_loss: 1.3570 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.38573 to 1.35696, saving model to model_init_2021-10-2723_54_21.814102\\model-00021-1.11701-0.58371-1.35696-0.43000.h5\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1454 - categorical_accuracy: 0.5551 - val_loss: 1.3341 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.35696 to 1.33410, saving model to model_init_2021-10-2723_54_21.814102\\model-00022-1.14544-0.55505-1.33410-0.49000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1110 - categorical_accuracy: 0.5943 - val_loss: 1.3064 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.33410 to 1.30644, saving model to model_init_2021-10-2723_54_21.814102\\model-00023-1.11101-0.59427-1.30644-0.48000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0836 - categorical_accuracy: 0.5913 - val_loss: 1.3090 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.30644\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0832 - categorical_accuracy: 0.5792 - val_loss: 1.2254 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.30644 to 1.22540, saving model to model_init_2021-10-2723_54_21.814102\\model-00025-1.08319-0.57919-1.22540-0.52000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0910 - categorical_accuracy: 0.5732 - val_loss: 1.2168 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.22540 to 1.21677, saving model to model_init_2021-10-2723_54_21.814102\\model-00026-1.09098-0.57315-1.21677-0.53000.h5\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 56s 3s/step - loss: 1.0616 - categorical_accuracy: 0.6078 - val_loss: 1.2244 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.21677\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0643 - categorical_accuracy: 0.5958 - val_loss: 1.1777 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.21677 to 1.17775, saving model to model_init_2021-10-2723_54_21.814102\\model-00028-1.06430-0.59578-1.17775-0.54000.h5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0490 - categorical_accuracy: 0.6305 - val_loss: 1.2451 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.17775\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0341 - categorical_accuracy: 0.6305 - val_loss: 1.1766 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.17775 to 1.17661, saving model to model_init_2021-10-2723_54_21.814102\\model-00030-1.03409-0.63047-1.17661-0.53000.h5\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0134 - categorical_accuracy: 0.6229 - val_loss: 1.1704 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.17661 to 1.17035, saving model to model_init_2021-10-2723_54_21.814102\\model-00031-1.01338-0.62293-1.17035-0.54000.h5\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0125 - categorical_accuracy: 0.6395 - val_loss: 1.1498 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.17035 to 1.14981, saving model to model_init_2021-10-2723_54_21.814102\\model-00032-1.01252-0.63952-1.14981-0.56000.h5\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9926 - categorical_accuracy: 0.6305 - val_loss: 1.1501 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.14981\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0059 - categorical_accuracy: 0.6229 - val_loss: 1.1651 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.14981\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9709 - categorical_accuracy: 0.6546 - val_loss: 1.1386 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.14981 to 1.13859, saving model to model_init_2021-10-2723_54_21.814102\\model-00035-0.97092-0.65460-1.13859-0.55000.h5\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9726 - categorical_accuracy: 0.6531 - val_loss: 1.2043 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.13859\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9464 - categorical_accuracy: 0.6591 - val_loss: 1.0197 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.13859 to 1.01965, saving model to model_init_2021-10-2723_54_21.814102\\model-00037-0.94641-0.65913-1.01965-0.59000.h5\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.9484 - categorical_accuracy: 0.6606 - val_loss: 1.0942 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.01965\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9402 - categorical_accuracy: 0.6606 - val_loss: 1.1183 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.01965\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9178 - categorical_accuracy: 0.6621 - val_loss: 1.1049 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.01965\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9303 - categorical_accuracy: 0.6516 - val_loss: 1.1603 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.01965\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.9021 - categorical_accuracy: 0.6953 - val_loss: 1.1501 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.01965\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8969 - categorical_accuracy: 0.6697 - val_loss: 1.1164 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.01965\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8888 - categorical_accuracy: 0.6878 - val_loss: 1.1228 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.01965\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8698 - categorical_accuracy: 0.7119 - val_loss: 1.1211 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.01965\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.8609 - categorical_accuracy: 0.7044 - val_loss: 1.0714 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.01965\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8896 - categorical_accuracy: 0.6893 - val_loss: 1.0991 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.01965\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8661 - categorical_accuracy: 0.6998 - val_loss: 0.9982 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.01965 to 0.99824, saving model to model_init_2021-10-2723_54_21.814102\\model-00048-0.86609-0.69985-0.99824-0.64000.h5\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8530 - categorical_accuracy: 0.6983 - val_loss: 1.1152 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.99824\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.8498 - categorical_accuracy: 0.6998 - val_loss: 1.1003 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.99824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2572619ea00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_14.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_14 is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding one more conv2D layer to the first model and also using 50% dropouts in dense layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_15 = Sequential()\n",
    "\n",
    "model_15.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "model_15.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_15.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_15.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_15.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_15.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_15.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_15.add(TimeDistributed(Conv2D(128, (2,2),padding='same', activation='relu')))\n",
    "model_15.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_15.add(TimeDistributed(BatchNormalization()))\n",
    "model_15.add(Dropout(0.25))\n",
    "\n",
    "model_15.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_15.add(Dense(128, activation='relu'))\n",
    "model_15.add(Dropout(0.5))\n",
    "model_15.add(Dense(64, activation='relu'))\n",
    "model_15.add(Dropout(0.5))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_15.add(GRU(128, return_sequences=False))\n",
    "model_15.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_18 (TimeDis (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 20, 5, 5, 128)     32896     \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 20, 2, 2, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 20, 2, 2, 128)     512       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 20, 2, 2, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 20, 512)           0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20, 128)           65664     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 20, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 196,757\n",
      "Trainable params: 196,501\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_15.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_15.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.5981 - categorical_accuracy: 0.2474 - val_loss: 1.6071 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60714, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.59811-0.24736-1.60714-0.24000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.5696 - categorical_accuracy: 0.2941 - val_loss: 1.6035 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60714 to 1.60347, saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.56963-0.29412-1.60347-0.23000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.5391 - categorical_accuracy: 0.3032 - val_loss: 1.6022 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.60347 to 1.60216, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.53910-0.30317-1.60216-0.19000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.5173 - categorical_accuracy: 0.3092 - val_loss: 1.6023 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.60216\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.4942 - categorical_accuracy: 0.3529 - val_loss: 1.6014 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.60216 to 1.60136, saving model to model_init_2021-10-2723_54_21.814102\\model-00005-1.49417-0.35294-1.60136-0.20000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4664 - categorical_accuracy: 0.3876 - val_loss: 1.5964 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.60136 to 1.59643, saving model to model_init_2021-10-2723_54_21.814102\\model-00006-1.46640-0.38763-1.59643-0.18000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4618 - categorical_accuracy: 0.3680 - val_loss: 1.5968 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.59643\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.4384 - categorical_accuracy: 0.3982 - val_loss: 1.5964 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.59643 to 1.59640, saving model to model_init_2021-10-2723_54_21.814102\\model-00008-1.43837-0.39819-1.59640-0.20000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4319 - categorical_accuracy: 0.3831 - val_loss: 1.5893 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.59640 to 1.58932, saving model to model_init_2021-10-2723_54_21.814102\\model-00009-1.43185-0.38311-1.58932-0.20000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4237 - categorical_accuracy: 0.3741 - val_loss: 1.5903 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.58932\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4019 - categorical_accuracy: 0.4012 - val_loss: 1.5807 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.58932 to 1.58066, saving model to model_init_2021-10-2723_54_21.814102\\model-00011-1.40187-0.40121-1.58066-0.22000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.4052 - categorical_accuracy: 0.3680 - val_loss: 1.5698 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.58066 to 1.56982, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.40525-0.36802-1.56982-0.24000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3707 - categorical_accuracy: 0.4268 - val_loss: 1.5648 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.56982 to 1.56484, saving model to model_init_2021-10-2723_54_21.814102\\model-00013-1.37074-0.42685-1.56484-0.29000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3554 - categorical_accuracy: 0.4223 - val_loss: 1.5450 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.56484 to 1.54498, saving model to model_init_2021-10-2723_54_21.814102\\model-00014-1.35538-0.42232-1.54498-0.25000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3747 - categorical_accuracy: 0.3846 - val_loss: 1.5398 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.54498 to 1.53979, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.37469-0.38462-1.53979-0.32000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.3441 - categorical_accuracy: 0.4314 - val_loss: 1.5407 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.53979\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3517 - categorical_accuracy: 0.4027 - val_loss: 1.5250 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.53979 to 1.52500, saving model to model_init_2021-10-2723_54_21.814102\\model-00017-1.35171-0.40271-1.52500-0.36000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3586 - categorical_accuracy: 0.4027 - val_loss: 1.5009 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.52500 to 1.50092, saving model to model_init_2021-10-2723_54_21.814102\\model-00018-1.35857-0.40271-1.50092-0.40000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3483 - categorical_accuracy: 0.4238 - val_loss: 1.5114 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.50092\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.3355 - categorical_accuracy: 0.4253 - val_loss: 1.4943 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.50092 to 1.49432, saving model to model_init_2021-10-2723_54_21.814102\\model-00020-1.33545-0.42534-1.49432-0.39000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3245 - categorical_accuracy: 0.4811 - val_loss: 1.4791 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.49432 to 1.47907, saving model to model_init_2021-10-2723_54_21.814102\\model-00021-1.32450-0.48115-1.47907-0.40000.h5\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2960 - categorical_accuracy: 0.4208 - val_loss: 1.4827 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.47907\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3090 - categorical_accuracy: 0.4661 - val_loss: 1.4503 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.47907 to 1.45029, saving model to model_init_2021-10-2723_54_21.814102\\model-00023-1.30897-0.46606-1.45029-0.46000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2985 - categorical_accuracy: 0.4510 - val_loss: 1.4449 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.45029 to 1.44486, saving model to model_init_2021-10-2723_54_21.814102\\model-00024-1.29845-0.45098-1.44486-0.44000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3155 - categorical_accuracy: 0.4555 - val_loss: 1.4358 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.44486 to 1.43580, saving model to model_init_2021-10-2723_54_21.814102\\model-00025-1.31546-0.45551-1.43580-0.43000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2665 - categorical_accuracy: 0.4721 - val_loss: 1.3866 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.43580 to 1.38659, saving model to model_init_2021-10-2723_54_21.814102\\model-00026-1.26654-0.47210-1.38659-0.42000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2970 - categorical_accuracy: 0.4540 - val_loss: 1.4478 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.38659\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.2890 - categorical_accuracy: 0.4751 - val_loss: 1.4337 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.38659\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2508 - categorical_accuracy: 0.4917 - val_loss: 1.4096 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.38659\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2848 - categorical_accuracy: 0.4540 - val_loss: 1.4133 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.38659\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2494 - categorical_accuracy: 0.4766 - val_loss: 1.4293 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.38659\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2360 - categorical_accuracy: 0.4721 - val_loss: 1.4206 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.38659\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.2541 - categorical_accuracy: 0.4736 - val_loss: 1.4062 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.38659\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2641 - categorical_accuracy: 0.4781 - val_loss: 1.4277 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.38659\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2531 - categorical_accuracy: 0.4887 - val_loss: 1.4455 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.38659\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2321 - categorical_accuracy: 0.4766 - val_loss: 1.4217 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.38659\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2284 - categorical_accuracy: 0.4932 - val_loss: 1.4058 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.38659\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2382 - categorical_accuracy: 0.4811 - val_loss: 1.4134 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.38659\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2300 - categorical_accuracy: 0.4842 - val_loss: 1.3922 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.38659\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.2288 - categorical_accuracy: 0.4811 - val_loss: 1.3890 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.38659\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2310 - categorical_accuracy: 0.4992 - val_loss: 1.4040 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.38659\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2189 - categorical_accuracy: 0.4781 - val_loss: 1.4613 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.38659\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2209 - categorical_accuracy: 0.4872 - val_loss: 1.4375 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.38659\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1920 - categorical_accuracy: 0.5113 - val_loss: 1.4034 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.38659\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2243 - categorical_accuracy: 0.5008 - val_loss: 1.4081 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.38659\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2042 - categorical_accuracy: 0.5023 - val_loss: 1.4565 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.38659\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1908 - categorical_accuracy: 0.5143 - val_loss: 1.2900 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.38659 to 1.29001, saving model to model_init_2021-10-2723_54_21.814102\\model-00047-1.19081-0.51433-1.29001-0.55000.h5\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2145 - categorical_accuracy: 0.5173 - val_loss: 1.4214 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.29001\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1777 - categorical_accuracy: 0.5339 - val_loss: 1.4058 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.29001\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1992 - categorical_accuracy: 0.5249 - val_loss: 1.4076 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.29001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2572619e1f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_15.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of Model_15 is not good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying model 1 with 50% dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_16 = Sequential()\n",
    "\n",
    "model_16.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "\n",
    "\n",
    "model_16.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_16.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_16.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_16.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_16.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_16.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_16.add(TimeDistributed(BatchNormalization()))\n",
    "model_16.add(Dropout(0.25))\n",
    "\n",
    "model_16.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_16.add(Dense(128, activation='relu'))\n",
    "model_16.add(Dropout(0.5))\n",
    "model_16.add(Dense(64, activation='relu'))\n",
    "model_16.add(Dropout(0.5))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_16.add(GRU(128, return_sequences=False))\n",
    "model_16.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_29 (TimeDis (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20, 128)           204928    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 20, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 302,869\n",
      "Trainable params: 302,741\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_16.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_16.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.6289 - categorical_accuracy: 0.1946 - val_loss: 1.6070 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60701, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.62886-0.19457-1.60701-0.21000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.5866 - categorical_accuracy: 0.2624 - val_loss: 1.6055 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60701 to 1.60550, saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.58661-0.26244-1.60550-0.22000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.5501 - categorical_accuracy: 0.3167 - val_loss: 1.6023 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.60550 to 1.60233, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.55008-0.31674-1.60233-0.23000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.5281 - categorical_accuracy: 0.3439 - val_loss: 1.6016 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.60233 to 1.60156, saving model to model_init_2021-10-2723_54_21.814102\\model-00004-1.52813-0.34389-1.60156-0.22000.h5\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.5090 - categorical_accuracy: 0.3469 - val_loss: 1.5963 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.60156 to 1.59628, saving model to model_init_2021-10-2723_54_21.814102\\model-00005-1.50901-0.34691-1.59628-0.26000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.4884 - categorical_accuracy: 0.4027 - val_loss: 1.5931 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.59628 to 1.59314, saving model to model_init_2021-10-2723_54_21.814102\\model-00006-1.48844-0.40271-1.59314-0.29000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4651 - categorical_accuracy: 0.4042 - val_loss: 1.5892 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.59314 to 1.58925, saving model to model_init_2021-10-2723_54_21.814102\\model-00007-1.46513-0.40422-1.58925-0.27000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.4458 - categorical_accuracy: 0.4103 - val_loss: 1.5776 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.58925 to 1.57757, saving model to model_init_2021-10-2723_54_21.814102\\model-00008-1.44579-0.41026-1.57757-0.37000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.4151 - categorical_accuracy: 0.4268 - val_loss: 1.5813 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.57757\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.3825 - categorical_accuracy: 0.4646 - val_loss: 1.5702 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.57757 to 1.57024, saving model to model_init_2021-10-2723_54_21.814102\\model-00010-1.38248-0.46456-1.57024-0.33000.h5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3713 - categorical_accuracy: 0.4706 - val_loss: 1.5628 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.57024 to 1.56284, saving model to model_init_2021-10-2723_54_21.814102\\model-00011-1.37128-0.47059-1.56284-0.33000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3667 - categorical_accuracy: 0.4525 - val_loss: 1.5436 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.56284 to 1.54358, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.36666-0.45249-1.54358-0.36000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3634 - categorical_accuracy: 0.4706 - val_loss: 1.5451 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.54358\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.3248 - categorical_accuracy: 0.4857 - val_loss: 1.5307 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.54358 to 1.53071, saving model to model_init_2021-10-2723_54_21.814102\\model-00014-1.32483-0.48567-1.53071-0.39000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3231 - categorical_accuracy: 0.4857 - val_loss: 1.5153 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.53071 to 1.51528, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.32313-0.48567-1.51528-0.41000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3164 - categorical_accuracy: 0.4600 - val_loss: 1.5020 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.51528 to 1.50198, saving model to model_init_2021-10-2723_54_21.814102\\model-00016-1.31641-0.46003-1.50198-0.42000.h5\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2831 - categorical_accuracy: 0.4992 - val_loss: 1.4978 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.50198 to 1.49784, saving model to model_init_2021-10-2723_54_21.814102\\model-00017-1.28309-0.49925-1.49784-0.39000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.2717 - categorical_accuracy: 0.5038 - val_loss: 1.4625 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.49784 to 1.46248, saving model to model_init_2021-10-2723_54_21.814102\\model-00018-1.27169-0.50377-1.46248-0.43000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 1.2752 - categorical_accuracy: 0.5113 - val_loss: 1.4475 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.46248 to 1.44748, saving model to model_init_2021-10-2723_54_21.814102\\model-00019-1.27522-0.51131-1.44748-0.43000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 62s 3s/step - loss: 1.2590 - categorical_accuracy: 0.5173 - val_loss: 1.4321 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.44748 to 1.43213, saving model to model_init_2021-10-2723_54_21.814102\\model-00020-1.25895-0.51735-1.43213-0.45000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2233 - categorical_accuracy: 0.5264 - val_loss: 1.3903 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.43213 to 1.39031, saving model to model_init_2021-10-2723_54_21.814102\\model-00021-1.22328-0.52640-1.39031-0.45000.h5\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2343 - categorical_accuracy: 0.5294 - val_loss: 1.3956 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.39031\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.2122 - categorical_accuracy: 0.5339 - val_loss: 1.3694 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.39031 to 1.36936, saving model to model_init_2021-10-2723_54_21.814102\\model-00023-1.21215-0.53394-1.36936-0.44000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2156 - categorical_accuracy: 0.5173 - val_loss: 1.3402 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.36936 to 1.34016, saving model to model_init_2021-10-2723_54_21.814102\\model-00024-1.21558-0.51735-1.34016-0.45000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2004 - categorical_accuracy: 0.5415 - val_loss: 1.3538 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.34016\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.1687 - categorical_accuracy: 0.5671 - val_loss: 1.3115 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.34016 to 1.31154, saving model to model_init_2021-10-2723_54_21.814102\\model-00026-1.16875-0.56712-1.31154-0.47000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1976 - categorical_accuracy: 0.5279 - val_loss: 1.2969 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.31154 to 1.29689, saving model to model_init_2021-10-2723_54_21.814102\\model-00027-1.19756-0.52790-1.29689-0.47000.h5\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 56s 3s/step - loss: 1.1790 - categorical_accuracy: 0.5385 - val_loss: 1.2787 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.29689 to 1.27874, saving model to model_init_2021-10-2723_54_21.814102\\model-00028-1.17900-0.53846-1.27874-0.45000.h5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1848 - categorical_accuracy: 0.5460 - val_loss: 1.2661 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.27874 to 1.26614, saving model to model_init_2021-10-2723_54_21.814102\\model-00029-1.18476-0.54600-1.26614-0.52000.h5\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1505 - categorical_accuracy: 0.5535 - val_loss: 1.2599 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.26614 to 1.25986, saving model to model_init_2021-10-2723_54_21.814102\\model-00030-1.15048-0.55354-1.25986-0.50000.h5\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1387 - categorical_accuracy: 0.5701 - val_loss: 1.2507 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.25986 to 1.25067, saving model to model_init_2021-10-2723_54_21.814102\\model-00031-1.13872-0.57014-1.25067-0.50000.h5\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1275 - categorical_accuracy: 0.5626 - val_loss: 1.2561 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.25067\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1444 - categorical_accuracy: 0.5716 - val_loss: 1.1653 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.25067 to 1.16526, saving model to model_init_2021-10-2723_54_21.814102\\model-00033-1.14435-0.57164-1.16526-0.57000.h5\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 1.1149 - categorical_accuracy: 0.6003 - val_loss: 1.2462 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.16526\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.1024 - categorical_accuracy: 0.5867 - val_loss: 1.2292 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.16526\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1150 - categorical_accuracy: 0.5792 - val_loss: 1.1749 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.16526\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0661 - categorical_accuracy: 0.6139 - val_loss: 1.3397 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.16526\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0995 - categorical_accuracy: 0.5732 - val_loss: 1.2011 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.16526\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0672 - categorical_accuracy: 0.5867 - val_loss: 1.2132 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.16526\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.0684 - categorical_accuracy: 0.5943 - val_loss: 1.2806 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.16526\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0938 - categorical_accuracy: 0.5928 - val_loss: 1.2378 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.16526\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.0512 - categorical_accuracy: 0.6033 - val_loss: 1.2041 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.16526\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0652 - categorical_accuracy: 0.5928 - val_loss: 1.2014 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.16526\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0784 - categorical_accuracy: 0.6003 - val_loss: 1.0974 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.16526 to 1.09740, saving model to model_init_2021-10-2723_54_21.814102\\model-00044-1.07835-0.60030-1.09740-0.57000.h5\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0501 - categorical_accuracy: 0.6063 - val_loss: 1.2238 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.09740\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0402 - categorical_accuracy: 0.5988 - val_loss: 1.1796 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.09740\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0396 - categorical_accuracy: 0.6139 - val_loss: 1.1836 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.09740\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0489 - categorical_accuracy: 0.5897 - val_loss: 1.1440 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.09740\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9893 - categorical_accuracy: 0.6290 - val_loss: 1.1658 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.09740\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0346 - categorical_accuracy: 0.6078 - val_loss: 1.1660 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.09740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2572612a040>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_16.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of model_16 is not good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying with batch normalization after every MaxPool Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_17 = Sequential()\n",
    "\n",
    "model_17.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "model_17.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_17.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model_17.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model_17.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_17.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model_17.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model_17.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_17.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model_17.add(TimeDistributed(BatchNormalization()))\n",
    "model_17.add(Dropout(0.25))\n",
    "\n",
    "model_17.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_17.add(Dense(128, activation='relu'))\n",
    "model_17.add(Dropout(0.5))\n",
    "model_17.add(Dense(64, activation='relu'))\n",
    "model_17.add(Dropout(0.5))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_17.add(GRU(128, return_sequences=False))\n",
    "model_17.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_38 (TimeDis (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_39 (TimeDis (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_40 (TimeDis (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_41 (TimeDis (None, 20, 21, 21, 16)    64        \n",
      "_________________________________________________________________\n",
      "time_distributed_42 (TimeDis (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_43 (TimeDis (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_44 (TimeDis (None, 20, 10, 10, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_45 (TimeDis (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_46 (TimeDis (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_47 (TimeDis (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_48 (TimeDis (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20, 128)           204928    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 20, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 303,061\n",
      "Trainable params: 302,837\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_17.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_17.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.6970 - categorical_accuracy: 0.1961 - val_loss: 1.6080 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60798, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.69696-0.19608-1.60798-0.21000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.6197 - categorical_accuracy: 0.2368 - val_loss: 1.6064 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60798 to 1.60641, saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.61973-0.23680-1.60641-0.28000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.5788 - categorical_accuracy: 0.2866 - val_loss: 1.6019 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.60641 to 1.60188, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.57879-0.28658-1.60188-0.24000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.5272 - categorical_accuracy: 0.2956 - val_loss: 1.6033 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.60188\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.5043 - categorical_accuracy: 0.3394 - val_loss: 1.6024 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.60188\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.4742 - categorical_accuracy: 0.3650 - val_loss: 1.6131 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.60188\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.4555 - categorical_accuracy: 0.3484 - val_loss: 1.5653 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.60188 to 1.56527, saving model to model_init_2021-10-2723_54_21.814102\\model-00007-1.45552-0.34842-1.56527-0.31000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4430 - categorical_accuracy: 0.3952 - val_loss: 1.6129 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.56527\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.3778 - categorical_accuracy: 0.4404 - val_loss: 1.6087 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.56527\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.3750 - categorical_accuracy: 0.4344 - val_loss: 1.6116 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.56527\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.3663 - categorical_accuracy: 0.4163 - val_loss: 1.6113 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.56527\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.3626 - categorical_accuracy: 0.4570 - val_loss: 1.5889 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.56527\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3125 - categorical_accuracy: 0.4510 - val_loss: 1.6025 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.56527\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3402 - categorical_accuracy: 0.4555 - val_loss: 1.6101 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.56527\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3118 - categorical_accuracy: 0.4570 - val_loss: 1.5977 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.56527\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2979 - categorical_accuracy: 0.4510 - val_loss: 1.5784 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.56527\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2845 - categorical_accuracy: 0.4751 - val_loss: 1.5587 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.56527 to 1.55872, saving model to model_init_2021-10-2723_54_21.814102\\model-00017-1.28446-0.47511-1.55872-0.35000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2630 - categorical_accuracy: 0.4887 - val_loss: 1.5130 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.55872 to 1.51303, saving model to model_init_2021-10-2723_54_21.814102\\model-00018-1.26305-0.48869-1.51303-0.41000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2729 - categorical_accuracy: 0.4857 - val_loss: 1.4743 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.51303 to 1.47434, saving model to model_init_2021-10-2723_54_21.814102\\model-00019-1.27294-0.48567-1.47434-0.40000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2332 - categorical_accuracy: 0.5249 - val_loss: 1.5291 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.47434\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2554 - categorical_accuracy: 0.5279 - val_loss: 1.4838 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.47434\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.2163 - categorical_accuracy: 0.5173 - val_loss: 1.5099 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.47434\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2264 - categorical_accuracy: 0.5143 - val_loss: 1.4165 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.47434 to 1.41653, saving model to model_init_2021-10-2723_54_21.814102\\model-00023-1.22637-0.51433-1.41653-0.40000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2099 - categorical_accuracy: 0.5324 - val_loss: 1.4006 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.41653 to 1.40064, saving model to model_init_2021-10-2723_54_21.814102\\model-00024-1.20993-0.53243-1.40064-0.40000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2011 - categorical_accuracy: 0.5143 - val_loss: 1.3632 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.40064 to 1.36317, saving model to model_init_2021-10-2723_54_21.814102\\model-00025-1.20113-0.51433-1.36317-0.41000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2091 - categorical_accuracy: 0.5098 - val_loss: 1.3518 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.36317 to 1.35176, saving model to model_init_2021-10-2723_54_21.814102\\model-00026-1.20905-0.50980-1.35176-0.42000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2152 - categorical_accuracy: 0.4917 - val_loss: 1.2888 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.35176 to 1.28880, saving model to model_init_2021-10-2723_54_21.814102\\model-00027-1.21521-0.49170-1.28880-0.56000.h5\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1737 - categorical_accuracy: 0.5053 - val_loss: 1.2517 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.28880 to 1.25175, saving model to model_init_2021-10-2723_54_21.814102\\model-00028-1.17370-0.50528-1.25175-0.53000.h5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1691 - categorical_accuracy: 0.5490 - val_loss: 1.2595 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.25175\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1570 - categorical_accuracy: 0.5430 - val_loss: 1.2110 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.25175 to 1.21104, saving model to model_init_2021-10-2723_54_21.814102\\model-00030-1.15700-0.54299-1.21104-0.52000.h5\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1636 - categorical_accuracy: 0.5400 - val_loss: 1.2104 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.21104 to 1.21041, saving model to model_init_2021-10-2723_54_21.814102\\model-00031-1.16361-0.53997-1.21041-0.53000.h5\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 54s 3s/step - loss: 1.1714 - categorical_accuracy: 0.5324 - val_loss: 1.1992 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.21041 to 1.19915, saving model to model_init_2021-10-2723_54_21.814102\\model-00032-1.17137-0.53243-1.19915-0.54000.h5\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1050 - categorical_accuracy: 0.5747 - val_loss: 1.1876 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.19915 to 1.18757, saving model to model_init_2021-10-2723_54_21.814102\\model-00033-1.10495-0.57466-1.18757-0.53000.h5\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1116 - categorical_accuracy: 0.5641 - val_loss: 1.2294 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.18757\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1250 - categorical_accuracy: 0.5792 - val_loss: 1.1501 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.18757 to 1.15012, saving model to model_init_2021-10-2723_54_21.814102\\model-00035-1.12504-0.57919-1.15012-0.54000.h5\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0755 - categorical_accuracy: 0.5837 - val_loss: 1.1933 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.15012\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1281 - categorical_accuracy: 0.5626 - val_loss: 1.1434 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.15012 to 1.14343, saving model to model_init_2021-10-2723_54_21.814102\\model-00037-1.12808-0.56259-1.14343-0.53000.h5\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0929 - categorical_accuracy: 0.5882 - val_loss: 1.0866 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.14343 to 1.08657, saving model to model_init_2021-10-2723_54_21.814102\\model-00038-1.09291-0.58824-1.08657-0.55000.h5\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0855 - categorical_accuracy: 0.5852 - val_loss: 1.0178 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.08657 to 1.01784, saving model to model_init_2021-10-2723_54_21.814102\\model-00039-1.08546-0.58522-1.01784-0.58000.h5\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0696 - categorical_accuracy: 0.5928 - val_loss: 1.1410 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.01784\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0692 - categorical_accuracy: 0.6154 - val_loss: 1.1265 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.01784\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0455 - categorical_accuracy: 0.6003 - val_loss: 0.9932 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.01784 to 0.99319, saving model to model_init_2021-10-2723_54_21.814102\\model-00042-1.04553-0.60030-0.99319-0.57000.h5\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0304 - categorical_accuracy: 0.6290 - val_loss: 1.1532 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.99319\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0310 - categorical_accuracy: 0.6094 - val_loss: 1.0776 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.99319\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0002 - categorical_accuracy: 0.6395 - val_loss: 1.1099 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.99319\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0400 - categorical_accuracy: 0.6139 - val_loss: 1.0164 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.99319\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0373 - categorical_accuracy: 0.6199 - val_loss: 1.2151 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.99319\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0245 - categorical_accuracy: 0.6078 - val_loss: 1.1183 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.99319\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0160 - categorical_accuracy: 0.6124 - val_loss: 1.1170 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.99319\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0157 - categorical_accuracy: 0.6214 - val_loss: 1.1100 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.99319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25725de9ca0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_17.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of model_17 is not good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying dropouts after every conv2D layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_18 = Sequential()\n",
    "\n",
    "model_18.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "model_18.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_18.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model_18.add(TimeDistributed(BatchNormalization()))\n",
    "model_18.add(Dropout(0.25))\n",
    "\n",
    "model_18.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_18.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model_18.add(TimeDistributed(BatchNormalization()))\n",
    "model_18.add(Dropout(0.25))\n",
    "\n",
    "model_18.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_18.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model_18.add(TimeDistributed(BatchNormalization()))\n",
    "model_18.add(Dropout(0.25))\n",
    "\n",
    "model_18.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_18.add(Dense(128, activation='relu'))\n",
    "model_18.add(Dropout(0.5))\n",
    "model_18.add(Dense(64, activation='relu'))\n",
    "model_18.add(Dropout(0.5))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_18.add(GRU(128, return_sequences=False))\n",
    "model_18.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_49 (TimeDis (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_50 (TimeDis (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_51 (TimeDis (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_52 (TimeDis (None, 20, 21, 21, 16)    64        \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_53 (TimeDis (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_54 (TimeDis (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_55 (TimeDis (None, 20, 10, 10, 32)    128       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_56 (TimeDis (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_57 (TimeDis (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_58 (TimeDis (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_59 (TimeDis (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 20, 128)           204928    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 20, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 303,061\n",
      "Trainable params: 302,837\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_18.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_18.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.6948 - categorical_accuracy: 0.2202 - val_loss: 1.6121 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61210, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.69483-0.22021-1.61210-0.16000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.6250 - categorical_accuracy: 0.2624 - val_loss: 1.6203 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.61210\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.5976 - categorical_accuracy: 0.2670 - val_loss: 1.6297 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.61210\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.5412 - categorical_accuracy: 0.3183 - val_loss: 1.6381 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.61210\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.5185 - categorical_accuracy: 0.3198 - val_loss: 1.6709 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.61210\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.5030 - categorical_accuracy: 0.3514 - val_loss: 1.6854 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.61210\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4909 - categorical_accuracy: 0.3303 - val_loss: 1.7136 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.61210\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.4703 - categorical_accuracy: 0.3484 - val_loss: 1.7485 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.61210\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.4563 - categorical_accuracy: 0.3620 - val_loss: 1.7107 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.61210\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.4488 - categorical_accuracy: 0.3831 - val_loss: 1.8303 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.61210\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.4534 - categorical_accuracy: 0.3786 - val_loss: 1.8143 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.61210\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4377 - categorical_accuracy: 0.3650 - val_loss: 1.8250 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.61210\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.3735 - categorical_accuracy: 0.4359 - val_loss: 1.8909 - val_categorical_accuracy: 0.1200\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.61210\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.3972 - categorical_accuracy: 0.4057 - val_loss: 1.8419 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.61210\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3948 - categorical_accuracy: 0.3952 - val_loss: 1.8812 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.61210\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4258 - categorical_accuracy: 0.3831 - val_loss: 1.8655 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.61210\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3499 - categorical_accuracy: 0.4238 - val_loss: 1.9038 - val_categorical_accuracy: 0.1400\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.61210\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.3435 - categorical_accuracy: 0.4284 - val_loss: 1.8829 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.61210\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3581 - categorical_accuracy: 0.4072 - val_loss: 1.9295 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.61210\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3604 - categorical_accuracy: 0.4163 - val_loss: 1.9784 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.61210\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3499 - categorical_accuracy: 0.4118 - val_loss: 1.9198 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.61210\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.3222 - categorical_accuracy: 0.4374 - val_loss: 1.9426 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.61210\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3535 - categorical_accuracy: 0.4118 - val_loss: 1.9377 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.61210\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2933 - categorical_accuracy: 0.4525 - val_loss: 1.9392 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.61210\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3248 - categorical_accuracy: 0.4389 - val_loss: 1.9508 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.61210\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3217 - categorical_accuracy: 0.4525 - val_loss: 1.8803 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.61210\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2732 - categorical_accuracy: 0.4842 - val_loss: 1.8850 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.61210\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3621 - categorical_accuracy: 0.4329 - val_loss: 1.8529 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.61210\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3355 - categorical_accuracy: 0.4691 - val_loss: 1.7995 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.61210\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.2993 - categorical_accuracy: 0.4646 - val_loss: 1.8178 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.61210\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2661 - categorical_accuracy: 0.4977 - val_loss: 1.7930 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.61210\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3060 - categorical_accuracy: 0.4676 - val_loss: 1.7255 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.61210\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2917 - categorical_accuracy: 0.4600 - val_loss: 1.5956 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.61210 to 1.59556, saving model to model_init_2021-10-2723_54_21.814102\\model-00033-1.29167-0.46003-1.59556-0.38000.h5\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2812 - categorical_accuracy: 0.4676 - val_loss: 1.7339 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.59556\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2752 - categorical_accuracy: 0.4842 - val_loss: 1.7092 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.59556\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 1.2441 - categorical_accuracy: 0.5143 - val_loss: 1.6178 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.59556\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 1.2150 - categorical_accuracy: 0.4977 - val_loss: 1.6640 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.59556\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 59s 3s/step - loss: 1.2375 - categorical_accuracy: 0.4555 - val_loss: 1.6486 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.59556\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 62s 3s/step - loss: 1.2348 - categorical_accuracy: 0.4977 - val_loss: 1.6238 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.59556\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.2412 - categorical_accuracy: 0.4992 - val_loss: 1.6311 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.59556\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 62s 3s/step - loss: 1.2528 - categorical_accuracy: 0.5053 - val_loss: 1.6336 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.59556\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.2369 - categorical_accuracy: 0.5189 - val_loss: 1.5608 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.59556 to 1.56078, saving model to model_init_2021-10-2723_54_21.814102\\model-00042-1.23688-0.51885-1.56078-0.41000.h5\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.2037 - categorical_accuracy: 0.4977 - val_loss: 1.5840 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.56078\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.1912 - categorical_accuracy: 0.5158 - val_loss: 1.5857 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.56078\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.2152 - categorical_accuracy: 0.4977 - val_loss: 1.4876 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.56078 to 1.48764, saving model to model_init_2021-10-2723_54_21.814102\\model-00045-1.21519-0.49774-1.48764-0.44000.h5\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2226 - categorical_accuracy: 0.4977 - val_loss: 1.6246 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.48764\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1859 - categorical_accuracy: 0.5234 - val_loss: 1.5637 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.48764\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2190 - categorical_accuracy: 0.4962 - val_loss: 1.5351 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.48764\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1892 - categorical_accuracy: 0.5158 - val_loss: 1.5559 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.48764\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1952 - categorical_accuracy: 0.5098 - val_loss: 1.5650 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.48764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x257291da490>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_18.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_18 is overfitting and its overall performance is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying model 1 with 25% dropounts in 1st dense layer and 50% dropouts in 2nd dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_19 = Sequential()\n",
    "\n",
    "model_19.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "model_19.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_19.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_19.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_19.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_19.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_19.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model_19.add(TimeDistributed(BatchNormalization()))\n",
    "model_19.add(Dropout(0.25))\n",
    "\n",
    "model_19.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_19.add(Dense(128, activation='relu'))\n",
    "model_19.add(Dropout(0.25))\n",
    "model_19.add(Dense(64, activation='relu'))\n",
    "model_19.add(Dropout(0.5))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_19.add(GRU(128, return_sequences=False))\n",
    "model_19.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_60 (TimeDis (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_61 (TimeDis (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_62 (TimeDis (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_63 (TimeDis (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_64 (TimeDis (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_65 (TimeDis (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_66 (TimeDis (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_67 (TimeDis (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_68 (TimeDis (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 20, 128)           204928    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 20, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 302,869\n",
      "Trainable params: 302,741\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_19.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_19.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 61s 3s/step - loss: 1.6397 - categorical_accuracy: 0.2323 - val_loss: 1.6041 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60414, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.63967-0.23228-1.60414-0.21000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.5382 - categorical_accuracy: 0.2609 - val_loss: 1.6007 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60414 to 1.60066, saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.53824-0.26094-1.60066-0.23000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.5010 - categorical_accuracy: 0.3183 - val_loss: 1.5907 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.60066 to 1.59072, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.50104-0.31825-1.59072-0.24000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4426 - categorical_accuracy: 0.3801 - val_loss: 1.5919 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.59072\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.4135 - categorical_accuracy: 0.4148 - val_loss: 1.5796 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.59072 to 1.57957, saving model to model_init_2021-10-2723_54_21.814102\\model-00005-1.41355-0.41478-1.57957-0.27000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3910 - categorical_accuracy: 0.4434 - val_loss: 1.5645 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.57957 to 1.56446, saving model to model_init_2021-10-2723_54_21.814102\\model-00006-1.39100-0.44344-1.56446-0.27000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.3763 - categorical_accuracy: 0.4374 - val_loss: 1.5744 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.56446\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3449 - categorical_accuracy: 0.4389 - val_loss: 1.5535 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.56446 to 1.55348, saving model to model_init_2021-10-2723_54_21.814102\\model-00008-1.34486-0.43891-1.55348-0.29000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3305 - categorical_accuracy: 0.4465 - val_loss: 1.5430 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.55348 to 1.54297, saving model to model_init_2021-10-2723_54_21.814102\\model-00009-1.33051-0.44646-1.54297-0.32000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.3121 - categorical_accuracy: 0.4736 - val_loss: 1.5377 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.54297 to 1.53774, saving model to model_init_2021-10-2723_54_21.814102\\model-00010-1.31209-0.47360-1.53774-0.36000.h5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.3125 - categorical_accuracy: 0.4615 - val_loss: 1.5216 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.53774 to 1.52156, saving model to model_init_2021-10-2723_54_21.814102\\model-00011-1.31246-0.46154-1.52156-0.43000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2601 - categorical_accuracy: 0.5008 - val_loss: 1.5074 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.52156 to 1.50739, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.26013-0.50075-1.50739-0.42000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.3056 - categorical_accuracy: 0.4781 - val_loss: 1.4869 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.50739 to 1.48693, saving model to model_init_2021-10-2723_54_21.814102\\model-00013-1.30558-0.47813-1.48693-0.46000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.2225 - categorical_accuracy: 0.5370 - val_loss: 1.4837 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.48693 to 1.48369, saving model to model_init_2021-10-2723_54_21.814102\\model-00014-1.22252-0.53695-1.48369-0.42000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 1.2429 - categorical_accuracy: 0.5128 - val_loss: 1.4420 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.48369 to 1.44201, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.24289-0.51282-1.44201-0.49000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2389 - categorical_accuracy: 0.4977 - val_loss: 1.4257 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.44201 to 1.42569, saving model to model_init_2021-10-2723_54_21.814102\\model-00016-1.23887-0.49774-1.42569-0.48000.h5\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.2228 - categorical_accuracy: 0.5189 - val_loss: 1.4208 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.42569 to 1.42079, saving model to model_init_2021-10-2723_54_21.814102\\model-00017-1.22281-0.51885-1.42079-0.45000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2040 - categorical_accuracy: 0.5128 - val_loss: 1.4242 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.42079\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1878 - categorical_accuracy: 0.5324 - val_loss: 1.3502 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.42079 to 1.35017, saving model to model_init_2021-10-2723_54_21.814102\\model-00019-1.18778-0.53243-1.35017-0.49000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1794 - categorical_accuracy: 0.5249 - val_loss: 1.3634 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.35017\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1721 - categorical_accuracy: 0.5430 - val_loss: 1.3514 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.35017\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1845 - categorical_accuracy: 0.5339 - val_loss: 1.3151 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.35017 to 1.31509, saving model to model_init_2021-10-2723_54_21.814102\\model-00022-1.18451-0.53394-1.31509-0.47000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1599 - categorical_accuracy: 0.5339 - val_loss: 1.3103 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.31509 to 1.31028, saving model to model_init_2021-10-2723_54_21.814102\\model-00023-1.15993-0.53394-1.31028-0.48000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.1413 - categorical_accuracy: 0.5520 - val_loss: 1.3240 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.31028\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1497 - categorical_accuracy: 0.5566 - val_loss: 1.3022 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.31028 to 1.30216, saving model to model_init_2021-10-2723_54_21.814102\\model-00025-1.14966-0.55656-1.30216-0.45000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1492 - categorical_accuracy: 0.5475 - val_loss: 1.2967 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.30216 to 1.29675, saving model to model_init_2021-10-2723_54_21.814102\\model-00026-1.14916-0.54751-1.29675-0.49000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0951 - categorical_accuracy: 0.5958 - val_loss: 1.2971 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.29675\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1140 - categorical_accuracy: 0.5581 - val_loss: 1.2816 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.29675 to 1.28165, saving model to model_init_2021-10-2723_54_21.814102\\model-00028-1.11400-0.55807-1.28165-0.47000.h5\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 58s 3s/step - loss: 1.0996 - categorical_accuracy: 0.5701 - val_loss: 1.2706 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.28165 to 1.27063, saving model to model_init_2021-10-2723_54_21.814102\\model-00029-1.09957-0.57014-1.27063-0.49000.h5\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0951 - categorical_accuracy: 0.5777 - val_loss: 1.3144 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.27063\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.0733 - categorical_accuracy: 0.5988 - val_loss: 1.2587 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.27063 to 1.25872, saving model to model_init_2021-10-2723_54_21.814102\\model-00031-1.07333-0.59879-1.25872-0.46000.h5\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0864 - categorical_accuracy: 0.5732 - val_loss: 1.2573 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.25872 to 1.25732, saving model to model_init_2021-10-2723_54_21.814102\\model-00032-1.08638-0.57315-1.25732-0.49000.h5\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.0714 - categorical_accuracy: 0.5822 - val_loss: 1.2639 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.25732\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0372 - categorical_accuracy: 0.6124 - val_loss: 1.2238 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.25732 to 1.22381, saving model to model_init_2021-10-2723_54_21.814102\\model-00034-1.03723-0.61237-1.22381-0.45000.h5\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0596 - categorical_accuracy: 0.5988 - val_loss: 1.2920 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.22381\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0424 - categorical_accuracy: 0.6033 - val_loss: 1.2549 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.22381\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0222 - categorical_accuracy: 0.6169 - val_loss: 1.2550 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.22381\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0594 - categorical_accuracy: 0.5822 - val_loss: 1.3117 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.22381\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0270 - categorical_accuracy: 0.6350 - val_loss: 1.3846 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.22381\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0277 - categorical_accuracy: 0.6199 - val_loss: 1.2215 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.22381 to 1.22148, saving model to model_init_2021-10-2723_54_21.814102\\model-00040-1.02774-0.61991-1.22148-0.49000.h5\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0159 - categorical_accuracy: 0.6048 - val_loss: 1.2503 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.22148\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0149 - categorical_accuracy: 0.6154 - val_loss: 1.3102 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.22148\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9998 - categorical_accuracy: 0.6063 - val_loss: 1.2880 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.22148\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.9741 - categorical_accuracy: 0.6425 - val_loss: 1.2552 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.22148\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.9503 - categorical_accuracy: 0.6802 - val_loss: 1.2465 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.22148\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9903 - categorical_accuracy: 0.6078 - val_loss: 1.2085 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.22148 to 1.20852, saving model to model_init_2021-10-2723_54_21.814102\\model-00046-0.99034-0.60784-1.20852-0.48000.h5\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9961 - categorical_accuracy: 0.6184 - val_loss: 1.2576 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.20852\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.9647 - categorical_accuracy: 0.6214 - val_loss: 1.2299 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.20852\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9503 - categorical_accuracy: 0.6365 - val_loss: 1.2451 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.20852\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9451 - categorical_accuracy: 0.6516 - val_loss: 1.3162 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.20852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x257299d6310>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_19.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_19 is overfitting and overall performance is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying model 1 with 50% dropounts in 1st dense layer and 25% dropouts in 2nd dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_20 = Sequential()\n",
    "\n",
    "model_20.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "model_20.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_20.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_20.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_20.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_20.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_20.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model_20.add(TimeDistributed(BatchNormalization()))\n",
    "model_20.add(Dropout(0.25))\n",
    "\n",
    "model_20.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_20.add(Dense(128, activation='relu'))\n",
    "model_20.add(Dropout(0.5))\n",
    "model_20.add(Dense(64, activation='relu'))\n",
    "model_20.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_20.add(GRU(128, return_sequences=False))\n",
    "model_20.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_69 (TimeDis (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_70 (TimeDis (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_71 (TimeDis (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_72 (TimeDis (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_73 (TimeDis (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_74 (TimeDis (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_75 (TimeDis (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_76 (TimeDis (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_77 (TimeDis (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 20, 128)           204928    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 20, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 302,869\n",
      "Trainable params: 302,741\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_20.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_20.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.6632 - categorical_accuracy: 0.2428 - val_loss: 1.6013 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60129, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.66323-0.24284-1.60129-0.23000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.5579 - categorical_accuracy: 0.3107 - val_loss: 1.5938 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60129 to 1.59379, saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.55785-0.31071-1.59379-0.26000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4994 - categorical_accuracy: 0.3484 - val_loss: 1.5890 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.59379 to 1.58902, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.49944-0.34842-1.58902-0.25000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4585 - categorical_accuracy: 0.3695 - val_loss: 1.5855 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.58902 to 1.58553, saving model to model_init_2021-10-2723_54_21.814102\\model-00004-1.45851-0.36953-1.58553-0.25000.h5\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4501 - categorical_accuracy: 0.3710 - val_loss: 1.5631 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.58553 to 1.56310, saving model to model_init_2021-10-2723_54_21.814102\\model-00005-1.45007-0.37104-1.56310-0.28000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.4261 - categorical_accuracy: 0.4057 - val_loss: 1.5716 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.56310\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3864 - categorical_accuracy: 0.4042 - val_loss: 1.5541 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.56310 to 1.55415, saving model to model_init_2021-10-2723_54_21.814102\\model-00007-1.38637-0.40422-1.55415-0.29000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3711 - categorical_accuracy: 0.4133 - val_loss: 1.5597 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.55415\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3498 - categorical_accuracy: 0.4268 - val_loss: 1.5383 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.55415 to 1.53828, saving model to model_init_2021-10-2723_54_21.814102\\model-00009-1.34975-0.42685-1.53828-0.24000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.3366 - categorical_accuracy: 0.4208 - val_loss: 1.5268 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.53828 to 1.52679, saving model to model_init_2021-10-2723_54_21.814102\\model-00010-1.33661-0.42081-1.52679-0.30000.h5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3316 - categorical_accuracy: 0.4419 - val_loss: 1.5041 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.52679 to 1.50407, saving model to model_init_2021-10-2723_54_21.814102\\model-00011-1.33159-0.44193-1.50407-0.34000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3179 - categorical_accuracy: 0.4389 - val_loss: 1.4939 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.50407 to 1.49392, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.31792-0.43891-1.49392-0.39000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3184 - categorical_accuracy: 0.4480 - val_loss: 1.4902 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.49392 to 1.49016, saving model to model_init_2021-10-2723_54_21.814102\\model-00013-1.31837-0.44796-1.49016-0.38000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.2789 - categorical_accuracy: 0.4480 - val_loss: 1.4608 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.49016 to 1.46079, saving model to model_init_2021-10-2723_54_21.814102\\model-00014-1.27892-0.44796-1.46079-0.43000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2883 - categorical_accuracy: 0.4525 - val_loss: 1.4469 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.46079 to 1.44691, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.28832-0.45249-1.44691-0.44000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2428 - categorical_accuracy: 0.4977 - val_loss: 1.4397 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.44691 to 1.43968, saving model to model_init_2021-10-2723_54_21.814102\\model-00016-1.24277-0.49774-1.43968-0.46000.h5\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2960 - categorical_accuracy: 0.4480 - val_loss: 1.4473 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.43968\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2394 - categorical_accuracy: 0.5008 - val_loss: 1.4006 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.43968 to 1.40058, saving model to model_init_2021-10-2723_54_21.814102\\model-00018-1.23942-0.50075-1.40058-0.46000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.2372 - categorical_accuracy: 0.4962 - val_loss: 1.3878 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.40058 to 1.38780, saving model to model_init_2021-10-2723_54_21.814102\\model-00019-1.23724-0.49623-1.38780-0.47000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2001 - categorical_accuracy: 0.5294 - val_loss: 1.3229 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.38780 to 1.32294, saving model to model_init_2021-10-2723_54_21.814102\\model-00020-1.20006-0.52941-1.32294-0.48000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1895 - categorical_accuracy: 0.5385 - val_loss: 1.3718 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.32294\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2388 - categorical_accuracy: 0.4842 - val_loss: 1.3676 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.32294\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1975 - categorical_accuracy: 0.5339 - val_loss: 1.3358 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.32294\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1808 - categorical_accuracy: 0.5113 - val_loss: 1.3964 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.32294\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1661 - categorical_accuracy: 0.5264 - val_loss: 1.2679 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.32294 to 1.26786, saving model to model_init_2021-10-2723_54_21.814102\\model-00025-1.16614-0.52640-1.26786-0.54000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.1602 - categorical_accuracy: 0.5551 - val_loss: 1.3036 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.26786\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1411 - categorical_accuracy: 0.5686 - val_loss: 1.3016 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.26786\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1539 - categorical_accuracy: 0.5475 - val_loss: 1.3349 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.26786\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1292 - categorical_accuracy: 0.5430 - val_loss: 1.3249 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.26786\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.1175 - categorical_accuracy: 0.5686 - val_loss: 1.2964 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.26786\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1190 - categorical_accuracy: 0.5505 - val_loss: 1.2743 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.26786\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0999 - categorical_accuracy: 0.5882 - val_loss: 1.2290 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.26786 to 1.22896, saving model to model_init_2021-10-2723_54_21.814102\\model-00032-1.09987-0.58824-1.22896-0.52000.h5\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1390 - categorical_accuracy: 0.5445 - val_loss: 1.2656 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.22896\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0913 - categorical_accuracy: 0.5747 - val_loss: 1.2846 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.22896\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0880 - categorical_accuracy: 0.5641 - val_loss: 1.2581 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.22896\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0680 - categorical_accuracy: 0.6094 - val_loss: 1.2269 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.22896 to 1.22689, saving model to model_init_2021-10-2723_54_21.814102\\model-00036-1.06802-0.60935-1.22689-0.53000.h5\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0599 - categorical_accuracy: 0.6018 - val_loss: 1.3423 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.22689\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0305 - categorical_accuracy: 0.6184 - val_loss: 1.2347 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.22689\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0770 - categorical_accuracy: 0.5807 - val_loss: 1.2440 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.22689\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0294 - categorical_accuracy: 0.6199 - val_loss: 1.1760 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.22689 to 1.17599, saving model to model_init_2021-10-2723_54_21.814102\\model-00040-1.02943-0.61991-1.17599-0.51000.h5\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0321 - categorical_accuracy: 0.6275 - val_loss: 1.3867 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.17599\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.0482 - categorical_accuracy: 0.5988 - val_loss: 1.2413 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.17599\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9884 - categorical_accuracy: 0.6486 - val_loss: 1.2213 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.17599\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0251 - categorical_accuracy: 0.5988 - val_loss: 1.1541 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.17599 to 1.15408, saving model to model_init_2021-10-2723_54_21.814102\\model-00044-1.02512-0.59879-1.15408-0.56000.h5\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0488 - categorical_accuracy: 0.5882 - val_loss: 1.1634 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.15408\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0153 - categorical_accuracy: 0.6184 - val_loss: 1.1860 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.15408\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9687 - categorical_accuracy: 0.6259 - val_loss: 1.2098 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.15408\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0163 - categorical_accuracy: 0.5852 - val_loss: 1.1722 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.15408\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9608 - categorical_accuracy: 0.6561 - val_loss: 1.3407 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.15408\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9880 - categorical_accuracy: 0.6124 - val_loss: 1.2180 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.15408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25ac8fe1550>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_20.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall performance of model_20 is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LSTM instead of GRU in model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "#write your model here\n",
    "\n",
    "model_21 = Sequential()\n",
    "\n",
    "model_21.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "model_21.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_21.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_21.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_21.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_21.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_21.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model_21.add(TimeDistributed(BatchNormalization()))\n",
    "model_21.add(Dropout(0.25))\n",
    "\n",
    "model_21.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_21.add(Dense(128, activation='relu'))\n",
    "model_21.add(Dropout(0.25))\n",
    "model_21.add(Dense(64, activation='relu'))\n",
    "model_21.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_21.add(LSTM(128, return_sequences=False))\n",
    "model_21.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_78 (TimeDis (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_79 (TimeDis (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_80 (TimeDis (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_81 (TimeDis (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_82 (TimeDis (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_83 (TimeDis (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_84 (TimeDis (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_85 (TimeDis (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_86 (TimeDis (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 20, 128)           204928    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 20, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 327,189\n",
      "Trainable params: 327,061\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_21.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_21.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.5811 - categorical_accuracy: 0.2368 - val_loss: 1.6049 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60493, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.58113-0.23680-1.60493-0.25000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.4840 - categorical_accuracy: 0.3620 - val_loss: 1.6037 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60493 to 1.60373, saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.48399-0.36199-1.60373-0.21000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.4329 - categorical_accuracy: 0.4238 - val_loss: 1.5904 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.60373 to 1.59042, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.43286-0.42383-1.59042-0.27000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.3533 - categorical_accuracy: 0.4329 - val_loss: 1.5983 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.59042\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3315 - categorical_accuracy: 0.4585 - val_loss: 1.5869 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.59042 to 1.58688, saving model to model_init_2021-10-2723_54_21.814102\\model-00005-1.33147-0.45852-1.58688-0.23000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2889 - categorical_accuracy: 0.5008 - val_loss: 1.5835 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.58688 to 1.58346, saving model to model_init_2021-10-2723_54_21.814102\\model-00006-1.28888-0.50075-1.58346-0.25000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2824 - categorical_accuracy: 0.4842 - val_loss: 1.5774 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.58346 to 1.57739, saving model to model_init_2021-10-2723_54_21.814102\\model-00007-1.28241-0.48416-1.57739-0.22000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2497 - categorical_accuracy: 0.5113 - val_loss: 1.5658 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.57739 to 1.56578, saving model to model_init_2021-10-2723_54_21.814102\\model-00008-1.24969-0.51131-1.56578-0.22000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.2215 - categorical_accuracy: 0.5339 - val_loss: 1.5493 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.56578 to 1.54930, saving model to model_init_2021-10-2723_54_21.814102\\model-00009-1.22146-0.53394-1.54930-0.24000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.2119 - categorical_accuracy: 0.5234 - val_loss: 1.5354 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.54930 to 1.53541, saving model to model_init_2021-10-2723_54_21.814102\\model-00010-1.21190-0.52338-1.53541-0.23000.h5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1808 - categorical_accuracy: 0.5339 - val_loss: 1.5218 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.53541 to 1.52178, saving model to model_init_2021-10-2723_54_21.814102\\model-00011-1.18078-0.53394-1.52178-0.32000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1594 - categorical_accuracy: 0.5747 - val_loss: 1.4902 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.52178 to 1.49016, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.15940-0.57466-1.49016-0.35000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1380 - categorical_accuracy: 0.5505 - val_loss: 1.4774 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.49016 to 1.47742, saving model to model_init_2021-10-2723_54_21.814102\\model-00013-1.13796-0.55053-1.47742-0.38000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1315 - categorical_accuracy: 0.5822 - val_loss: 1.4701 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.47742 to 1.47014, saving model to model_init_2021-10-2723_54_21.814102\\model-00014-1.13149-0.58220-1.47014-0.41000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0945 - categorical_accuracy: 0.6003 - val_loss: 1.4445 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.47014 to 1.44447, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.09454-0.60030-1.44447-0.39000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.0860 - categorical_accuracy: 0.6003 - val_loss: 1.4238 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.44447 to 1.42381, saving model to model_init_2021-10-2723_54_21.814102\\model-00016-1.08598-0.60030-1.42381-0.43000.h5\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0795 - categorical_accuracy: 0.5792 - val_loss: 1.3940 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.42381 to 1.39399, saving model to model_init_2021-10-2723_54_21.814102\\model-00017-1.07947-0.57919-1.39399-0.44000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0553 - categorical_accuracy: 0.6018 - val_loss: 1.3857 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.39399 to 1.38569, saving model to model_init_2021-10-2723_54_21.814102\\model-00018-1.05527-0.60181-1.38569-0.45000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0230 - categorical_accuracy: 0.6078 - val_loss: 1.3496 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.38569 to 1.34959, saving model to model_init_2021-10-2723_54_21.814102\\model-00019-1.02299-0.60784-1.34959-0.45000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.0458 - categorical_accuracy: 0.6139 - val_loss: 1.3371 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.34959 to 1.33715, saving model to model_init_2021-10-2723_54_21.814102\\model-00020-1.04581-0.61388-1.33715-0.52000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.9961 - categorical_accuracy: 0.6410 - val_loss: 1.3129 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.33715 to 1.31288, saving model to model_init_2021-10-2723_54_21.814102\\model-00021-0.99608-0.64103-1.31288-0.53000.h5\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0067 - categorical_accuracy: 0.6199 - val_loss: 1.2945 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.31288 to 1.29454, saving model to model_init_2021-10-2723_54_21.814102\\model-00022-1.00669-0.61991-1.29454-0.52000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9817 - categorical_accuracy: 0.6380 - val_loss: 1.1834 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.29454 to 1.18343, saving model to model_init_2021-10-2723_54_21.814102\\model-00023-0.98168-0.63801-1.18343-0.55000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.9486 - categorical_accuracy: 0.6546 - val_loss: 1.2582 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.18343\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9354 - categorical_accuracy: 0.6591 - val_loss: 1.2523 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.18343\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9182 - categorical_accuracy: 0.6712 - val_loss: 1.1766 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.18343 to 1.17659, saving model to model_init_2021-10-2723_54_21.814102\\model-00026-0.91823-0.67119-1.17659-0.56000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 0.9190 - categorical_accuracy: 0.6652 - val_loss: 1.3144 - val_categorical_accuracy: 0.4600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00027: val_loss did not improve from 1.17659\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.9066 - categorical_accuracy: 0.6817 - val_loss: 1.2089 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.17659\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8773 - categorical_accuracy: 0.6863 - val_loss: 1.2068 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.17659\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8428 - categorical_accuracy: 0.6878 - val_loss: 1.1850 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.17659\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.8625 - categorical_accuracy: 0.6968 - val_loss: 1.2071 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.17659\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.8314 - categorical_accuracy: 0.7164 - val_loss: 1.1792 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.17659\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8406 - categorical_accuracy: 0.7044 - val_loss: 1.1769 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.17659\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8148 - categorical_accuracy: 0.7089 - val_loss: 1.1302 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.17659 to 1.13023, saving model to model_init_2021-10-2723_54_21.814102\\model-00034-0.81477-0.70890-1.13023-0.60000.h5\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.7845 - categorical_accuracy: 0.7511 - val_loss: 1.2182 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.13023\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.7740 - categorical_accuracy: 0.7496 - val_loss: 1.1790 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.13023\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.7651 - categorical_accuracy: 0.7345 - val_loss: 1.1420 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.13023\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.7486 - categorical_accuracy: 0.7511 - val_loss: 1.1104 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.13023 to 1.11045, saving model to model_init_2021-10-2723_54_21.814102\\model-00038-0.74861-0.75113-1.11045-0.63000.h5\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.7318 - categorical_accuracy: 0.7466 - val_loss: 1.1662 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.11045\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 0.7093 - categorical_accuracy: 0.7647 - val_loss: 1.1247 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.11045\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.7015 - categorical_accuracy: 0.7813 - val_loss: 1.1226 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.11045\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.7056 - categorical_accuracy: 0.7722 - val_loss: 1.0396 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.11045 to 1.03960, saving model to model_init_2021-10-2723_54_21.814102\\model-00042-0.70563-0.77225-1.03960-0.67000.h5\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.6547 - categorical_accuracy: 0.7964 - val_loss: 1.1694 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.03960\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.6727 - categorical_accuracy: 0.7979 - val_loss: 1.0973 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.03960\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.6480 - categorical_accuracy: 0.7949 - val_loss: 1.1123 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.03960\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.6351 - categorical_accuracy: 0.7979 - val_loss: 1.0996 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.03960\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.6185 - categorical_accuracy: 0.8039 - val_loss: 1.0152 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.03960 to 1.01519, saving model to model_init_2021-10-2723_54_21.814102\\model-00047-0.61848-0.80392-1.01519-0.69000.h5\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 0.6230 - categorical_accuracy: 0.7903 - val_loss: 1.0902 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.01519\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.5685 - categorical_accuracy: 0.8341 - val_loss: 1.1038 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.01519\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.6219 - categorical_accuracy: 0.8115 - val_loss: 1.1363 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.01519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25ae4349c70>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_21.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_21 is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying GRU before the dense layers in model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_22 = Sequential()\n",
    "\n",
    "model_22.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "model_22.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_22.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_22.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_22.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_22.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_22.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model_22.add(TimeDistributed(BatchNormalization()))\n",
    "model_22.add(Dropout(0.25))\n",
    "\n",
    "model_22.add(TimeDistributed(Flatten()))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_22.add(GRU(128, return_sequences=False))\n",
    "\n",
    "model_22.add(Dense(128, activation='relu'))\n",
    "model_22.add(Dropout(0.25))\n",
    "model_22.add(Dense(64, activation='relu'))\n",
    "model_22.add(Dropout(0.25))\n",
    "\n",
    "model_22.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_87 (TimeDis (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_88 (TimeDis (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_89 (TimeDis (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_90 (TimeDis (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_91 (TimeDis (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_92 (TimeDis (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_93 (TimeDis (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_94 (TimeDis (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_95 (TimeDis (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 128)               664320    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 703,957\n",
      "Trainable params: 703,829\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_22.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_22.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.5822 - categorical_accuracy: 0.2549 - val_loss: 1.5982 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59823, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.58216-0.25490-1.59823-0.22000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.4932 - categorical_accuracy: 0.3424 - val_loss: 1.5996 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.59823\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.4547 - categorical_accuracy: 0.3590 - val_loss: 1.5924 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.59823 to 1.59238, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.45468-0.35897-1.59238-0.28000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.4135 - categorical_accuracy: 0.3891 - val_loss: 1.5768 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.59238 to 1.57681, saving model to model_init_2021-10-2723_54_21.814102\\model-00004-1.41351-0.38914-1.57681-0.27000.h5\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3737 - categorical_accuracy: 0.4057 - val_loss: 1.5859 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.57681\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.3208 - categorical_accuracy: 0.4434 - val_loss: 1.5725 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.57681 to 1.57247, saving model to model_init_2021-10-2723_54_21.814102\\model-00006-1.32082-0.44344-1.57247-0.27000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3317 - categorical_accuracy: 0.4133 - val_loss: 1.5599 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.57247 to 1.55987, saving model to model_init_2021-10-2723_54_21.814102\\model-00007-1.33173-0.41327-1.55987-0.32000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3156 - categorical_accuracy: 0.4268 - val_loss: 1.5485 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.55987 to 1.54854, saving model to model_init_2021-10-2723_54_21.814102\\model-00008-1.31558-0.42685-1.54854-0.43000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2732 - categorical_accuracy: 0.4525 - val_loss: 1.5079 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.54854 to 1.50790, saving model to model_init_2021-10-2723_54_21.814102\\model-00009-1.27324-0.45249-1.50790-0.42000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.2845 - categorical_accuracy: 0.4465 - val_loss: 1.5170 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.50790\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2314 - categorical_accuracy: 0.5053 - val_loss: 1.5065 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.50790 to 1.50649, saving model to model_init_2021-10-2723_54_21.814102\\model-00011-1.23142-0.50528-1.50649-0.42000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2372 - categorical_accuracy: 0.4872 - val_loss: 1.4999 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.50649 to 1.49989, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.23721-0.48718-1.49989-0.42000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2150 - categorical_accuracy: 0.5204 - val_loss: 1.4505 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.49989 to 1.45052, saving model to model_init_2021-10-2723_54_21.814102\\model-00013-1.21499-0.52036-1.45052-0.50000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.2119 - categorical_accuracy: 0.5219 - val_loss: 1.4648 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.45052\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1939 - categorical_accuracy: 0.5053 - val_loss: 1.4425 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.45052 to 1.44245, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.19391-0.50528-1.44245-0.47000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2314 - categorical_accuracy: 0.4887 - val_loss: 1.4335 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.44245 to 1.43354, saving model to model_init_2021-10-2723_54_21.814102\\model-00016-1.23144-0.48869-1.43354-0.46000.h5\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1453 - categorical_accuracy: 0.5415 - val_loss: 1.4127 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.43354 to 1.41267, saving model to model_init_2021-10-2723_54_21.814102\\model-00017-1.14528-0.54148-1.41267-0.43000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.1872 - categorical_accuracy: 0.5385 - val_loss: 1.4119 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.41267 to 1.41192, saving model to model_init_2021-10-2723_54_21.814102\\model-00018-1.18715-0.53846-1.41192-0.47000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1536 - categorical_accuracy: 0.5294 - val_loss: 1.3740 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.41192 to 1.37397, saving model to model_init_2021-10-2723_54_21.814102\\model-00019-1.15365-0.52941-1.37397-0.48000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1458 - categorical_accuracy: 0.5219 - val_loss: 1.3325 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.37397 to 1.33250, saving model to model_init_2021-10-2723_54_21.814102\\model-00020-1.14580-0.52187-1.33250-0.44000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1229 - categorical_accuracy: 0.5596 - val_loss: 1.3333 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.33250\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1251 - categorical_accuracy: 0.5505 - val_loss: 1.3209 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.33250 to 1.32085, saving model to model_init_2021-10-2723_54_21.814102\\model-00022-1.12513-0.55053-1.32085-0.51000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1385 - categorical_accuracy: 0.5339 - val_loss: 1.3084 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.32085 to 1.30844, saving model to model_init_2021-10-2723_54_21.814102\\model-00023-1.13850-0.53394-1.30844-0.49000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1162 - categorical_accuracy: 0.5551 - val_loss: 1.2283 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.30844 to 1.22834, saving model to model_init_2021-10-2723_54_21.814102\\model-00024-1.11621-0.55505-1.22834-0.53000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0729 - categorical_accuracy: 0.5928 - val_loss: 1.2680 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.22834\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0642 - categorical_accuracy: 0.5897 - val_loss: 1.2886 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.22834\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0923 - categorical_accuracy: 0.5656 - val_loss: 1.2560 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.22834\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0505 - categorical_accuracy: 0.5701 - val_loss: 1.3041 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.22834\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0635 - categorical_accuracy: 0.5747 - val_loss: 1.2089 - val_categorical_accuracy: 0.5600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00029: val_loss improved from 1.22834 to 1.20885, saving model to model_init_2021-10-2723_54_21.814102\\model-00029-1.06355-0.57466-1.20885-0.56000.h5\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0509 - categorical_accuracy: 0.5656 - val_loss: 1.2238 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.20885\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.0237 - categorical_accuracy: 0.6244 - val_loss: 1.2235 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.20885\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.0657 - categorical_accuracy: 0.5928 - val_loss: 1.2345 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.20885\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.0178 - categorical_accuracy: 0.6124 - val_loss: 1.1823 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.20885 to 1.18234, saving model to model_init_2021-10-2723_54_21.814102\\model-00033-1.01779-0.61237-1.18234-0.50000.h5\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0278 - categorical_accuracy: 0.5882 - val_loss: 1.1948 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.18234\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9975 - categorical_accuracy: 0.6094 - val_loss: 1.1978 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.18234\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 0.9903 - categorical_accuracy: 0.6410 - val_loss: 1.1751 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.18234 to 1.17514, saving model to model_init_2021-10-2723_54_21.814102\\model-00036-0.99031-0.64103-1.17514-0.51000.h5\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 0.9846 - categorical_accuracy: 0.6471 - val_loss: 1.2376 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.17514\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0239 - categorical_accuracy: 0.6124 - val_loss: 1.1632 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.17514 to 1.16319, saving model to model_init_2021-10-2723_54_21.814102\\model-00038-1.02386-0.61237-1.16319-0.54000.h5\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0001 - categorical_accuracy: 0.6350 - val_loss: 1.1762 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.16319\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9888 - categorical_accuracy: 0.6139 - val_loss: 1.2346 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.16319\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9637 - categorical_accuracy: 0.6305 - val_loss: 1.1375 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.16319 to 1.13748, saving model to model_init_2021-10-2723_54_21.814102\\model-00041-0.96372-0.63047-1.13748-0.57000.h5\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.9419 - categorical_accuracy: 0.6380 - val_loss: 1.1744 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.13748\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9660 - categorical_accuracy: 0.6305 - val_loss: 1.1603 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.13748\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9234 - categorical_accuracy: 0.6546 - val_loss: 1.2047 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.13748\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9410 - categorical_accuracy: 0.6486 - val_loss: 1.2064 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.13748\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.9148 - categorical_accuracy: 0.6697 - val_loss: 1.1101 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.13748 to 1.11013, saving model to model_init_2021-10-2723_54_21.814102\\model-00046-0.91478-0.66968-1.11013-0.53000.h5\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9319 - categorical_accuracy: 0.6546 - val_loss: 1.1469 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.11013\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9194 - categorical_accuracy: 0.6742 - val_loss: 1.1112 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.11013\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8993 - categorical_accuracy: 0.6772 - val_loss: 1.1234 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.11013\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9110 - categorical_accuracy: 0.6727 - val_loss: 1.1343 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.11013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2572987e1c0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_22.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_22 is overfitting and does not have a good performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying LSTM in model 10 instead of GRU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_23 = Sequential()\n",
    "\n",
    "model_23.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "model_23.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_23.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_23.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_23.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_23.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_23.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model_23.add(TimeDistributed(BatchNormalization()))\n",
    "model_23.add(Dropout(0.25))\n",
    "\n",
    "model_23.add(TimeDistributed(Flatten()))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model_23.add(LSTM(128, return_sequences=False))\n",
    "\n",
    "model_23.add(Dense(128, activation='relu'))\n",
    "model_23.add(Dropout(0.25))\n",
    "model_23.add(Dense(64, activation='relu'))\n",
    "model_23.add(Dropout(0.25))\n",
    "\n",
    "model_23.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_96 (TimeDis (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_97 (TimeDis (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_98 (TimeDis (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_99 (TimeDis (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_100 (TimeDi (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_101 (TimeDi (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_102 (TimeDi (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_103 (TimeDi (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_104 (TimeDi (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               885248    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 924,885\n",
      "Trainable params: 924,757\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_23.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_23.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.6027 - categorical_accuracy: 0.2700 - val_loss: 1.6057 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60574, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.60268-0.26998-1.60574-0.24000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.5338 - categorical_accuracy: 0.3167 - val_loss: 1.5951 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60574 to 1.59514, saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.53380-0.31674-1.59514-0.25000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.4887 - categorical_accuracy: 0.3379 - val_loss: 1.6045 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.59514\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.4375 - categorical_accuracy: 0.3967 - val_loss: 1.5951 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.59514 to 1.59510, saving model to model_init_2021-10-2723_54_21.814102\\model-00004-1.43752-0.39668-1.59510-0.23000.h5\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4067 - categorical_accuracy: 0.3997 - val_loss: 1.5921 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.59510 to 1.59209, saving model to model_init_2021-10-2723_54_21.814102\\model-00005-1.40666-0.39970-1.59209-0.23000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3701 - categorical_accuracy: 0.4434 - val_loss: 1.5806 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.59209 to 1.58056, saving model to model_init_2021-10-2723_54_21.814102\\model-00006-1.37006-0.44344-1.58056-0.27000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3541 - categorical_accuracy: 0.4419 - val_loss: 1.5764 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.58056 to 1.57636, saving model to model_init_2021-10-2723_54_21.814102\\model-00007-1.35408-0.44193-1.57636-0.21000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.3285 - categorical_accuracy: 0.4872 - val_loss: 1.5709 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.57636 to 1.57090, saving model to model_init_2021-10-2723_54_21.814102\\model-00008-1.32845-0.48718-1.57090-0.23000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2857 - categorical_accuracy: 0.4962 - val_loss: 1.5567 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.57090 to 1.55672, saving model to model_init_2021-10-2723_54_21.814102\\model-00009-1.28568-0.49623-1.55672-0.29000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2718 - categorical_accuracy: 0.4857 - val_loss: 1.5228 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.55672 to 1.52284, saving model to model_init_2021-10-2723_54_21.814102\\model-00010-1.27183-0.48567-1.52284-0.29000.h5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2641 - categorical_accuracy: 0.4992 - val_loss: 1.5503 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.52284\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 53s 3s/step - loss: 1.2420 - categorical_accuracy: 0.5173 - val_loss: 1.5002 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.52284 to 1.50019, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.24198-0.51735-1.50019-0.40000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2168 - categorical_accuracy: 0.5354 - val_loss: 1.4886 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.50019 to 1.48865, saving model to model_init_2021-10-2723_54_21.814102\\model-00013-1.21680-0.53544-1.48865-0.40000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2091 - categorical_accuracy: 0.5219 - val_loss: 1.4635 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.48865 to 1.46354, saving model to model_init_2021-10-2723_54_21.814102\\model-00014-1.20914-0.52187-1.46354-0.43000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1890 - categorical_accuracy: 0.5581 - val_loss: 1.4550 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.46354 to 1.45498, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.18899-0.55807-1.45498-0.45000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.1805 - categorical_accuracy: 0.5309 - val_loss: 1.4311 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.45498 to 1.43112, saving model to model_init_2021-10-2723_54_21.814102\\model-00016-1.18051-0.53092-1.43112-0.46000.h5\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 78s 4s/step - loss: 1.1596 - categorical_accuracy: 0.5234 - val_loss: 1.4107 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.43112 to 1.41075, saving model to model_init_2021-10-2723_54_21.814102\\model-00017-1.15961-0.52338-1.41075-0.47000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 68s 3s/step - loss: 1.1085 - categorical_accuracy: 0.5882 - val_loss: 1.4043 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.41075 to 1.40428, saving model to model_init_2021-10-2723_54_21.814102\\model-00018-1.10847-0.58824-1.40428-0.46000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1109 - categorical_accuracy: 0.5867 - val_loss: 1.3742 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.40428 to 1.37424, saving model to model_init_2021-10-2723_54_21.814102\\model-00019-1.11088-0.58673-1.37424-0.47000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1133 - categorical_accuracy: 0.5988 - val_loss: 1.3450 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.37424 to 1.34503, saving model to model_init_2021-10-2723_54_21.814102\\model-00020-1.11333-0.59879-1.34503-0.44000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1009 - categorical_accuracy: 0.5973 - val_loss: 1.3273 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.34503 to 1.32731, saving model to model_init_2021-10-2723_54_21.814102\\model-00021-1.10092-0.59729-1.32731-0.46000.h5\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 91s 5s/step - loss: 1.0727 - categorical_accuracy: 0.5913 - val_loss: 1.2806 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.32731 to 1.28060, saving model to model_init_2021-10-2723_54_21.814102\\model-00022-1.07269-0.59125-1.28060-0.52000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0480 - categorical_accuracy: 0.6199 - val_loss: 1.2848 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.28060\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0601 - categorical_accuracy: 0.6109 - val_loss: 1.2560 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.28060 to 1.25603, saving model to model_init_2021-10-2723_54_21.814102\\model-00024-1.06007-0.61086-1.25603-0.49000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0343 - categorical_accuracy: 0.6214 - val_loss: 1.2590 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.25603\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0324 - categorical_accuracy: 0.6214 - val_loss: 1.2963 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.25603\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0017 - categorical_accuracy: 0.6471 - val_loss: 1.1484 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.25603 to 1.14839, saving model to model_init_2021-10-2723_54_21.814102\\model-00027-1.00170-0.64706-1.14839-0.56000.h5\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.0035 - categorical_accuracy: 0.6169 - val_loss: 1.2259 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.14839\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9749 - categorical_accuracy: 0.6410 - val_loss: 1.2156 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.14839\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9747 - categorical_accuracy: 0.6591 - val_loss: 1.2330 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.14839\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9694 - categorical_accuracy: 0.6305 - val_loss: 1.1791 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.14839\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9568 - categorical_accuracy: 0.6757 - val_loss: 1.1872 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.14839\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 63s 3s/step - loss: 0.9384 - categorical_accuracy: 0.6712 - val_loss: 1.1893 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.14839\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 62s 3s/step - loss: 0.9319 - categorical_accuracy: 0.6727 - val_loss: 1.1664 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.14839\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 62s 3s/step - loss: 0.9205 - categorical_accuracy: 0.6772 - val_loss: 1.3211 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.14839\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.9211 - categorical_accuracy: 0.6817 - val_loss: 1.1959 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.14839\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8671 - categorical_accuracy: 0.7164 - val_loss: 1.1796 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.14839\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8729 - categorical_accuracy: 0.6983 - val_loss: 1.2149 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.14839\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8504 - categorical_accuracy: 0.6983 - val_loss: 1.1331 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.14839 to 1.13311, saving model to model_init_2021-10-2723_54_21.814102\\model-00039-0.85040-0.69834-1.13311-0.52000.h5\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.8487 - categorical_accuracy: 0.6833 - val_loss: 1.1836 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.13311\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.8281 - categorical_accuracy: 0.7270 - val_loss: 1.1722 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.13311\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8579 - categorical_accuracy: 0.6893 - val_loss: 1.0794 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.13311 to 1.07938, saving model to model_init_2021-10-2723_54_21.814102\\model-00042-0.85794-0.68929-1.07938-0.55000.h5\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8323 - categorical_accuracy: 0.7240 - val_loss: 1.2819 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.07938\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.8693 - categorical_accuracy: 0.6833 - val_loss: 1.2028 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.07938\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8010 - categorical_accuracy: 0.7300 - val_loss: 1.1763 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.07938\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.7757 - categorical_accuracy: 0.7376 - val_loss: 1.1232 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.07938\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.7868 - categorical_accuracy: 0.7210 - val_loss: 1.1788 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.07938\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.7966 - categorical_accuracy: 0.7391 - val_loss: 1.1676 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.07938\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.7345 - categorical_accuracy: 0.7903 - val_loss: 1.1716 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.07938\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.7337 - categorical_accuracy: 0.7632 - val_loss: 1.0477 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.07938 to 1.04773, saving model to model_init_2021-10-2723_54_21.814102\\model-00050-0.73374-0.76320-1.04773-0.58000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25ace7785b0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_23.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_23 is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the dropouts after the third Conv2D layer and trying again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_24 = Sequential()\n",
    "\n",
    "model_24.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "model_24.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_24.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_24.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_24.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_24.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_24.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model_24.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model_24.add(TimeDistributed(Flatten()))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model_24.add(LSTM(128, return_sequences=False))\n",
    "\n",
    "model_24.add(Dense(128, activation='relu'))\n",
    "model_24.add(Dropout(0.25))\n",
    "model_24.add(Dense(64, activation='relu'))\n",
    "model_24.add(Dropout(0.25))\n",
    "\n",
    "model_24.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_105 (TimeDi (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_106 (TimeDi (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_107 (TimeDi (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_108 (TimeDi (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_109 (TimeDi (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_110 (TimeDi (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_111 (TimeDi (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_112 (TimeDi (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "time_distributed_113 (TimeDi (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               885248    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 924,885\n",
      "Trainable params: 924,757\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_24.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_24.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 1.6025 - categorical_accuracy: 0.2353 - val_loss: 1.6057 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60567, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.60247-0.23529-1.60567-0.21000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.5152 - categorical_accuracy: 0.3454 - val_loss: 1.6065 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.60567\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.5001 - categorical_accuracy: 0.3424 - val_loss: 1.6026 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.60567 to 1.60260, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.50015-0.34238-1.60260-0.18000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.4461 - categorical_accuracy: 0.3982 - val_loss: 1.5945 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.60260 to 1.59446, saving model to model_init_2021-10-2723_54_21.814102\\model-00004-1.44613-0.39819-1.59446-0.21000.h5\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3878 - categorical_accuracy: 0.4419 - val_loss: 1.5939 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.59446 to 1.59390, saving model to model_init_2021-10-2723_54_21.814102\\model-00005-1.38780-0.44193-1.59390-0.24000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3837 - categorical_accuracy: 0.4449 - val_loss: 1.5872 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.59390 to 1.58719, saving model to model_init_2021-10-2723_54_21.814102\\model-00006-1.38367-0.44495-1.58719-0.20000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3309 - categorical_accuracy: 0.4842 - val_loss: 1.5810 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.58719 to 1.58100, saving model to model_init_2021-10-2723_54_21.814102\\model-00007-1.33094-0.48416-1.58100-0.22000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3379 - categorical_accuracy: 0.4540 - val_loss: 1.5796 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.58100 to 1.57959, saving model to model_init_2021-10-2723_54_21.814102\\model-00008-1.33788-0.45400-1.57959-0.25000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3124 - categorical_accuracy: 0.5008 - val_loss: 1.5624 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.57959 to 1.56241, saving model to model_init_2021-10-2723_54_21.814102\\model-00009-1.31244-0.50075-1.56241-0.31000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.2705 - categorical_accuracy: 0.5158 - val_loss: 1.5392 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.56241 to 1.53924, saving model to model_init_2021-10-2723_54_21.814102\\model-00010-1.27050-0.51584-1.53924-0.31000.h5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.2569 - categorical_accuracy: 0.5143 - val_loss: 1.5329 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.53924 to 1.53294, saving model to model_init_2021-10-2723_54_21.814102\\model-00011-1.25694-0.51433-1.53294-0.37000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2202 - categorical_accuracy: 0.5596 - val_loss: 1.5226 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.53294 to 1.52261, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.22017-0.55958-1.52261-0.44000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2122 - categorical_accuracy: 0.5475 - val_loss: 1.5005 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.52261 to 1.50054, saving model to model_init_2021-10-2723_54_21.814102\\model-00013-1.21221-0.54751-1.50054-0.43000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.1974 - categorical_accuracy: 0.5551 - val_loss: 1.4914 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.50054 to 1.49139, saving model to model_init_2021-10-2723_54_21.814102\\model-00014-1.19739-0.55505-1.49139-0.43000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1390 - categorical_accuracy: 0.5988 - val_loss: 1.4642 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.49139 to 1.46416, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.13905-0.59879-1.46416-0.45000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1670 - categorical_accuracy: 0.5762 - val_loss: 1.4120 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.46416 to 1.41202, saving model to model_init_2021-10-2723_54_21.814102\\model-00016-1.16701-0.57617-1.41202-0.47000.h5\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1566 - categorical_accuracy: 0.5807 - val_loss: 1.4237 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.41202\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0694 - categorical_accuracy: 0.6380 - val_loss: 1.4131 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.41202\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1213 - categorical_accuracy: 0.5671 - val_loss: 1.3937 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.41202 to 1.39372, saving model to model_init_2021-10-2723_54_21.814102\\model-00019-1.12132-0.56712-1.39372-0.45000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0940 - categorical_accuracy: 0.6094 - val_loss: 1.3472 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.39372 to 1.34718, saving model to model_init_2021-10-2723_54_21.814102\\model-00020-1.09404-0.60935-1.34718-0.54000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0889 - categorical_accuracy: 0.6078 - val_loss: 1.3559 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.34718\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0467 - categorical_accuracy: 0.6591 - val_loss: 1.3730 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.34718\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0228 - categorical_accuracy: 0.6712 - val_loss: 1.3442 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.34718 to 1.34420, saving model to model_init_2021-10-2723_54_21.814102\\model-00023-1.02284-0.67119-1.34420-0.46000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0106 - categorical_accuracy: 0.6561 - val_loss: 1.3248 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.34420 to 1.32480, saving model to model_init_2021-10-2723_54_21.814102\\model-00024-1.01060-0.65611-1.32480-0.47000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0221 - categorical_accuracy: 0.6305 - val_loss: 1.3346 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.32480\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.9698 - categorical_accuracy: 0.6908 - val_loss: 1.3223 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.32480 to 1.32229, saving model to model_init_2021-10-2723_54_21.814102\\model-00026-0.96981-0.69080-1.32229-0.47000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9707 - categorical_accuracy: 0.6727 - val_loss: 1.3103 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.32229 to 1.31032, saving model to model_init_2021-10-2723_54_21.814102\\model-00027-0.97072-0.67270-1.31032-0.47000.h5\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 0.9684 - categorical_accuracy: 0.6893 - val_loss: 1.3159 - val_categorical_accuracy: 0.4700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_loss did not improve from 1.31032\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9385 - categorical_accuracy: 0.7134 - val_loss: 1.1858 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.31032 to 1.18580, saving model to model_init_2021-10-2723_54_21.814102\\model-00029-0.93848-0.71342-1.18580-0.57000.h5\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.9642 - categorical_accuracy: 0.6682 - val_loss: 1.2924 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.18580\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9106 - categorical_accuracy: 0.7255 - val_loss: 1.2810 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.18580\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9211 - categorical_accuracy: 0.7134 - val_loss: 1.2903 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.18580\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8983 - categorical_accuracy: 0.7240 - val_loss: 1.2689 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.18580\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8904 - categorical_accuracy: 0.7345 - val_loss: 1.2380 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.18580\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8677 - categorical_accuracy: 0.7285 - val_loss: 1.2724 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.18580\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8612 - categorical_accuracy: 0.7270 - val_loss: 1.2869 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.18580\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8246 - categorical_accuracy: 0.7526 - val_loss: 1.2374 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.18580\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.8163 - categorical_accuracy: 0.7617 - val_loss: 1.2477 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.18580\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8231 - categorical_accuracy: 0.7632 - val_loss: 1.2597 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.18580\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8305 - categorical_accuracy: 0.7481 - val_loss: 1.2918 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.18580\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.7780 - categorical_accuracy: 0.7647 - val_loss: 1.2487 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.18580\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.7719 - categorical_accuracy: 0.7707 - val_loss: 1.1942 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.18580\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 0.7787 - categorical_accuracy: 0.7873 - val_loss: 1.2513 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.18580\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.7642 - categorical_accuracy: 0.7647 - val_loss: 1.2375 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.18580\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 0.7705 - categorical_accuracy: 0.7783 - val_loss: 1.1717 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.18580 to 1.17165, saving model to model_init_2021-10-2723_54_21.814102\\model-00045-0.77046-0.77828-1.17165-0.56000.h5\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.7412 - categorical_accuracy: 0.7964 - val_loss: 1.2665 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.17165\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.7366 - categorical_accuracy: 0.7949 - val_loss: 1.2444 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.17165\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.7115 - categorical_accuracy: 0.7979 - val_loss: 1.2493 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.17165\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.7037 - categorical_accuracy: 0.8100 - val_loss: 1.2727 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.17165\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.6847 - categorical_accuracy: 0.8220 - val_loss: 1.2543 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.17165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25b51fb4040>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_24.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_24 is overfitting. Also, as far as validation accuracy is concerned, there was no benefit of removing the dropouts\n",
    "# after the third Conv2D layer. In fact, doing so reduced the validation accuracy as compared to epoch 50 of model_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running model 1 with only 1 dense(128) layer and 25% dropouts after that dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_25 = Sequential()\n",
    "\n",
    "model_25.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "\n",
    "\n",
    "model_25.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_25.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_25.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_25.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_25.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_25.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_25.add(TimeDistributed(BatchNormalization()))\n",
    "model_25.add(Dropout(0.25))\n",
    "\n",
    "model_25.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_25.add(Dense(128, activation='relu'))\n",
    "model_25.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_25.add(GRU(128, return_sequences=False))\n",
    "model_25.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_114 (TimeDi (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_115 (TimeDi (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_116 (TimeDi (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_117 (TimeDi (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_118 (TimeDi (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_119 (TimeDi (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_120 (TimeDi (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_121 (TimeDi (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_122 (TimeDi (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 20, 128)           204928    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 128)               99072     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 319,189\n",
      "Trainable params: 319,061\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_25.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_25.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.5903 - categorical_accuracy: 0.2730 - val_loss: 1.6017 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60168, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.59034-0.27300-1.60168-0.23000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4488 - categorical_accuracy: 0.3771 - val_loss: 1.6003 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60168 to 1.60025, saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.44880-0.37707-1.60025-0.18000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3638 - categorical_accuracy: 0.4495 - val_loss: 1.5760 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.60025 to 1.57595, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.36381-0.44947-1.57595-0.25000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.3239 - categorical_accuracy: 0.4570 - val_loss: 1.5834 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.57595\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2639 - categorical_accuracy: 0.4947 - val_loss: 1.5714 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.57595 to 1.57144, saving model to model_init_2021-10-2723_54_21.814102\\model-00005-1.26388-0.49472-1.57144-0.23000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2392 - categorical_accuracy: 0.4917 - val_loss: 1.5584 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.57144 to 1.55837, saving model to model_init_2021-10-2723_54_21.814102\\model-00006-1.23916-0.49170-1.55837-0.22000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2043 - categorical_accuracy: 0.5505 - val_loss: 1.5563 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.55837 to 1.55630, saving model to model_init_2021-10-2723_54_21.814102\\model-00007-1.20428-0.55053-1.55630-0.25000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1841 - categorical_accuracy: 0.5505 - val_loss: 1.5330 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.55630 to 1.53298, saving model to model_init_2021-10-2723_54_21.814102\\model-00008-1.18413-0.55053-1.53298-0.27000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1648 - categorical_accuracy: 0.5551 - val_loss: 1.5165 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.53298 to 1.51645, saving model to model_init_2021-10-2723_54_21.814102\\model-00009-1.16481-0.55505-1.51645-0.34000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1542 - categorical_accuracy: 0.5656 - val_loss: 1.4937 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.51645 to 1.49366, saving model to model_init_2021-10-2723_54_21.814102\\model-00010-1.15423-0.56561-1.49366-0.38000.h5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1184 - categorical_accuracy: 0.5777 - val_loss: 1.5014 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.49366\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1116 - categorical_accuracy: 0.5732 - val_loss: 1.4630 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.49366 to 1.46297, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.11155-0.57315-1.46297-0.42000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0599 - categorical_accuracy: 0.6320 - val_loss: 1.4433 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.46297 to 1.44329, saving model to model_init_2021-10-2723_54_21.814102\\model-00013-1.05993-0.63198-1.44329-0.45000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0672 - categorical_accuracy: 0.5928 - val_loss: 1.4521 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.44329\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0653 - categorical_accuracy: 0.5973 - val_loss: 1.4054 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.44329 to 1.40536, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.06534-0.59729-1.40536-0.42000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0577 - categorical_accuracy: 0.6048 - val_loss: 1.3873 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.40536 to 1.38725, saving model to model_init_2021-10-2723_54_21.814102\\model-00016-1.05774-0.60483-1.38725-0.46000.h5\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0129 - categorical_accuracy: 0.6305 - val_loss: 1.3671 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.38725 to 1.36711, saving model to model_init_2021-10-2723_54_21.814102\\model-00017-1.01295-0.63047-1.36711-0.44000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9897 - categorical_accuracy: 0.6591 - val_loss: 1.3082 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.36711 to 1.30822, saving model to model_init_2021-10-2723_54_21.814102\\model-00018-0.98970-0.65913-1.30822-0.49000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0112 - categorical_accuracy: 0.6229 - val_loss: 1.3656 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.30822\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.9773 - categorical_accuracy: 0.6501 - val_loss: 1.3042 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.30822 to 1.30422, saving model to model_init_2021-10-2723_54_21.814102\\model-00020-0.97730-0.65008-1.30422-0.47000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9869 - categorical_accuracy: 0.6395 - val_loss: 1.2985 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.30422 to 1.29854, saving model to model_init_2021-10-2723_54_21.814102\\model-00021-0.98694-0.63952-1.29854-0.47000.h5\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9484 - categorical_accuracy: 0.6757 - val_loss: 1.2446 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.29854 to 1.24459, saving model to model_init_2021-10-2723_54_21.814102\\model-00022-0.94838-0.67572-1.24459-0.50000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9472 - categorical_accuracy: 0.6637 - val_loss: 1.3561 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.24459\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.9638 - categorical_accuracy: 0.6471 - val_loss: 1.2645 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.24459\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9323 - categorical_accuracy: 0.6712 - val_loss: 1.2545 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.24459\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9343 - categorical_accuracy: 0.6667 - val_loss: 1.2270 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.24459 to 1.22701, saving model to model_init_2021-10-2723_54_21.814102\\model-00026-0.93427-0.66667-1.22701-0.54000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8696 - categorical_accuracy: 0.6878 - val_loss: 1.1888 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.22701 to 1.18882, saving model to model_init_2021-10-2723_54_21.814102\\model-00027-0.86963-0.68778-1.18882-0.48000.h5\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.9195 - categorical_accuracy: 0.6893 - val_loss: 1.2496 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.18882\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8587 - categorical_accuracy: 0.7104 - val_loss: 1.2298 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.18882\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8715 - categorical_accuracy: 0.6817 - val_loss: 1.2785 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.18882\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 0.8514 - categorical_accuracy: 0.7164 - val_loss: 1.1682 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.18882 to 1.16816, saving model to model_init_2021-10-2723_54_21.814102\\model-00031-0.85136-0.71644-1.16816-0.54000.h5\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.8523 - categorical_accuracy: 0.7270 - val_loss: 1.2160 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.16816\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8413 - categorical_accuracy: 0.7074 - val_loss: 1.2187 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.16816\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8531 - categorical_accuracy: 0.7270 - val_loss: 1.2164 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.16816\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.8174 - categorical_accuracy: 0.7240 - val_loss: 1.2336 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.16816\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.8253 - categorical_accuracy: 0.7255 - val_loss: 1.2278 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.16816\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.7882 - categorical_accuracy: 0.7315 - val_loss: 1.2145 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.16816\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.7848 - categorical_accuracy: 0.7572 - val_loss: 1.3090 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.16816\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8271 - categorical_accuracy: 0.7044 - val_loss: 1.3241 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.16816\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.7523 - categorical_accuracy: 0.7557 - val_loss: 1.1932 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.16816\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.7489 - categorical_accuracy: 0.7647 - val_loss: 1.2124 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.16816\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.7778 - categorical_accuracy: 0.7436 - val_loss: 1.3265 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.16816\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.7327 - categorical_accuracy: 0.7632 - val_loss: 1.1933 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.16816\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.7739 - categorical_accuracy: 0.7285 - val_loss: 1.2004 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.16816\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.7091 - categorical_accuracy: 0.7798 - val_loss: 1.2229 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.16816\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.7482 - categorical_accuracy: 0.7587 - val_loss: 1.2196 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.16816\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 0.7206 - categorical_accuracy: 0.7662 - val_loss: 1.1032 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.16816 to 1.10317, saving model to model_init_2021-10-2723_54_21.814102\\model-00047-0.72060-0.76621-1.10317-0.56000.h5\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.7244 - categorical_accuracy: 0.7647 - val_loss: 1.2319 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.10317\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.6795 - categorical_accuracy: 0.7979 - val_loss: 1.2058 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.10317\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.7033 - categorical_accuracy: 0.7783 - val_loss: 1.2493 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.10317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25b7189b640>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_25.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_25 is overfitting a lot. Moreover, the validation accuracy is poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running model 1 with only 1 dense(128) layer and 50% dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_26 = Sequential()\n",
    "\n",
    "model_26.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "\n",
    "model_26.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_26.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_26.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_26.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_26.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_26.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_26.add(TimeDistributed(BatchNormalization()))\n",
    "model_26.add(Dropout(0.25))\n",
    "\n",
    "model_26.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_26.add(Dense(128, activation='relu'))\n",
    "model_26.add(Dropout(0.50))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_26.add(GRU(128, return_sequences=False))\n",
    "model_26.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_132 (TimeDi (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_133 (TimeDi (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_134 (TimeDi (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_135 (TimeDi (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_136 (TimeDi (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_137 (TimeDi (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_138 (TimeDi (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_139 (TimeDi (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_140 (TimeDi (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 20, 128)           204928    \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 128)               99072     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 319,189\n",
      "Trainable params: 319,061\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_26.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_26.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.5907 - categorical_accuracy: 0.2896 - val_loss: 1.6180 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61796, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.59073-0.28959-1.61796-0.19000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.4987 - categorical_accuracy: 0.3152 - val_loss: 1.6015 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.61796 to 1.60149, saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.49867-0.31523-1.60149-0.22000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 62s 3s/step - loss: 1.4109 - categorical_accuracy: 0.4193 - val_loss: 1.5987 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.60149 to 1.59874, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.41090-0.41931-1.59874-0.22000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 1.3762 - categorical_accuracy: 0.3952 - val_loss: 1.5879 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.59874 to 1.58793, saving model to model_init_2021-10-2723_54_21.814102\\model-00004-1.37618-0.39517-1.58793-0.22000.h5\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 61s 3s/step - loss: 1.3467 - categorical_accuracy: 0.4389 - val_loss: 1.5941 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.58793\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.3036 - categorical_accuracy: 0.4630 - val_loss: 1.5853 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.58793 to 1.58527, saving model to model_init_2021-10-2723_54_21.814102\\model-00006-1.30359-0.46305-1.58527-0.20000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 1.2914 - categorical_accuracy: 0.4465 - val_loss: 1.5755 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.58527 to 1.57550, saving model to model_init_2021-10-2723_54_21.814102\\model-00007-1.29144-0.44646-1.57550-0.20000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 61s 3s/step - loss: 1.2666 - categorical_accuracy: 0.4706 - val_loss: 1.5703 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.57550 to 1.57026, saving model to model_init_2021-10-2723_54_21.814102\\model-00008-1.26658-0.47059-1.57026-0.18000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.2375 - categorical_accuracy: 0.5053 - val_loss: 1.5589 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.57026 to 1.55889, saving model to model_init_2021-10-2723_54_21.814102\\model-00009-1.23750-0.50528-1.55889-0.24000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2299 - categorical_accuracy: 0.5008 - val_loss: 1.5431 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.55889 to 1.54308, saving model to model_init_2021-10-2723_54_21.814102\\model-00010-1.22994-0.50075-1.54308-0.25000.h5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.2095 - categorical_accuracy: 0.5173 - val_loss: 1.5331 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.54308 to 1.53307, saving model to model_init_2021-10-2723_54_21.814102\\model-00011-1.20954-0.51735-1.53307-0.34000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.1783 - categorical_accuracy: 0.5189 - val_loss: 1.5159 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.53307 to 1.51594, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.17832-0.51885-1.51594-0.36000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.1474 - categorical_accuracy: 0.5505 - val_loss: 1.5156 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.51594 to 1.51558, saving model to model_init_2021-10-2723_54_21.814102\\model-00013-1.14737-0.55053-1.51558-0.32000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 64s 3s/step - loss: 1.2083 - categorical_accuracy: 0.5204 - val_loss: 1.4802 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.51558 to 1.48015, saving model to model_init_2021-10-2723_54_21.814102\\model-00014-1.20829-0.52036-1.48015-0.41000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 61s 3s/step - loss: 1.1366 - categorical_accuracy: 0.5807 - val_loss: 1.4741 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.48015 to 1.47408, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.13663-0.58069-1.47408-0.44000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1397 - categorical_accuracy: 0.5747 - val_loss: 1.4374 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.47408 to 1.43743, saving model to model_init_2021-10-2723_54_21.814102\\model-00016-1.13971-0.57466-1.43743-0.49000.h5\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1465 - categorical_accuracy: 0.5430 - val_loss: 1.4736 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.43743\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 62s 3s/step - loss: 1.1222 - categorical_accuracy: 0.5626 - val_loss: 1.4248 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.43743 to 1.42480, saving model to model_init_2021-10-2723_54_21.814102\\model-00018-1.12222-0.56259-1.42480-0.45000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 65s 3s/step - loss: 1.0998 - categorical_accuracy: 0.5792 - val_loss: 1.4065 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.42480 to 1.40654, saving model to model_init_2021-10-2723_54_21.814102\\model-00019-1.09978-0.57919-1.40654-0.47000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 64s 3s/step - loss: 1.0735 - categorical_accuracy: 0.5867 - val_loss: 1.4114 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.40654\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 64s 3s/step - loss: 1.1253 - categorical_accuracy: 0.5807 - val_loss: 1.3318 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.40654 to 1.33181, saving model to model_init_2021-10-2723_54_21.814102\\model-00021-1.12532-0.58069-1.33181-0.49000.h5\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 62s 3s/step - loss: 1.0750 - categorical_accuracy: 0.5792 - val_loss: 1.3555 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.33181\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 64s 3s/step - loss: 1.0730 - categorical_accuracy: 0.6063 - val_loss: 1.3434 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.33181\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 64s 3s/step - loss: 1.0698 - categorical_accuracy: 0.5822 - val_loss: 1.2781 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.33181 to 1.27806, saving model to model_init_2021-10-2723_54_21.814102\\model-00024-1.06980-0.58220-1.27806-0.51000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 61s 3s/step - loss: 1.0610 - categorical_accuracy: 0.6018 - val_loss: 1.3020 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.27806\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0333 - categorical_accuracy: 0.6109 - val_loss: 1.3086 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.27806\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0404 - categorical_accuracy: 0.6229 - val_loss: 1.2971 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.27806\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0328 - categorical_accuracy: 0.6184 - val_loss: 1.3401 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.27806\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0035 - categorical_accuracy: 0.6516 - val_loss: 1.3048 - val_categorical_accuracy: 0.4800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00029: val_loss did not improve from 1.27806\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.0293 - categorical_accuracy: 0.5973 - val_loss: 1.2588 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.27806 to 1.25881, saving model to model_init_2021-10-2723_54_21.814102\\model-00030-1.02928-0.59729-1.25881-0.50000.h5\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 64s 3s/step - loss: 1.0028 - categorical_accuracy: 0.6169 - val_loss: 1.2622 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.25881\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 63s 3s/step - loss: 0.9964 - categorical_accuracy: 0.6199 - val_loss: 1.1936 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.25881 to 1.19356, saving model to model_init_2021-10-2723_54_21.814102\\model-00032-0.99639-0.61991-1.19356-0.58000.h5\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 63s 3s/step - loss: 0.9718 - categorical_accuracy: 0.6244 - val_loss: 1.2319 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.19356\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 61s 3s/step - loss: 0.9886 - categorical_accuracy: 0.6561 - val_loss: 1.2542 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.19356\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 63s 3s/step - loss: 0.9603 - categorical_accuracy: 0.6546 - val_loss: 1.2529 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.19356\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 64s 3s/step - loss: 0.9474 - categorical_accuracy: 0.6305 - val_loss: 1.1412 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.19356 to 1.14123, saving model to model_init_2021-10-2723_54_21.814102\\model-00036-0.94743-0.63047-1.14123-0.56000.h5\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 64s 3s/step - loss: 0.9429 - categorical_accuracy: 0.6561 - val_loss: 1.3724 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.14123\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 0.9337 - categorical_accuracy: 0.6471 - val_loss: 1.2335 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.14123\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 0.9476 - categorical_accuracy: 0.6395 - val_loss: 1.2389 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.14123\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 61s 3s/step - loss: 0.9223 - categorical_accuracy: 0.6878 - val_loss: 1.1770 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.14123\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 63s 3s/step - loss: 0.9081 - categorical_accuracy: 0.6652 - val_loss: 1.2943 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.14123\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9541 - categorical_accuracy: 0.6621 - val_loss: 1.1686 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.14123\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 61s 3s/step - loss: 0.8918 - categorical_accuracy: 0.6983 - val_loss: 1.2171 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.14123\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 63s 3s/step - loss: 0.8764 - categorical_accuracy: 0.6848 - val_loss: 1.2930 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.14123\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 64s 3s/step - loss: 0.9327 - categorical_accuracy: 0.6652 - val_loss: 1.1806 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.14123\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.8568 - categorical_accuracy: 0.6878 - val_loss: 1.2101 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.14123\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 0.8968 - categorical_accuracy: 0.6712 - val_loss: 1.1939 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.14123\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8948 - categorical_accuracy: 0.6712 - val_loss: 1.2469 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.14123\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8448 - categorical_accuracy: 0.7089 - val_loss: 1.0085 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.14123 to 1.00850, saving model to model_init_2021-10-2723_54_21.814102\\model-00049-0.84484-0.70890-1.00850-0.63000.h5\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.8787 - categorical_accuracy: 0.6923 - val_loss: 1.2169 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.00850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25b51f64eb0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_26.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 49 gave good result for model_26. Increasing the dropouts from 25% in model_25 to 50% in model_26 in the dense\n",
    "# layer improved the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running model 1 with only 1 dense(64) layer and 25% dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_27 = Sequential()\n",
    "\n",
    "model_27.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "\n",
    "model_27.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_27.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_27.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_27.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_27.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_27.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_27.add(TimeDistributed(BatchNormalization()))\n",
    "model_27.add(Dropout(0.25))\n",
    "\n",
    "model_27.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_27.add(Dense(64, activation='relu'))\n",
    "model_27.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_27.add(GRU(128, return_sequences=False))\n",
    "model_27.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_141 (TimeDi (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_142 (TimeDi (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_143 (TimeDi (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_144 (TimeDi (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_145 (TimeDi (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_146 (TimeDi (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_147 (TimeDi (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_148 (TimeDi (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_149 (TimeDi (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 20, 64)            102464    \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 192,149\n",
      "Trainable params: 192,021\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_27.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_27.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 1.5928 - categorical_accuracy: 0.2655 - val_loss: 1.6034 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60342, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.59277-0.26546-1.60342-0.23000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.5020 - categorical_accuracy: 0.3213 - val_loss: 1.5915 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60342 to 1.59147, saving model to model_init_2021-10-2723_54_21.814102\\model-00002-1.50200-0.32127-1.59147-0.28000.h5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.4533 - categorical_accuracy: 0.3846 - val_loss: 1.5947 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.59147\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3768 - categorical_accuracy: 0.4404 - val_loss: 1.5880 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.59147 to 1.58801, saving model to model_init_2021-10-2723_54_21.814102\\model-00004-1.37676-0.44042-1.58801-0.23000.h5\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.3571 - categorical_accuracy: 0.4404 - val_loss: 1.5831 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.58801 to 1.58309, saving model to model_init_2021-10-2723_54_21.814102\\model-00005-1.35707-0.44042-1.58309-0.25000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3348 - categorical_accuracy: 0.4676 - val_loss: 1.5849 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.58309\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2967 - categorical_accuracy: 0.4902 - val_loss: 1.5544 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.58309 to 1.55440, saving model to model_init_2021-10-2723_54_21.814102\\model-00007-1.29671-0.49020-1.55440-0.32000.h5\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.2862 - categorical_accuracy: 0.4977 - val_loss: 1.5610 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.55440\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.2654 - categorical_accuracy: 0.4932 - val_loss: 1.5491 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.55440 to 1.54906, saving model to model_init_2021-10-2723_54_21.814102\\model-00009-1.26543-0.49321-1.54906-0.28000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.2167 - categorical_accuracy: 0.5445 - val_loss: 1.5272 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.54906 to 1.52717, saving model to model_init_2021-10-2723_54_21.814102\\model-00010-1.21674-0.54449-1.52717-0.35000.h5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.2320 - categorical_accuracy: 0.5173 - val_loss: 1.5535 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.52717\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1976 - categorical_accuracy: 0.5505 - val_loss: 1.5055 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.52717 to 1.50550, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.19760-0.55053-1.50550-0.40000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1946 - categorical_accuracy: 0.5234 - val_loss: 1.4959 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.50550 to 1.49588, saving model to model_init_2021-10-2723_54_21.814102\\model-00013-1.19457-0.52338-1.49588-0.41000.h5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1702 - categorical_accuracy: 0.5596 - val_loss: 1.4749 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.49588 to 1.47487, saving model to model_init_2021-10-2723_54_21.814102\\model-00014-1.17018-0.55958-1.47487-0.45000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1913 - categorical_accuracy: 0.5249 - val_loss: 1.4567 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.47487 to 1.45665, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.19125-0.52489-1.45665-0.46000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1501 - categorical_accuracy: 0.5822 - val_loss: 1.4603 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.45665\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1720 - categorical_accuracy: 0.5460 - val_loss: 1.4302 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.45665 to 1.43019, saving model to model_init_2021-10-2723_54_21.814102\\model-00017-1.17199-0.54600-1.43019-0.50000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1161 - categorical_accuracy: 0.6033 - val_loss: 1.4468 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.43019\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1466 - categorical_accuracy: 0.5686 - val_loss: 1.4101 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.43019 to 1.41013, saving model to model_init_2021-10-2723_54_21.814102\\model-00019-1.14657-0.56863-1.41013-0.52000.h5\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0959 - categorical_accuracy: 0.6078 - val_loss: 1.3942 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.41013 to 1.39415, saving model to model_init_2021-10-2723_54_21.814102\\model-00020-1.09590-0.60784-1.39415-0.50000.h5\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1102 - categorical_accuracy: 0.5747 - val_loss: 1.3669 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.39415 to 1.36690, saving model to model_init_2021-10-2723_54_21.814102\\model-00021-1.11021-0.57466-1.36690-0.50000.h5\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0907 - categorical_accuracy: 0.6229 - val_loss: 1.3664 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.36690 to 1.36642, saving model to model_init_2021-10-2723_54_21.814102\\model-00022-1.09069-0.62293-1.36642-0.47000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0886 - categorical_accuracy: 0.5867 - val_loss: 1.3348 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.36642 to 1.33477, saving model to model_init_2021-10-2723_54_21.814102\\model-00023-1.08859-0.58673-1.33477-0.46000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0967 - categorical_accuracy: 0.5822 - val_loss: 1.3189 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.33477 to 1.31887, saving model to model_init_2021-10-2723_54_21.814102\\model-00024-1.09671-0.58220-1.31887-0.52000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0643 - categorical_accuracy: 0.5988 - val_loss: 1.3158 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.31887 to 1.31577, saving model to model_init_2021-10-2723_54_21.814102\\model-00025-1.06434-0.59879-1.31577-0.49000.h5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0897 - categorical_accuracy: 0.6018 - val_loss: 1.2656 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.31577 to 1.26560, saving model to model_init_2021-10-2723_54_21.814102\\model-00026-1.08971-0.60181-1.26560-0.52000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.0547 - categorical_accuracy: 0.5958 - val_loss: 1.2641 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.26560 to 1.26408, saving model to model_init_2021-10-2723_54_21.814102\\model-00027-1.05470-0.59578-1.26408-0.54000.h5\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0354 - categorical_accuracy: 0.6320 - val_loss: 1.2805 - val_categorical_accuracy: 0.5100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_loss did not improve from 1.26408\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0323 - categorical_accuracy: 0.6244 - val_loss: 1.2808 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.26408\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0306 - categorical_accuracy: 0.6139 - val_loss: 1.3096 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.26408\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0205 - categorical_accuracy: 0.6395 - val_loss: 1.2497 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.26408 to 1.24968, saving model to model_init_2021-10-2723_54_21.814102\\model-00031-1.02050-0.63952-1.24968-0.51000.h5\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.9940 - categorical_accuracy: 0.6365 - val_loss: 1.2688 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.24968\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 1.0341 - categorical_accuracy: 0.6078 - val_loss: 1.2561 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.24968\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 63s 3s/step - loss: 0.9845 - categorical_accuracy: 0.6667 - val_loss: 1.2109 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.24968 to 1.21087, saving model to model_init_2021-10-2723_54_21.814102\\model-00034-0.98450-0.66667-1.21087-0.50000.h5\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 1.0067 - categorical_accuracy: 0.6365 - val_loss: 1.1892 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.21087 to 1.18919, saving model to model_init_2021-10-2723_54_21.814102\\model-00035-1.00668-0.63650-1.18919-0.57000.h5\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.9874 - categorical_accuracy: 0.6380 - val_loss: 1.2858 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.18919\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9673 - categorical_accuracy: 0.6667 - val_loss: 1.2417 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.18919\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 0.9726 - categorical_accuracy: 0.6425 - val_loss: 1.2202 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.18919\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9456 - categorical_accuracy: 0.6712 - val_loss: 1.2894 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.18919\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.9512 - categorical_accuracy: 0.6697 - val_loss: 1.2291 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.18919\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9776 - categorical_accuracy: 0.6305 - val_loss: 1.2306 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.18919\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9167 - categorical_accuracy: 0.7014 - val_loss: 1.2243 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.18919\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.9366 - categorical_accuracy: 0.6772 - val_loss: 1.2301 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.18919\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.9382 - categorical_accuracy: 0.6772 - val_loss: 1.2525 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.18919\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9367 - categorical_accuracy: 0.6667 - val_loss: 1.2170 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.18919\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.8999 - categorical_accuracy: 0.6923 - val_loss: 1.3338 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.18919\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8980 - categorical_accuracy: 0.7089 - val_loss: 1.2890 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.18919\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 0.9208 - categorical_accuracy: 0.6606 - val_loss: 1.2307 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.18919\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 0.9033 - categorical_accuracy: 0.6863 - val_loss: 1.2061 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.18919\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.8800 - categorical_accuracy: 0.7014 - val_loss: 1.1406 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.18919 to 1.14056, saving model to model_init_2021-10-2723_54_21.814102\\model-00050-0.88000-0.70136-1.14056-0.58000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bae1f59a0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_27.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_27 is overfitting. When we compare it with model_25, in the 50th epoch, the categorical accuracy has reduced\n",
    "# (from 77.83% to 70.14%), while the validation accuracy has increased (from 45 to 58)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running model 1 with only 1 dense(64) layer and 50% dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "model_28 = Sequential()\n",
    "\n",
    "model_28.add(TimeDistributed(Conv2D(8, (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=(20,84,84,3)))\n",
    "\n",
    "model_28.add(TimeDistributed(Conv2D(16, (3,3),padding='same', activation='relu')))\n",
    "model_28.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_28.add(TimeDistributed(Conv2D(32, (3,3),padding='same', activation='relu')))\n",
    "model_28.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_28.add(TimeDistributed(Conv2D(64, (2,2),padding='same', activation='relu')))\n",
    "model_28.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model_28.add(TimeDistributed(BatchNormalization()))\n",
    "model_28.add(Dropout(0.25))\n",
    "\n",
    "model_28.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_28.add(Dense(64, activation='relu'))\n",
    "model_28.add(Dropout(0.50))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model_28.add(GRU(64, return_sequences=False))\n",
    "model_28.add(Dense(5, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_150 (TimeDi (None, 20, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_151 (TimeDi (None, 20, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_152 (TimeDi (None, 20, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_153 (TimeDi (None, 20, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_154 (TimeDi (None, 20, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_155 (TimeDi (None, 20, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_156 (TimeDi (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_157 (TimeDi (None, 20, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_158 (TimeDi (None, 20, 1600)          0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 20, 64)            102464    \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 64)                24960     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 142,293\n",
      "Trainable params: 142,165\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_28.compile(optimizer=optimiser_2, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_28.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.5981 - categorical_accuracy: 0.2504 - val_loss: 1.5980 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59802, saving model to model_init_2021-10-2723_54_21.814102\\model-00001-1.59807-0.25038-1.59802-0.26000.h5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.5196 - categorical_accuracy: 0.3288 - val_loss: 1.5994 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.59802\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.4420 - categorical_accuracy: 0.3816 - val_loss: 1.5948 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.59802 to 1.59481, saving model to model_init_2021-10-2723_54_21.814102\\model-00003-1.44202-0.38160-1.59481-0.25000.h5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.4229 - categorical_accuracy: 0.3906 - val_loss: 1.5982 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.59481\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.4012 - categorical_accuracy: 0.3937 - val_loss: 1.5794 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.59481 to 1.57937, saving model to model_init_2021-10-2723_54_21.814102\\model-00005-1.40117-0.39367-1.57937-0.26000.h5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.3873 - categorical_accuracy: 0.4072 - val_loss: 1.5751 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.57937 to 1.57505, saving model to model_init_2021-10-2723_54_21.814102\\model-00006-1.38732-0.40724-1.57505-0.25000.h5\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3591 - categorical_accuracy: 0.4223 - val_loss: 1.5763 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.57505\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3665 - categorical_accuracy: 0.4223 - val_loss: 1.5731 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.57505 to 1.57314, saving model to model_init_2021-10-2723_54_21.814102\\model-00008-1.36651-0.42232-1.57314-0.21000.h5\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3203 - categorical_accuracy: 0.4706 - val_loss: 1.5587 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.57314 to 1.55869, saving model to model_init_2021-10-2723_54_21.814102\\model-00009-1.32030-0.47059-1.55869-0.35000.h5\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2911 - categorical_accuracy: 0.4751 - val_loss: 1.5456 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.55869 to 1.54559, saving model to model_init_2021-10-2723_54_21.814102\\model-00010-1.29109-0.47511-1.54559-0.33000.h5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.3132 - categorical_accuracy: 0.4887 - val_loss: 1.5385 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.54559 to 1.53846, saving model to model_init_2021-10-2723_54_21.814102\\model-00011-1.31321-0.48869-1.53846-0.37000.h5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2927 - categorical_accuracy: 0.4646 - val_loss: 1.5217 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.53846 to 1.52168, saving model to model_init_2021-10-2723_54_21.814102\\model-00012-1.29268-0.46456-1.52168-0.43000.h5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.2726 - categorical_accuracy: 0.4721 - val_loss: 1.5299 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.52168\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.2348 - categorical_accuracy: 0.5415 - val_loss: 1.4985 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.52168 to 1.49850, saving model to model_init_2021-10-2723_54_21.814102\\model-00014-1.23482-0.54148-1.49850-0.43000.h5\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.2586 - categorical_accuracy: 0.4887 - val_loss: 1.4925 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.49850 to 1.49252, saving model to model_init_2021-10-2723_54_21.814102\\model-00015-1.25856-0.48869-1.49252-0.41000.h5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.2675 - categorical_accuracy: 0.4827 - val_loss: 1.4859 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.49252 to 1.48589, saving model to model_init_2021-10-2723_54_21.814102\\model-00016-1.26745-0.48265-1.48589-0.47000.h5\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.2233 - categorical_accuracy: 0.5113 - val_loss: 1.4431 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.48589 to 1.44315, saving model to model_init_2021-10-2723_54_21.814102\\model-00017-1.22331-0.51131-1.44315-0.50000.h5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.2356 - categorical_accuracy: 0.5038 - val_loss: 1.4342 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.44315 to 1.43424, saving model to model_init_2021-10-2723_54_21.814102\\model-00018-1.23562-0.50377-1.43424-0.47000.h5\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 61s 3s/step - loss: 1.2223 - categorical_accuracy: 0.5083 - val_loss: 1.4405 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.43424\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.2107 - categorical_accuracy: 0.5023 - val_loss: 1.4399 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.43424\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 65s 3s/step - loss: 1.2145 - categorical_accuracy: 0.5023 - val_loss: 1.4548 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.43424\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 1.2008 - categorical_accuracy: 0.5354 - val_loss: 1.4014 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.43424 to 1.40142, saving model to model_init_2021-10-2723_54_21.814102\\model-00022-1.20078-0.53544-1.40142-0.45000.h5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.2070 - categorical_accuracy: 0.5415 - val_loss: 1.3888 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.40142 to 1.38878, saving model to model_init_2021-10-2723_54_21.814102\\model-00023-1.20703-0.54148-1.38878-0.48000.h5\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1879 - categorical_accuracy: 0.5656 - val_loss: 1.3639 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.38878 to 1.36390, saving model to model_init_2021-10-2723_54_21.814102\\model-00024-1.18792-0.56561-1.36390-0.49000.h5\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 64s 3s/step - loss: 1.1804 - categorical_accuracy: 0.5264 - val_loss: 1.4035 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.36390\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 61s 3s/step - loss: 1.1479 - categorical_accuracy: 0.5490 - val_loss: 1.3490 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.36390 to 1.34904, saving model to model_init_2021-10-2723_54_21.814102\\model-00026-1.14795-0.54902-1.34904-0.49000.h5\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 63s 3s/step - loss: 1.1375 - categorical_accuracy: 0.5822 - val_loss: 1.3513 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.34904\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 65s 3s/step - loss: 1.1652 - categorical_accuracy: 0.5581 - val_loss: 1.3972 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.34904\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 65s 3s/step - loss: 1.1606 - categorical_accuracy: 0.5566 - val_loss: 1.2376 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.34904 to 1.23756, saving model to model_init_2021-10-2723_54_21.814102\\model-00029-1.16064-0.55656-1.23756-0.58000.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1496 - categorical_accuracy: 0.5520 - val_loss: 1.3295 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.23756\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1461 - categorical_accuracy: 0.5551 - val_loss: 1.3173 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.23756\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1513 - categorical_accuracy: 0.5354 - val_loss: 1.2744 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.23756\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1048 - categorical_accuracy: 0.5897 - val_loss: 1.2945 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.23756\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 54s 3s/step - loss: 1.1123 - categorical_accuracy: 0.5626 - val_loss: 1.2945 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.23756\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.1250 - categorical_accuracy: 0.5611 - val_loss: 1.2902 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.23756\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0789 - categorical_accuracy: 0.6109 - val_loss: 1.3975 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.23756\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.1153 - categorical_accuracy: 0.5882 - val_loss: 1.2692 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.23756\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0911 - categorical_accuracy: 0.5943 - val_loss: 1.2865 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.23756\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0588 - categorical_accuracy: 0.6154 - val_loss: 1.2691 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.23756\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.1022 - categorical_accuracy: 0.5897 - val_loss: 1.3027 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.23756\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.0703 - categorical_accuracy: 0.6244 - val_loss: 1.1843 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.23756 to 1.18427, saving model to model_init_2021-10-2723_54_21.814102\\model-00041-1.07035-0.62443-1.18427-0.60000.h5\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0797 - categorical_accuracy: 0.5852 - val_loss: 1.2477 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.18427\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.0829 - categorical_accuracy: 0.6003 - val_loss: 1.2493 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.18427\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.0308 - categorical_accuracy: 0.6305 - val_loss: 1.2225 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.18427\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.0541 - categorical_accuracy: 0.6018 - val_loss: 1.2496 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.18427\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 55s 3s/step - loss: 1.0296 - categorical_accuracy: 0.6365 - val_loss: 1.2755 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.18427\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0227 - categorical_accuracy: 0.6229 - val_loss: 1.2328 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.18427\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 59s 3s/step - loss: 1.0442 - categorical_accuracy: 0.6214 - val_loss: 1.2387 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.18427\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.0358 - categorical_accuracy: 0.6214 - val_loss: 1.2313 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.18427\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.0443 - categorical_accuracy: 0.6018 - val_loss: 1.2109 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.18427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bae83df10>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_28.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall performance of model_28 is not good. When we compare this with model_27, we notice that both categorical accuracy\n",
    "# (from 70.14% to 60.18%) and validation accuracy (58% to 54%) have gone down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - RNN Models (With Transfer Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_path = train_path i.e. path of 663 folders\n",
    "# folder_list = train_doc i.e. csv file\n",
    "# batch_size = 64\n",
    "\n",
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    # It is not possible to work with all the 30 images, as it will take too long processing time.\n",
    "    # So lets choose randomly 15 images, as this is more computationally expensive\n",
    "    img_idx = [1,2,4,6,10,12,14,16,18,20,22,24,27,28,29] #create a list of image numbers you want to use for a particular video(incase if u want to try with lesser images)\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(t)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,15,84,84,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = resize(image[:,20:140,:],(84,84)).astype(np.float32)\n",
    "                    normalizedImg = image/255.0                    \n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (normalizedImg[:,:,0]) #normalise and feed in the image # divide by 255.0\n",
    "                    batch_data[folder,idx,:,:,1] = (normalizedImg[:,:,1]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (normalizedImg[:,:,2]) #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1 # OHE\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if(len(t)%batch_size)!=0:\n",
    "            batch_data = np.zeros((len(t)%batch_size,15,84,84,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((len(t)%batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(len(t)%batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (num_batches*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imageio.imread(source_path+'/'+ t[folder + (num_batches*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = resize(image[:,20:140,:],(84,84)).astype(np.float32)\n",
    "                    normalizedImg = image/255.0                    \n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (normalizedImg[:,:,0]) #normalise and feed in the image # divide by 255.0\n",
    "                    batch_data[folder,idx,:,:,1] = (normalizedImg[:,:,1]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (normalizedImg[:,:,2]) #normalise and feed in the imagee\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (num_batches*batch_size)].strip().split(';')[2])] = 1 # OHE\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(84,84,3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "# x.add(Dropout(0.5))\n",
    "features = Dense(64, activation='relu')(x)\n",
    "conv_model = Model(inputs= base_model.input, outputs=features)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_29 = Sequential()\n",
    "model_29.add(TimeDistributed(conv_model, input_shape=(15,84,84,3)))\n",
    "model_29.add(LSTM(32, return_sequences=True))\n",
    "model_29.add(LSTM(16))\n",
    "model_29.add(Dropout(0.25))\n",
    "model_29.add(Dense(8, activation='relu'))\n",
    "model_29.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_2 (TimeDist (None, 15, 64)            14845824  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 15, 32)            12416     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 14,861,557\n",
      "Trainable params: 146,869\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import adam_v2\n",
    "\n",
    "optimiser_3 =adam_v2.Adam(0.001) #write your optimizer\n",
    "\n",
    "model_29.compile(optimizer=optimiser_3, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_29.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if #images=55, batch_size=5, then we have 11 batches and 11 epochs\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "# if #images=55, batch_size=5, then we have 11 batches and 3 pending images, therefore 12 epoch will be reqd for last 3 images\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 45s 4s/step - loss: 1.6053 - categorical_accuracy: 0.2066 - val_loss: 1.5933 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59328, saving model to model_init_2021-10-2820_51_26.241077\\model-00001-1.60527-0.20664-1.59328-0.30000.h5\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.5501 - categorical_accuracy: 0.3198 - val_loss: 1.5667 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.59328 to 1.56668, saving model to model_init_2021-10-2820_51_26.241077\\model-00002-1.55006-0.31976-1.56668-0.28000.h5\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.5042 - categorical_accuracy: 0.3680 - val_loss: 1.4917 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.56668 to 1.49169, saving model to model_init_2021-10-2820_51_26.241077\\model-00003-1.50416-0.36802-1.49169-0.39000.h5\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.4322 - categorical_accuracy: 0.4344 - val_loss: 1.4322 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.49169 to 1.43219, saving model to model_init_2021-10-2820_51_26.241077\\model-00004-1.43218-0.43439-1.43219-0.41000.h5\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.3654 - categorical_accuracy: 0.4480 - val_loss: 1.4262 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.43219 to 1.42616, saving model to model_init_2021-10-2820_51_26.241077\\model-00005-1.36538-0.44796-1.42616-0.40000.h5\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.2702 - categorical_accuracy: 0.5279 - val_loss: 1.3552 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.42616 to 1.35519, saving model to model_init_2021-10-2820_51_26.241077\\model-00006-1.27023-0.52790-1.35519-0.38000.h5\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 45s 4s/step - loss: 1.2056 - categorical_accuracy: 0.5324 - val_loss: 1.3478 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.35519 to 1.34782, saving model to model_init_2021-10-2820_51_26.241077\\model-00007-1.20565-0.53243-1.34782-0.43000.h5\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.1254 - categorical_accuracy: 0.5641 - val_loss: 1.3418 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.34782 to 1.34182, saving model to model_init_2021-10-2820_51_26.241077\\model-00008-1.12542-0.56410-1.34182-0.47000.h5\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.0614 - categorical_accuracy: 0.5897 - val_loss: 1.2976 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.34182 to 1.29762, saving model to model_init_2021-10-2820_51_26.241077\\model-00009-1.06140-0.58974-1.29762-0.45000.h5\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 0.9728 - categorical_accuracy: 0.6214 - val_loss: 1.2816 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.29762 to 1.28159, saving model to model_init_2021-10-2820_51_26.241077\\model-00010-0.97276-0.62142-1.28159-0.45000.h5\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.9167 - categorical_accuracy: 0.6486 - val_loss: 1.2669 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.28159 to 1.26692, saving model to model_init_2021-10-2820_51_26.241077\\model-00011-0.91669-0.64857-1.26692-0.49000.h5\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.8911 - categorical_accuracy: 0.6682 - val_loss: 1.3093 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.26692\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.8857 - categorical_accuracy: 0.6425 - val_loss: 1.2247 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.26692 to 1.22471, saving model to model_init_2021-10-2820_51_26.241077\\model-00013-0.88573-0.64253-1.22471-0.57000.h5\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 0.7485 - categorical_accuracy: 0.7300 - val_loss: 1.4210 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.22471\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.7325 - categorical_accuracy: 0.7376 - val_loss: 1.2878 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.22471\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 0.7217 - categorical_accuracy: 0.7526 - val_loss: 1.1563 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.22471 to 1.15633, saving model to model_init_2021-10-2820_51_26.241077\\model-00016-0.72171-0.75264-1.15633-0.56000.h5\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.6070 - categorical_accuracy: 0.8115 - val_loss: 1.2974 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.15633\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 0.5988 - categorical_accuracy: 0.8265 - val_loss: 1.1961 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.15633\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.5438 - categorical_accuracy: 0.8582 - val_loss: 1.2687 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.15633\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 0.5426 - categorical_accuracy: 0.8281 - val_loss: 1.2084 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.15633\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.5472 - categorical_accuracy: 0.8567 - val_loss: 1.2654 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.15633\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 0.5220 - categorical_accuracy: 0.8612 - val_loss: 1.3657 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.15633\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.5214 - categorical_accuracy: 0.8597 - val_loss: 1.2703 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.15633\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 0.4982 - categorical_accuracy: 0.8688 - val_loss: 1.2970 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.15633\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 0.5249 - categorical_accuracy: 0.8582 - val_loss: 1.3057 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.15633\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 0.4945 - categorical_accuracy: 0.8854 - val_loss: 1.3258 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.15633\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.5094 - categorical_accuracy: 0.8643 - val_loss: 1.2965 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.15633\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 0.4820 - categorical_accuracy: 0.8884 - val_loss: 1.2144 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.15633\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.5036 - categorical_accuracy: 0.8748 - val_loss: 1.3026 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.15633\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 42s 4s/step - loss: 0.4814 - categorical_accuracy: 0.8673 - val_loss: 1.3148 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.15633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec22b96e20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_29.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_29 is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying with GRU(64) and GRU(32):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(84,84,3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "# x.add(Dropout(0.5))\n",
    "features = Dense(64, activation='relu')(x)\n",
    "conv_model = Model(inputs= base_model.input, outputs=features)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_30 = Sequential()\n",
    "model_30.add(TimeDistributed(conv_model, input_shape=(15,84,84,3)))\n",
    "model_30.add(GRU(64, return_sequences=True))\n",
    "model_30.add(GRU(32))\n",
    "model_30.add(Dropout(0.25))\n",
    "model_30.add(Dense(8, activation='relu'))\n",
    "model_30.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 15, 64)            14845824  \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 15, 64)            24960     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                9408      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 14,880,501\n",
      "Trainable params: 165,813\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_30.compile(optimizer=optimiser_3, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_30.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.6149 - categorical_accuracy: 0.1991Source path =  C:\\Users\\Amit\\Documents\\Academics\\upGrad\\Deep Learning\\Project_data\\val ; batch size = 64\n",
      "11/11 [==============================] - 48s 5s/step - loss: 1.6149 - categorical_accuracy: 0.1991 - val_loss: 1.5600 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.55999, saving model to model_init_2021-10-2820_51_26.241077\\model-00001-1.61490-0.19910-1.55999-0.26000.h5\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.5699 - categorical_accuracy: 0.2730 - val_loss: 1.4788 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.55999 to 1.47879, saving model to model_init_2021-10-2820_51_26.241077\\model-00002-1.56994-0.27300-1.47879-0.31000.h5\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 45s 4s/step - loss: 1.4425 - categorical_accuracy: 0.3499 - val_loss: 1.4997 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.47879\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.3353 - categorical_accuracy: 0.4057 - val_loss: 1.4126 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.47879 to 1.41258, saving model to model_init_2021-10-2820_51_26.241077\\model-00004-1.33526-0.40573-1.41258-0.37000.h5\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 45s 4s/step - loss: 1.2505 - categorical_accuracy: 0.4510 - val_loss: 1.4117 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.41258 to 1.41167, saving model to model_init_2021-10-2820_51_26.241077\\model-00005-1.25051-0.45098-1.41167-0.41000.h5\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.0983 - categorical_accuracy: 0.5913 - val_loss: 1.1304 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.41167 to 1.13042, saving model to model_init_2021-10-2820_51_26.241077\\model-00006-1.09829-0.59125-1.13042-0.50000.h5\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.8849 - categorical_accuracy: 0.6968 - val_loss: 1.2804 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.13042\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.7271 - categorical_accuracy: 0.7602 - val_loss: 1.5177 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.13042\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.6651 - categorical_accuracy: 0.7843 - val_loss: 1.2288 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.13042\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 0.5833 - categorical_accuracy: 0.8130 - val_loss: 0.9426 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.13042 to 0.94257, saving model to model_init_2021-10-2820_51_26.241077\\model-00010-0.58332-0.81297-0.94257-0.62000.h5\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.4811 - categorical_accuracy: 0.8718 - val_loss: 1.0820 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.94257\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.4201 - categorical_accuracy: 0.8808 - val_loss: 1.1789 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.94257\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.3831 - categorical_accuracy: 0.8854 - val_loss: 1.1585 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.94257\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.3660 - categorical_accuracy: 0.9125 - val_loss: 0.9356 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.94257 to 0.93556, saving model to model_init_2021-10-2820_51_26.241077\\model-00014-0.36602-0.91252-0.93556-0.72000.h5\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.3190 - categorical_accuracy: 0.9246 - val_loss: 1.2009 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.93556\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.3158 - categorical_accuracy: 0.9170 - val_loss: 1.2083 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.93556\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.2684 - categorical_accuracy: 0.9397 - val_loss: 1.1548 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.93556\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.2696 - categorical_accuracy: 0.9367 - val_loss: 1.2524 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.93556\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.2745 - categorical_accuracy: 0.9427 - val_loss: 1.1640 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.93556\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.2490 - categorical_accuracy: 0.9472 - val_loss: 1.2910 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.93556\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.2458 - categorical_accuracy: 0.9487 - val_loss: 1.1647 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.93556\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.2489 - categorical_accuracy: 0.9457 - val_loss: 1.3135 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.93556\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 45s 4s/step - loss: 0.2555 - categorical_accuracy: 0.9412 - val_loss: 1.1684 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.93556\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.2650 - categorical_accuracy: 0.9412 - val_loss: 1.1483 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.93556\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 45s 4s/step - loss: 0.2386 - categorical_accuracy: 0.9517 - val_loss: 1.1650 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.93556\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.2434 - categorical_accuracy: 0.9517 - val_loss: 1.0504 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.93556\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 45s 4s/step - loss: 0.2453 - categorical_accuracy: 0.9517 - val_loss: 1.1627 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.93556\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.2332 - categorical_accuracy: 0.9563 - val_loss: 1.3015 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.93556\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 45s 5s/step - loss: 0.2495 - categorical_accuracy: 0.9487 - val_loss: 1.1622 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.93556\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 46s 5s/step - loss: 0.2362 - categorical_accuracy: 0.9578 - val_loss: 1.0933 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.93556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec1f161cd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_30.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_30 is massively overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying with GRU(64) with return sequences = False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(84,84,3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "# x.add(Dropout(0.5))\n",
    "features = Dense(64, activation='relu')(x)\n",
    "conv_model = Model(inputs= base_model.input, outputs=features)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_31 = Sequential()\n",
    "model_31.add(TimeDistributed(conv_model, input_shape=(15,84,84,3)))\n",
    "model_31.add(GRU(64))\n",
    "model_31.add(Dropout(0.25))\n",
    "model_31.add(Dense(8, activation='relu'))\n",
    "model_31.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_3 (TimeDist (None, 15, 64)            14845824  \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                24960     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 14,871,349\n",
      "Trainable params: 156,661\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_31.compile(optimizer=optimiser_3, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_31.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 45s 4s/step - loss: 1.6852 - categorical_accuracy: 0.1825 - val_loss: 1.6281 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.62811, saving model to model_init_2021-10-2820_51_26.241077\\model-00001-1.68517-0.18250-1.62811-0.17000.h5\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.6406 - categorical_accuracy: 0.1916 - val_loss: 1.6096 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.62811 to 1.60964, saving model to model_init_2021-10-2820_51_26.241077\\model-00002-1.64061-0.19155-1.60964-0.15000.h5\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.6222 - categorical_accuracy: 0.1870 - val_loss: 1.6108 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.60964\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.6075 - categorical_accuracy: 0.1946 - val_loss: 1.6129 - val_categorical_accuracy: 0.1300\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.60964\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.6097 - categorical_accuracy: 0.2232 - val_loss: 1.6085 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.60964 to 1.60851, saving model to model_init_2021-10-2820_51_26.241077\\model-00005-1.60972-0.22323-1.60851-0.19000.h5\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.6109 - categorical_accuracy: 0.2081 - val_loss: 1.6010 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.60851 to 1.60103, saving model to model_init_2021-10-2820_51_26.241077\\model-00006-1.61088-0.20814-1.60103-0.20000.h5\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 45s 5s/step - loss: 1.6065 - categorical_accuracy: 0.2036 - val_loss: 1.6063 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.60103\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.6107 - categorical_accuracy: 0.2232 - val_loss: 1.6058 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.60103\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.5994 - categorical_accuracy: 0.2217 - val_loss: 1.6043 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.60103\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 47s 5s/step - loss: 1.6103 - categorical_accuracy: 0.2051 - val_loss: 1.5984 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.60103 to 1.59841, saving model to model_init_2021-10-2820_51_26.241077\\model-00010-1.61028-0.20513-1.59841-0.19000.h5\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 46s 5s/step - loss: 1.5996 - categorical_accuracy: 0.2112 - val_loss: 1.6026 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.59841\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.5993 - categorical_accuracy: 0.2368 - val_loss: 1.5963 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.59841 to 1.59632, saving model to model_init_2021-10-2820_51_26.241077\\model-00012-1.59933-0.23680-1.59632-0.22000.h5\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 45s 4s/step - loss: 1.5976 - categorical_accuracy: 0.2142 - val_loss: 1.6013 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.59632\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.6059 - categorical_accuracy: 0.2157 - val_loss: 1.6013 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.59632\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.5948 - categorical_accuracy: 0.2504 - val_loss: 1.5990 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.59632\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.5854 - categorical_accuracy: 0.2474 - val_loss: 1.5966 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.59632\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.5815 - categorical_accuracy: 0.2685 - val_loss: 1.5959 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.59632 to 1.59587, saving model to model_init_2021-10-2820_51_26.241077\\model-00017-1.58146-0.26848-1.59587-0.22000.h5\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.5876 - categorical_accuracy: 0.2640 - val_loss: 1.6002 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.59587\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 45s 4s/step - loss: 1.5823 - categorical_accuracy: 0.2730 - val_loss: 1.5912 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.59587 to 1.59123, saving model to model_init_2021-10-2820_51_26.241077\\model-00019-1.58227-0.27300-1.59123-0.26000.h5\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.5846 - categorical_accuracy: 0.2383 - val_loss: 1.5844 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.59123 to 1.58439, saving model to model_init_2021-10-2820_51_26.241077\\model-00020-1.58455-0.23831-1.58439-0.33000.h5\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.5800 - categorical_accuracy: 0.2594 - val_loss: 1.5822 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.58439 to 1.58222, saving model to model_init_2021-10-2820_51_26.241077\\model-00021-1.57996-0.25943-1.58222-0.25000.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.5810 - categorical_accuracy: 0.2685 - val_loss: 1.5686 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.58222 to 1.56864, saving model to model_init_2021-10-2820_51_26.241077\\model-00022-1.58099-0.26848-1.56864-0.31000.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 48s 5s/step - loss: 1.5664 - categorical_accuracy: 0.2821 - val_loss: 1.5710 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.56864\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 47s 5s/step - loss: 1.5687 - categorical_accuracy: 0.2700 - val_loss: 1.5629 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.56864 to 1.56286, saving model to model_init_2021-10-2820_51_26.241077\\model-00024-1.56870-0.26998-1.56286-0.27000.h5\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 51s 5s/step - loss: 1.5674 - categorical_accuracy: 0.2700 - val_loss: 1.5560 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.56286 to 1.55604, saving model to model_init_2021-10-2820_51_26.241077\\model-00025-1.56743-0.26998-1.55604-0.31000.h5\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 51s 5s/step - loss: 1.5524 - categorical_accuracy: 0.2866 - val_loss: 1.5520 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.55604 to 1.55204, saving model to model_init_2021-10-2820_51_26.241077\\model-00026-1.55244-0.28658-1.55204-0.32000.h5\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 45s 5s/step - loss: 1.5562 - categorical_accuracy: 0.2986 - val_loss: 1.5427 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.55204 to 1.54273, saving model to model_init_2021-10-2820_51_26.241077\\model-00027-1.55616-0.29864-1.54273-0.35000.h5\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.5507 - categorical_accuracy: 0.3047 - val_loss: 1.5464 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.54273\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.5424 - categorical_accuracy: 0.3032 - val_loss: 1.5309 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.54273 to 1.53090, saving model to model_init_2021-10-2820_51_26.241077\\model-00029-1.54236-0.30317-1.53090-0.36000.h5\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.5322 - categorical_accuracy: 0.2760 - val_loss: 1.5429 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.53090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec258ebb80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_31.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall performance of model_31 is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying with LSTM 16 and 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "#write your model here\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(84,84,3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "# x.add(Dropout(0.5))\n",
    "features = Dense(64, activation='relu')(x)\n",
    "conv_model = Model(inputs= base_model.input, outputs=features)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_32 = Sequential()\n",
    "model_32.add(TimeDistributed(conv_model, input_shape=(15,84,84,3)))\n",
    "model_32.add(LSTM(16, return_sequences=True))\n",
    "model_32.add(LSTM(8))\n",
    "model_32.add(Dropout(0.25))\n",
    "model_32.add(Dense(8, activation='relu'))\n",
    "model_32.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_4 (TimeDist (None, 15, 64)            14845824  \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 15, 16)            5184      \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 14,851,925\n",
      "Trainable params: 137,237\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_32.compile(optimizer=optimiser_3, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_32.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 46s 4s/step - loss: 1.6081 - categorical_accuracy: 0.2021 - val_loss: 1.5977 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59768, saving model to model_init_2021-10-2820_51_26.241077\\model-00001-1.60807-0.20211-1.59768-0.23000.h5\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 47s 5s/step - loss: 1.6026 - categorical_accuracy: 0.2278 - val_loss: 1.6025 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.59768\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 49s 5s/step - loss: 1.5930 - categorical_accuracy: 0.2021 - val_loss: 1.5905 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.59768 to 1.59050, saving model to model_init_2021-10-2820_51_26.241077\\model-00003-1.59295-0.20211-1.59050-0.22000.h5\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.5946 - categorical_accuracy: 0.2217 - val_loss: 1.5816 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.59050 to 1.58161, saving model to model_init_2021-10-2820_51_26.241077\\model-00004-1.59455-0.22172-1.58161-0.30000.h5\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.5859 - categorical_accuracy: 0.2323 - val_loss: 1.5821 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.58161\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.5885 - categorical_accuracy: 0.2232 - val_loss: 1.5656 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.58161 to 1.56559, saving model to model_init_2021-10-2820_51_26.241077\\model-00006-1.58850-0.22323-1.56559-0.28000.h5\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 50s 5s/step - loss: 1.5761 - categorical_accuracy: 0.2504 - val_loss: 1.5723 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.56559\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 45s 5s/step - loss: 1.5700 - categorical_accuracy: 0.2609 - val_loss: 1.5703 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.56559\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 49s 5s/step - loss: 1.5751 - categorical_accuracy: 0.2202 - val_loss: 1.5629 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.56559 to 1.56292, saving model to model_init_2021-10-2820_51_26.241077\\model-00009-1.57510-0.22021-1.56292-0.25000.h5\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 52s 5s/step - loss: 1.5624 - categorical_accuracy: 0.2760 - val_loss: 1.5785 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.56292\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.5656 - categorical_accuracy: 0.2624 - val_loss: 1.5557 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.56292 to 1.55566, saving model to model_init_2021-10-2820_51_26.241077\\model-00011-1.56555-0.26244-1.55566-0.27000.h5\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.5569 - categorical_accuracy: 0.2745 - val_loss: 1.5494 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.55566 to 1.54943, saving model to model_init_2021-10-2820_51_26.241077\\model-00012-1.55687-0.27451-1.54943-0.25000.h5\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.5480 - categorical_accuracy: 0.2851 - val_loss: 1.5489 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.54943 to 1.54890, saving model to model_init_2021-10-2820_51_26.241077\\model-00013-1.54798-0.28507-1.54890-0.27000.h5\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.5613 - categorical_accuracy: 0.2670 - val_loss: 1.5368 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.54890 to 1.53679, saving model to model_init_2021-10-2820_51_26.241077\\model-00014-1.56134-0.26697-1.53679-0.25000.h5\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.5506 - categorical_accuracy: 0.2640 - val_loss: 1.5404 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.53679\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.5454 - categorical_accuracy: 0.2745 - val_loss: 1.5368 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.53679\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 46s 5s/step - loss: 1.5428 - categorical_accuracy: 0.2805 - val_loss: 1.5356 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.53679 to 1.53558, saving model to model_init_2021-10-2820_51_26.241077\\model-00017-1.54276-0.28054-1.53558-0.24000.h5\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.5303 - categorical_accuracy: 0.2941 - val_loss: 1.5396 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.53558\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 45s 4s/step - loss: 1.5312 - categorical_accuracy: 0.3047 - val_loss: 1.5303 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.53558 to 1.53031, saving model to model_init_2021-10-2820_51_26.241077\\model-00019-1.53124-0.30468-1.53031-0.24000.h5\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.5320 - categorical_accuracy: 0.2971 - val_loss: 1.5305 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.53031\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.5282 - categorical_accuracy: 0.2911 - val_loss: 1.5236 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.53031 to 1.52362, saving model to model_init_2021-10-2820_51_26.241077\\model-00021-1.52825-0.29110-1.52362-0.24000.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.5270 - categorical_accuracy: 0.2986 - val_loss: 1.5202 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.52362 to 1.52020, saving model to model_init_2021-10-2820_51_26.241077\\model-00022-1.52705-0.29864-1.52020-0.28000.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.5173 - categorical_accuracy: 0.3137 - val_loss: 1.5187 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.52020 to 1.51869, saving model to model_init_2021-10-2820_51_26.241077\\model-00023-1.51734-0.31373-1.51869-0.27000.h5\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.5255 - categorical_accuracy: 0.3002 - val_loss: 1.5213 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.51869\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.5097 - categorical_accuracy: 0.3122 - val_loss: 1.5112 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.51869 to 1.51117, saving model to model_init_2021-10-2820_51_26.241077\\model-00025-1.50968-0.31222-1.51117-0.28000.h5\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.5189 - categorical_accuracy: 0.2971 - val_loss: 1.5191 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.51117\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.5139 - categorical_accuracy: 0.3243 - val_loss: 1.5077 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.51117 to 1.50767, saving model to model_init_2021-10-2820_51_26.241077\\model-00027-1.51393-0.32428-1.50767-0.27000.h5\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.5060 - categorical_accuracy: 0.3273 - val_loss: 1.5214 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.50767\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.5056 - categorical_accuracy: 0.3333 - val_loss: 1.5009 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.50767 to 1.50086, saving model to model_init_2021-10-2820_51_26.241077\\model-00029-1.50561-0.33333-1.50086-0.28000.h5\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.5123 - categorical_accuracy: 0.2926 - val_loss: 1.5018 - val_categorical_accuracy: 0.2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00030: val_loss did not improve from 1.50086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec259154c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_32.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of model_32 is too poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to train the weights in model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "#write your model here\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(84,84,3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# x.add(Dropout(0.5))\n",
    "features = Dense(64, activation='relu')(x)\n",
    "conv_model = Model(inputs= base_model.input, outputs=features)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model_33 = Sequential()\n",
    "model_33.add(TimeDistributed(conv_model, input_shape=(15,84,84,3)))\n",
    "model_33.add(LSTM(32, return_sequences=True))\n",
    "model_33.add(LSTM(16))\n",
    "model_33.add(Dropout(0.25))\n",
    "model_33.add(Dense(8, activation='relu'))\n",
    "model_33.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 15, 64)            14845824  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 15, 32)            12416     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 14,861,557\n",
      "Trainable params: 14,861,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import adam_v2\n",
    "\n",
    "optimiser_3 =adam_v2.Adam(0.001) #write your optimizer\n",
    "\n",
    "model_33.compile(optimizer=optimiser_3, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_33.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if #images=55, batch_size=5, then we have 11 batches and 11 epochs\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "# if #images=55, batch_size=5, then we have 11 batches and 3 pending images, therefore 12 epoch will be reqd for last 3 images\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  C:\\Users\\Amit\\Documents\\Academics\\upGrad\\Deep Learning\\Project_data\\train ; batch size = 64\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.6407 - categorical_accuracy: 0.1704Source path =  C:\\Users\\Amit\\Documents\\Academics\\upGrad\\Deep Learning\\Project_data\\val ; batch size = 64\n",
      "11/11 [==============================] - 69s 5s/step - loss: 1.6407 - categorical_accuracy: 0.1704 - val_loss: 1.6208 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.62085, saving model to model_init_2021-10-2823_31_32.634291\\model-00001-1.64069-0.17044-1.62085-0.21000.h5\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.6435 - categorical_accuracy: 0.1795 - val_loss: 1.6511 - val_categorical_accuracy: 0.1300\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.62085\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.6167 - categorical_accuracy: 0.2097 - val_loss: 1.6158 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.62085 to 1.61580, saving model to model_init_2021-10-2823_31_32.634291\\model-00003-1.61674-0.20965-1.61580-0.18000.h5\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.6165 - categorical_accuracy: 0.2051 - val_loss: 1.6121 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.61580 to 1.61213, saving model to model_init_2021-10-2823_31_32.634291\\model-00004-1.61651-0.20513-1.61213-0.18000.h5\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.6165 - categorical_accuracy: 0.1946 - val_loss: 1.6097 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.61213 to 1.60968, saving model to model_init_2021-10-2823_31_32.634291\\model-00005-1.61647-0.19457-1.60968-0.18000.h5\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.6104 - categorical_accuracy: 0.2157 - val_loss: 1.6079 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.60968 to 1.60786, saving model to model_init_2021-10-2823_31_32.634291\\model-00006-1.61036-0.21569-1.60786-0.22000.h5\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.6066 - categorical_accuracy: 0.2066 - val_loss: 1.6084 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.60786\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.6087 - categorical_accuracy: 0.1885 - val_loss: 1.6070 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.60786 to 1.60699, saving model to model_init_2021-10-2823_31_32.634291\\model-00008-1.60870-0.18854-1.60699-0.16000.h5\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.6082 - categorical_accuracy: 0.2157 - val_loss: 1.6083 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.60699\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.6097 - categorical_accuracy: 0.2247 - val_loss: 1.6095 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.60699\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.6079 - categorical_accuracy: 0.2157 - val_loss: 1.6082 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.60699\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.6097 - categorical_accuracy: 0.1976 - val_loss: 1.6107 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.60699\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.6084 - categorical_accuracy: 0.2021 - val_loss: 1.6082 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.60699\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 42s 4s/step - loss: 1.6103 - categorical_accuracy: 0.1961 - val_loss: 1.6058 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.60699 to 1.60584, saving model to model_init_2021-10-2823_31_32.634291\\model-00014-1.61032-0.19608-1.60584-0.25000.h5\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 43s 4s/step - loss: 1.6092 - categorical_accuracy: 0.1976 - val_loss: 1.6082 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.60584\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 41s 4s/step - loss: 1.6117 - categorical_accuracy: 0.2021 - val_loss: 1.6074 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.60584\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 44s 4s/step - loss: 1.6102 - categorical_accuracy: 0.2051 - val_loss: 1.6082 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.60584\n",
      "Epoch 18/30\n",
      " 3/11 [=======>......................] - ETA: 28s - loss: 1.6157 - categorical_accuracy: 0.1406"
     ]
    }
   ],
   "source": [
    "model_33.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
